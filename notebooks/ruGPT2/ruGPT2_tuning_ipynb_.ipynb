{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ruGPT2-tuning.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GtjDiObh1yX"
      },
      "source": [
        "# ru_transformers - GPT-2 tuning for horoscopes\n",
        "Original git: https://github.com/mgrankin/ru_transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeFtD3ywlxnC"
      },
      "source": [
        "Открыть ноутбук можно на Colab:\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ZnTI4Cg9YGK4wIdE16AjdfiUpcxTpa0A?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9fGjPf4fbqy"
      },
      "source": [
        "import regex as re\n",
        "import os\n",
        "from fastai.basics import *\n",
        "from multiprocessing import Pool\n",
        "from colab_ssh import launch_ssh\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avUBvbKAzU5h",
        "outputId": "3510399b-2ef3-44a7-a1c3-54eca1c1b2b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!rm -rf '/content/ru_transformers' || :\n",
        "!git clone https://github.com/mgrankin/ru_transformers\n",
        "%cd ru_transformers\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') # для сохранения моделей и импорта данных\n",
        "!pip install -q -r \"tpu_requirements.txt\"\n",
        "!pip install -q tendo\n",
        "!pip install awscli\n",
        "!pip install colab_ssh\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ru_transformers'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 1959 (delta 14), reused 22 (delta 6), pack-reused 1921\u001b[K\n",
            "Receiving objects: 100% (1959/1959), 5.72 MiB | 22.03 MiB/s, done.\n",
            "Resolving deltas: 100% (1292/1292), done.\n",
            "/content/ru_transformers\n",
            "Mounted at /content/gdrive\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 5.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 49.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 53.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 53.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7MB 53.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 55.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 52.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.7MB 50.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.7MB 46.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.0MB/s \n",
            "\u001b[?25h  Building wheel for fastai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.19.2 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 112kB 6.7MB/s \n",
            "\u001b[?25hCollecting awscli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/1b/2b65ddc4e18ab8b232d413b75591ccd22021233fb3c3fd1ddd099d0170ce/awscli-1.18.162-py2.py3-none-any.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 4.1MB/s \n",
            "\u001b[?25hCollecting colorama<0.4.4,>=0.2.5; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from awscli) (0.3.3)\n",
            "Requirement already satisfied: botocore==1.19.2 in /usr/local/lib/python3.6/dist-packages (from awscli) (1.19.2)\n",
            "Collecting docutils<0.16,>=0.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML<5.4,>=3.10; python_version != \"3.4\" in /usr/local/lib/python3.6/dist-packages (from awscli) (3.13)\n",
            "Collecting rsa<=4.5.0,>=3.1.2; python_version != \"3.4\"\n",
            "  Downloading https://files.pythonhosted.org/packages/26/f8/8127fdda0294f044121d20aac7785feb810e159098447967a6103dedfb96/rsa-4.5-py2.py3-none-any.whl\n",
            "Collecting urllib3<1.26,>=1.25.4; python_version != \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 30.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.19.2->awscli) (2.8.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from botocore==1.19.2->awscli) (0.10.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=4.5.0,>=3.1.2; python_version != \"3.4\"->awscli) (0.4.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.19.2->awscli) (1.15.0)\n",
            "\u001b[31mERROR: kaggle 1.5.8 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.11 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: colorama, docutils, rsa, awscli, urllib3\n",
            "  Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Found existing installation: rsa 4.6\n",
            "    Uninstalling rsa-4.6:\n",
            "      Successfully uninstalled rsa-4.6\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed awscli-1.18.162 colorama-0.4.3 docutils-0.15.2 rsa-4.5 urllib3-1.25.11\n",
            "Collecting colab_ssh\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/95/4936b75ebb5d6dcd915a5ebb56ad1341de7f448459633a3f07ec34f207bc/colab_ssh-0.2.64-py3-none-any.whl\n",
            "Installing collected packages: colab-ssh\n",
            "Successfully installed colab-ssh-0.2.64\n",
            "Thu Oct 22 08:43:13 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmLKxemQzuK9",
        "outputId": "5f6a8894-663d-4080-bd2c-e26335f9427c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%set_env CUDA_HOME=/usr/local/cuda-10.1\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "# fix setup.py if complains for version mismatch\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: CUDA_HOME=/usr/local/cuda-10.1\n",
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 1, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 7456 (delta 0), reused 0 (delta 0), pack-reused 7455\u001b[K\n",
            "Receiving objects: 100% (7456/7456), 13.91 MiB | 4.07 MiB/s, done.\n",
            "Resolving deltas: 100% (5038/5038), done.\n",
            "/content/ru_transformers/apex\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-ljqbdlcq\n",
            "Created temporary directory: /tmp/pip-req-tracker-djjax0z6\n",
            "Created requirements tracker '/tmp/pip-req-tracker-djjax0z6'\n",
            "Created temporary directory: /tmp/pip-install-46ed7biz\n",
            "Processing /content/ru_transformers/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-pworqt62\n",
            "  Added file:///content/ru_transformers/apex to build tracker '/tmp/pip-req-tracker-djjax0z6'\n",
            "    Running setup.py (path:/tmp/pip-req-build-pworqt62/setup.py) egg_info for package from file:///content/ru_transformers/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.6.0+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-pworqt62/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-pworqt62/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-pworqt62/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-pworqt62/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-pworqt62/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-pworqt62/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-pworqt62/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-pworqt62 has version 0.1, which satisfies requirement apex==0.1 from file:///content/ru_transformers/apex\n",
            "  Removed apex==0.1 from file:///content/ru_transformers/apex from build tracker '/tmp/pip-req-tracker-djjax0z6'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-record-xbaserfu\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-pworqt62/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-pworqt62/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-xbaserfu/install-record.txt --single-version-externally-managed --compile\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.6.0+cu101\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-pworqt62/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "    Cuda compilation tools, release 10.1, V10.1.243\n",
            "    from /usr/local/cuda-10.1/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.6\n",
            "    creating build/lib.linux-x86_64-3.6/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "    creating build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    running build_ext\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/utils/cpp_extension.py:335: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.6\n",
            "    creating build/temp.linux-x86_64-3.6/csrc\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    In file included from csrc/flatten_unflatten.cpp:2:0:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:36:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         return tensors[0].type();\n",
            "                                ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'amp_C' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/amp_C_frontend.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'syncbn' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/syncbn.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'fused_layer_norm_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/macros/Macros.h:146:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:330:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                               \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:318:3: note: in expansion of macro ‘TORCH_CHECK_WITH_MSG’\n",
            "       TORCH_CHECK_WITH_MSG(error_t, cond, \"\", __VA_ARGS__)\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/util/Exception.h:341:32: note: in expansion of macro ‘TORCH_CHECK_WITH’\n",
            "     #define TORCH_CHECK(cond, ...) TORCH_CHECK_WITH(Error, cond, __VA_ARGS__)\n",
            "                                    ^~~~~~~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'mlp_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Parallel.h:149:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "                                                                                 ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                        ^\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:150:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                            \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:152:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:66:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:150:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                            \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:152:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:66:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:5,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/core/TensorBody.h:268:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:13:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/cuda-10.1/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda-10.1/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/record_function.h(18): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(97): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(126): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/record_function.h(18): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(97): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(126): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/lib/python3.6/dist-packages/torch/lib -L/usr/local/cuda-10.1/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    running install_lib\n",
            "    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    creating apex.egg-info\n",
            "    writing apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to apex.egg-info/top_level.txt\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-xbaserfu/install-record.txt'\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "  Removing source in /tmp/pip-req-build-pworqt62\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-djjax0z6'\n",
            "/content/ru_transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9exBIzLz02L",
        "outputId": "609caedf-207c-4cef-808d-facdc5f04576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!cd ..; aws s3 sync --no-sign-request s3://models.dobro.ai/gpt2/ru/unfreeze_all gpt2 #загрузка моделей"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Completed 7 Bytes/2.3 GiB (16 Bytes/s) with 10 file(s) remaining\rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/m_checkpoint-3364613/step.txt to gpt2/m_checkpoint-3364613/step.txt\n",
            "Completed 7 Bytes/2.3 GiB (16 Bytes/s) with 9 file(s) remaining\rCompleted 605 Bytes/2.3 GiB (1.2 KiB/s) with 9 file(s) remaining\rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/s_checkpoint-1900000/config.json to gpt2/s_checkpoint-1900000/config.json\n",
            "Completed 605 Bytes/2.3 GiB (1.2 KiB/s) with 8 file(s) remaining\rCompleted 1.2 KiB/2.3 GiB (2.6 KiB/s) with 8 file(s) remaining  \rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/m_checkpoint-3364613/config.json to gpt2/m_checkpoint-3364613/config.json\n",
            "Completed 1.2 KiB/2.3 GiB (2.6 KiB/s) with 7 file(s) remaining\rCompleted 2.6 KiB/2.3 GiB (5.2 KiB/s) with 7 file(s) remaining\rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/m_checkpoint-3364613/training_args.bin to gpt2/m_checkpoint-3364613/training_args.bin\n",
            "Completed 2.6 KiB/2.3 GiB (5.2 KiB/s) with 6 file(s) remaining\rCompleted 4.0 KiB/2.3 GiB (7.3 KiB/s) with 6 file(s) remaining\rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/s_checkpoint-1900000/training_args.bin to gpt2/s_checkpoint-1900000/training_args.bin\n",
            "Completed 4.0 KiB/2.3 GiB (7.3 KiB/s) with 5 file(s) remaining\rCompleted 260.0 KiB/2.3 GiB (468.6 KiB/s) with 5 file(s) remaining\rCompleted 516.0 KiB/2.3 GiB (912.0 KiB/s) with 5 file(s) remaining\rCompleted 772.0 KiB/2.3 GiB (1.3 MiB/s) with 5 file(s) remaining  \rCompleted 1.0 MiB/2.3 GiB (1.8 MiB/s) with 5 file(s) remaining    \rCompleted 1.0 MiB/2.3 GiB (1.8 MiB/s) with 5 file(s) remaining    \rCompleted 1.2 MiB/2.3 GiB (2.1 MiB/s) with 5 file(s) remaining    \rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/s_checkpoint-1900000/step.txt to gpt2/s_checkpoint-1900000/step.txt\n",
            "Completed 1.2 MiB/2.3 GiB (2.1 MiB/s) with 4 file(s) remaining\rdownload: s3://models.dobro.ai/gpt2/ru/unfreeze_all/m_checkpoint-3364613/encoder.model to gpt2/m_checkpoint-3364613/encoder.model\n",
            "download: s3://models.dobro.ai/gpt2/ru/unfreeze_all/s_checkpoint-1900000/encoder.model to gpt2/s_checkpoint-1900000/encoder.model\n",
            "download: s3://models.dobro.ai/gpt2/ru/unfreeze_all/s_checkpoint-1900000/pytorch_model.bin to gpt2/s_checkpoint-1900000/pytorch_model.bin\n",
            "download: s3://models.dobro.ai/gpt2/ru/unfreeze_all/m_checkpoint-3364613/pytorch_model.bin to gpt2/m_checkpoint-3364613/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eERVfn0x0GvZ"
      },
      "source": [
        "DATASET_PATH = \"/content/gdrive/My Drive/dataset\"\n",
        "SAVE_TO_PATH = \"./dataset/prepared/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npb5Xl5f0LFV"
      },
      "source": [
        "def process_function(path_to_file):\n",
        "    match = re.compile(r'(?=[^ ])([\\W])([\\w])')\n",
        "    match2 = re.compile('(.|\\s)\\\\1\\\\1+')\n",
        "    with open(path_to_file, 'r') as f:\n",
        "        lines = f.read()\n",
        "    if lines and lines[0] != ' ': lines = ' ' + lines\n",
        "    lines = match.sub(r'\\g<1> \\g<2>', lines)\n",
        "    lines = match2.sub(r'\\1'*3, lines)\n",
        "    path = os.path.join(SAVE_TO_PATH, os.path.split(path_to_file)[1])\n",
        "    with open(path, 'w') as handle:\n",
        "        handle.write(lines)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dylw4rdQ0Mcf",
        "outputId": "e0e5531d-dd48-45ff-df9d-b8f843183211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "txts = get_files(DATASET_PATH, '.txt')\n",
        "if not os.path.exists(SAVE_TO_PATH):\n",
        "    os.makedirs(SAVE_TO_PATH)\n",
        "\n",
        "\n",
        "for _ in progress_bar(Pool(64).imap_unordered(process_function, txts), len(txts)):\n",
        "    pass"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [2/2 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNniaOm200DP"
      },
      "source": [
        "!mkdir ./dataset/validation"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBHSLBvHIAac"
      },
      "source": [
        "!mkdir ./dataset/train"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfteHbKqH5CE"
      },
      "source": [
        "!mv ./dataset/prepared/corpus.txt ./dataset/train/\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAAErsfKgHLo"
      },
      "source": [
        "!mv ./dataset/prepared/validation.txt ./dataset/validation"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zzhb7gViXI-"
      },
      "source": [
        "os.chdir('/content/')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNdKhzNb0Ww5",
        "outputId": "03c504f7-2bdc-4dc5-9497-d0465db268f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%set_env CUDA_VISIBLE_DEVICES=0"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoolK8Db0XNT"
      },
      "source": [
        "# Можно и по ssh root@some.domen -p 12345\n",
        "#launch_ssh(\"YOUR TOKEN HERE\", \"YOUR PASSWORD HERE\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_ll2FyG_DaE"
      },
      "source": [
        "os.chdir('/content/ru_transformers')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS81Wqcw-_Lq",
        "outputId": "a2e117ae-7339-4e9d-f84b-cd998cdff9cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 run_lm_finetuning.py \\\n",
        "    --output_dir=\"/content/gdrive/My Drive/gpt2-ru\" \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=gpt2/s_checkpoint-1900000/ \\\n",
        "    --do_train \\\n",
        "    --train_data_file=./dataset/train/corpus.txt \\\n",
        "    --per_gpu_train_batch_size=2 \\\n",
        "    --save_steps=10000 \\\n",
        "    --logging_steps=1 \\\n",
        "    --warmup_samples 16000 \\\n",
        "    --learning_rate 3e-5 \\\n",
        "    --tokenizer_class YTEncoder \\\n",
        "    --tokenizer_name bpe/yt.model \\\n",
        "    --do_eval \\\n",
        "    --evaluate_during_training \\\n",
        "    --eval_steps 1000 \\\n",
        "    --eval_data_file=./dataset/validation/validation.txt \\\n",
        "    --num_train_epochs 5.0 \\\n",
        "    --unfreeze_level 0 \\\n",
        "    --fp16 \\\n",
        "    --fp16_opt_level O2 \\\n",
        "    --overwrite_output_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-21 09:09:02.518664: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:09:03.892569: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-21 09:09:03.892803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:09:03.893613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-21 09:09:03.893660: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:09:03.895635: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-21 09:09:03.897312: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-21 09:09:03.897646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-21 09:09:03.899651: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-21 09:09:03.900980: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-21 09:09:03.905210: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-21 09:09:03.905350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:09:03.906148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:09:03.906866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-21 09:09:03.913209: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-10-21 09:09:03.913469: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4bbd180 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-21 09:09:03.913508: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-21 09:09:03.967851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:09:03.968707: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4bbcfc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-21 09:09:03.968742: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-10-21 09:09:03.968964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:09:03.969660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-21 09:09:03.969721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:09:03.969814: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-21 09:09:03.969865: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-21 09:09:03.969917: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-21 09:09:03.969964: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-21 09:09:03.970007: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-21 09:09:03.970052: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-21 09:09:03.970140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:09:03.970898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:09:03.971576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-21 09:09:03.971653: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:09:06.710533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-21 09:09:06.710629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-21 09:09:06.710659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-21 09:09:06.710891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:09:06.711645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:09:06.712406: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-21 09:09:06.712499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10350 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "10/21/2020 09:09:06 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
            "10/21/2020 09:09:06 - INFO - transformers.configuration_utils -   loading configuration file gpt2/s_checkpoint-1900000/config.json\n",
            "10/21/2020 09:09:06 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_labels\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "10/21/2020 09:09:06 - INFO - transformers.modeling_utils -   loading weights file gpt2/s_checkpoint-1900000/pytorch_model.bin\n",
            "////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
            "149\n",
            "////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
            "5\n",
            "10/21/2020 09:09:16 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-06, block_size=1024, cache_dir='', config_name='', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_train=True, eval_all_checkpoints=False, eval_data_file='./dataset/validation/validation.txt', eval_steps=1000, evaluate_during_training=True, fp16=True, fp16_opt_level='O2', gradient_accumulation_steps=1, learning_rate=3e-05, local_rank=-1, logging_steps=1, lr_decay=False, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='gpt2/s_checkpoint-1900000/', model_type='gpt2', n_gpu=1, no_cuda=False, num_train_epochs=5.0, output_dir='/content/gdrive/My Drive/gpt2-ru', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=2, save_steps=10000, save_total_limit=None, seed=42, server_ip='', server_port='', tokenizer_class='YTEncoder', tokenizer_name='bpe/yt.model', train_data_file='./dataset/train/corpus.txt', unfreeze_level=0, warmup_samples=16000, weight_decay=0.0)\n",
            "10/21/2020 09:09:16 - INFO - __main__ -   Loading features from ./dataset/train/corpus.txt\n",
            "<IPython.core.display.HTML object>\n",
            "<IPython.core.display.HTML object>\n",
            "<IPython.core.display.HTML object>\n",
            "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "10/21/2020 09:09:17 - INFO - __main__ -   ***** Running training *****\n",
            "10/21/2020 09:09:17 - INFO - __main__ -     Num examples = 366\n",
            "10/21/2020 09:09:17 - INFO - __main__ -     Num Epochs = 5\n",
            "10/21/2020 09:09:17 - INFO - __main__ -     Instantaneous batch size per GPU = 2\n",
            "10/21/2020 09:09:17 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "10/21/2020 09:09:17 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "10/21/2020 09:09:17 - INFO - __main__ -     Total optimization steps = 915\n",
            "Epoch:   0% 0/5 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/183 [00:00<?, ?it/s]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "\n",
            "Iteration:   0% 0/183 [00:01<?, ?it/s, MovingLoss=3.38, Perplexity=29.34]\u001b[A\n",
            "Iteration:   1% 1/183 [00:01<04:51,  1.60s/it, MovingLoss=3.38, Perplexity=29.34]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:146: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   1% 1/183 [00:03<04:51,  1.60s/it, MovingLoss=3.15, Perplexity=23.28]\u001b[A\n",
            "Iteration:   1% 2/183 [00:03<04:45,  1.58s/it, MovingLoss=3.15, Perplexity=23.28]\u001b[A\n",
            "Iteration:   1% 2/183 [00:04<04:45,  1.58s/it, MovingLoss=3.23, Perplexity=25.24]\u001b[A\n",
            "Iteration:   2% 3/183 [00:04<04:42,  1.57s/it, MovingLoss=3.23, Perplexity=25.24]\u001b[A\n",
            "Iteration:   2% 3/183 [00:06<04:42,  1.57s/it, MovingLoss=3.28, Perplexity=26.60]\u001b[A\n",
            "Iteration:   2% 4/183 [00:06<04:39,  1.56s/it, MovingLoss=3.28, Perplexity=26.60]\u001b[A\n",
            "Iteration:   2% 4/183 [00:07<04:39,  1.56s/it, MovingLoss=3.31, Perplexity=27.51]\u001b[A\n",
            "Iteration:   3% 5/183 [00:07<04:37,  1.56s/it, MovingLoss=3.31, Perplexity=27.51]\u001b[A\n",
            "Iteration:   3% 5/183 [00:09<04:37,  1.56s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:   3% 6/183 [00:09<04:35,  1.56s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:   3% 6/183 [00:10<04:35,  1.56s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:   4% 7/183 [00:10<04:33,  1.55s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:   4% 7/183 [00:12<04:33,  1.55s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:   4% 8/183 [00:12<04:30,  1.55s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:   4% 8/183 [00:13<04:30,  1.55s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:   5% 9/183 [00:13<04:29,  1.55s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:   5% 9/183 [00:15<04:29,  1.55s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:   5% 10/183 [00:15<04:27,  1.55s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:   5% 10/183 [00:17<04:27,  1.55s/it, MovingLoss=3.38, Perplexity=29.24]\u001b[A\n",
            "Iteration:   6% 11/183 [00:17<04:25,  1.55s/it, MovingLoss=3.38, Perplexity=29.24]\u001b[A\n",
            "Iteration:   6% 11/183 [00:18<04:25,  1.55s/it, MovingLoss=3.38, Perplexity=29.23]\u001b[A\n",
            "Iteration:   7% 12/183 [00:18<04:23,  1.54s/it, MovingLoss=3.38, Perplexity=29.23]\u001b[A\n",
            "Iteration:   7% 12/183 [00:20<04:23,  1.54s/it, MovingLoss=3.38, Perplexity=29.43]\u001b[A\n",
            "Iteration:   7% 13/183 [00:20<04:22,  1.54s/it, MovingLoss=3.38, Perplexity=29.43]\u001b[A\n",
            "Iteration:   7% 13/183 [00:21<04:22,  1.54s/it, MovingLoss=3.39, Perplexity=29.52]\u001b[A\n",
            "Iteration:   8% 14/183 [00:21<04:19,  1.54s/it, MovingLoss=3.39, Perplexity=29.52]\u001b[A\n",
            "Iteration:   8% 14/183 [00:23<04:19,  1.54s/it, MovingLoss=3.39, Perplexity=29.52]\u001b[A\n",
            "Iteration:   8% 15/183 [00:23<04:18,  1.54s/it, MovingLoss=3.39, Perplexity=29.52]\u001b[A\n",
            "Iteration:   8% 15/183 [00:24<04:18,  1.54s/it, MovingLoss=3.38, Perplexity=29.45]\u001b[A\n",
            "Iteration:   9% 16/183 [00:24<04:17,  1.54s/it, MovingLoss=3.38, Perplexity=29.45]\u001b[A\n",
            "Iteration:   9% 16/183 [00:26<04:17,  1.54s/it, MovingLoss=3.38, Perplexity=29.50]\u001b[A\n",
            "Iteration:   9% 17/183 [00:26<04:16,  1.54s/it, MovingLoss=3.38, Perplexity=29.50]\u001b[A\n",
            "Iteration:   9% 17/183 [00:27<04:16,  1.54s/it, MovingLoss=3.39, Perplexity=29.55]\u001b[A\n",
            "Iteration:  10% 18/183 [00:27<04:14,  1.54s/it, MovingLoss=3.39, Perplexity=29.55]\u001b[A\n",
            "Iteration:  10% 18/183 [00:29<04:14,  1.54s/it, MovingLoss=3.39, Perplexity=29.58]\u001b[A\n",
            "Iteration:  10% 19/183 [00:29<04:12,  1.54s/it, MovingLoss=3.39, Perplexity=29.58]\u001b[A\n",
            "Iteration:  10% 19/183 [00:30<04:12,  1.54s/it, MovingLoss=3.39, Perplexity=29.64]\u001b[A\n",
            "Iteration:  11% 20/183 [00:30<04:10,  1.54s/it, MovingLoss=3.39, Perplexity=29.64]\u001b[A\n",
            "Iteration:  11% 20/183 [00:32<04:10,  1.54s/it, MovingLoss=3.39, Perplexity=29.61]\u001b[A\n",
            "Iteration:  11% 21/183 [00:32<04:09,  1.54s/it, MovingLoss=3.39, Perplexity=29.61]\u001b[A\n",
            "Iteration:  11% 21/183 [00:33<04:09,  1.54s/it, MovingLoss=3.39, Perplexity=29.55]\u001b[A\n",
            "Iteration:  12% 22/183 [00:33<04:08,  1.54s/it, MovingLoss=3.39, Perplexity=29.55]\u001b[A\n",
            "Iteration:  12% 22/183 [00:35<04:08,  1.54s/it, MovingLoss=3.36, Perplexity=28.91]\u001b[A\n",
            "Iteration:  13% 23/183 [00:35<04:06,  1.54s/it, MovingLoss=3.36, Perplexity=28.91]\u001b[A\n",
            "Iteration:  13% 23/183 [00:37<04:06,  1.54s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  13% 24/183 [00:37<04:05,  1.54s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  13% 24/183 [00:38<04:05,  1.54s/it, MovingLoss=3.34, Perplexity=28.33]\u001b[A\n",
            "Iteration:  14% 25/183 [00:38<04:04,  1.55s/it, MovingLoss=3.34, Perplexity=28.33]\u001b[A\n",
            "Iteration:  14% 25/183 [00:40<04:04,  1.55s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  14% 26/183 [00:40<04:02,  1.55s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  14% 26/183 [00:41<04:02,  1.55s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  15% 27/183 [00:41<04:00,  1.54s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  15% 27/183 [00:43<04:00,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  15% 28/183 [00:43<03:59,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  15% 28/183 [00:44<03:59,  1.54s/it, MovingLoss=3.36, Perplexity=28.73]\u001b[A\n",
            "Iteration:  16% 29/183 [00:44<03:57,  1.54s/it, MovingLoss=3.36, Perplexity=28.73]\u001b[A\n",
            "Iteration:  16% 29/183 [00:46<03:57,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  16% 30/183 [00:46<03:56,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  16% 30/183 [00:47<03:56,  1.54s/it, MovingLoss=3.35, Perplexity=28.42]\u001b[A\n",
            "Iteration:  17% 31/183 [00:47<03:54,  1.54s/it, MovingLoss=3.35, Perplexity=28.42]\u001b[A\n",
            "Iteration:  17% 31/183 [00:49<03:54,  1.54s/it, MovingLoss=3.33, Perplexity=28.05]\u001b[A\n",
            "Iteration:  17% 32/183 [00:49<03:52,  1.54s/it, MovingLoss=3.33, Perplexity=28.05]\u001b[A\n",
            "Iteration:  17% 32/183 [00:50<03:52,  1.54s/it, MovingLoss=3.34, Perplexity=28.13]\u001b[A\n",
            "Iteration:  18% 33/183 [00:50<03:51,  1.54s/it, MovingLoss=3.34, Perplexity=28.13]\u001b[A\n",
            "Iteration:  18% 33/183 [00:52<03:51,  1.54s/it, MovingLoss=3.34, Perplexity=28.22]\u001b[A\n",
            "Iteration:  19% 34/183 [00:52<03:49,  1.54s/it, MovingLoss=3.34, Perplexity=28.22]\u001b[A\n",
            "Iteration:  19% 34/183 [00:54<03:49,  1.54s/it, MovingLoss=3.34, Perplexity=28.36]\u001b[A\n",
            "Iteration:  19% 35/183 [00:54<03:47,  1.54s/it, MovingLoss=3.34, Perplexity=28.36]\u001b[A\n",
            "Iteration:  19% 35/183 [00:55<03:47,  1.54s/it, MovingLoss=3.35, Perplexity=28.36]\u001b[A\n",
            "Iteration:  20% 36/183 [00:55<03:45,  1.54s/it, MovingLoss=3.35, Perplexity=28.36]\u001b[A\n",
            "Iteration:  20% 36/183 [00:57<03:45,  1.54s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:  20% 37/183 [00:57<03:44,  1.54s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:  20% 37/183 [00:58<03:44,  1.54s/it, MovingLoss=3.35, Perplexity=28.48]\u001b[A\n",
            "Iteration:  21% 38/183 [00:58<03:43,  1.54s/it, MovingLoss=3.35, Perplexity=28.48]\u001b[A\n",
            "Iteration:  21% 38/183 [01:00<03:43,  1.54s/it, MovingLoss=3.35, Perplexity=28.60]\u001b[A\n",
            "Iteration:  21% 39/183 [01:00<03:40,  1.53s/it, MovingLoss=3.35, Perplexity=28.60]\u001b[A\n",
            "Iteration:  21% 39/183 [01:01<03:40,  1.53s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  22% 40/183 [01:01<03:39,  1.54s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  22% 40/183 [01:03<03:39,  1.54s/it, MovingLoss=3.36, Perplexity=28.72]\u001b[A\n",
            "Iteration:  22% 41/183 [01:03<03:37,  1.53s/it, MovingLoss=3.36, Perplexity=28.72]\u001b[A\n",
            "Iteration:  22% 41/183 [01:04<03:37,  1.53s/it, MovingLoss=3.36, Perplexity=28.74]\u001b[A\n",
            "Iteration:  23% 42/183 [01:04<03:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.74]\u001b[A\n",
            "Iteration:  23% 42/183 [01:06<03:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  23% 43/183 [01:06<03:34,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  23% 43/183 [01:07<03:34,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  24% 44/183 [01:07<03:33,  1.54s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  24% 44/183 [01:09<03:33,  1.54s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  25% 45/183 [01:09<03:32,  1.54s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  25% 45/183 [01:10<03:32,  1.54s/it, MovingLoss=3.36, Perplexity=28.88]\u001b[A\n",
            "Iteration:  25% 46/183 [01:10<03:30,  1.53s/it, MovingLoss=3.36, Perplexity=28.88]\u001b[A\n",
            "Iteration:  25% 46/183 [01:12<03:30,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  26% 47/183 [01:12<03:28,  1.54s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  26% 47/183 [01:13<03:28,  1.54s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  26% 48/183 [01:13<03:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  26% 48/183 [01:15<03:26,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  27% 49/183 [01:15<03:25,  1.54s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  27% 49/183 [01:17<03:25,  1.54s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  27% 50/183 [01:17<03:24,  1.54s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  27% 50/183 [01:18<03:24,  1.54s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  28% 51/183 [01:18<03:22,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  28% 51/183 [01:20<03:22,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  28% 52/183 [01:20<03:21,  1.54s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  28% 52/183 [01:21<03:21,  1.54s/it, MovingLoss=3.36, Perplexity=28.92]\u001b[A\n",
            "Iteration:  29% 53/183 [01:21<03:19,  1.53s/it, MovingLoss=3.36, Perplexity=28.92]\u001b[A\n",
            "Iteration:  29% 53/183 [01:23<03:19,  1.53s/it, MovingLoss=3.36, Perplexity=28.91]\u001b[A\n",
            "Iteration:  30% 54/183 [01:23<03:17,  1.53s/it, MovingLoss=3.36, Perplexity=28.91]\u001b[A\n",
            "Iteration:  30% 54/183 [01:24<03:17,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  30% 55/183 [01:24<03:16,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  30% 55/183 [01:26<03:16,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  31% 56/183 [01:26<03:14,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  31% 56/183 [01:27<03:14,  1.53s/it, MovingLoss=3.36, Perplexity=28.93]\u001b[A\n",
            "Iteration:  31% 57/183 [01:27<03:13,  1.53s/it, MovingLoss=3.36, Perplexity=28.93]\u001b[A\n",
            "Iteration:  31% 57/183 [01:29<03:13,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  32% 58/183 [01:29<03:12,  1.54s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  32% 58/183 [01:30<03:12,  1.54s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  32% 59/183 [01:30<03:10,  1.54s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  32% 59/183 [01:32<03:10,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  33% 60/183 [01:32<03:09,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  33% 60/183 [01:33<03:09,  1.54s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  33% 61/183 [01:33<03:07,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  33% 61/183 [01:35<03:07,  1.53s/it, MovingLoss=3.35, Perplexity=28.57]\u001b[A\n",
            "Iteration:  34% 62/183 [01:35<03:05,  1.53s/it, MovingLoss=3.35, Perplexity=28.57]\u001b[A\n",
            "Iteration:  34% 62/183 [01:36<03:05,  1.53s/it, MovingLoss=3.35, Perplexity=28.60]\u001b[A\n",
            "Iteration:  34% 63/183 [01:36<03:03,  1.53s/it, MovingLoss=3.35, Perplexity=28.60]\u001b[A\n",
            "Iteration:  34% 63/183 [01:38<03:03,  1.53s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  35% 64/183 [01:38<03:02,  1.53s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  35% 64/183 [01:40<03:02,  1.53s/it, MovingLoss=3.36, Perplexity=28.69]\u001b[A\n",
            "Iteration:  36% 65/183 [01:40<03:00,  1.53s/it, MovingLoss=3.36, Perplexity=28.69]\u001b[A\n",
            "Iteration:  36% 65/183 [01:41<03:00,  1.53s/it, MovingLoss=3.36, Perplexity=28.75]\u001b[A\n",
            "Iteration:  36% 66/183 [01:41<02:59,  1.54s/it, MovingLoss=3.36, Perplexity=28.75]\u001b[A\n",
            "Iteration:  36% 66/183 [01:43<02:59,  1.54s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  37% 67/183 [01:43<02:58,  1.54s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  37% 67/183 [01:44<02:58,  1.54s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  37% 68/183 [01:44<02:57,  1.54s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  37% 68/183 [01:46<02:57,  1.54s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  38% 69/183 [01:46<02:55,  1.54s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  38% 69/183 [01:47<02:55,  1.54s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  38% 70/183 [01:47<02:53,  1.54s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  38% 70/183 [01:49<02:53,  1.54s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  39% 71/183 [01:49<02:52,  1.54s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  39% 71/183 [01:50<02:52,  1.54s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  39% 72/183 [01:50<02:50,  1.54s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  39% 72/183 [01:52<02:50,  1.54s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  40% 73/183 [01:52<02:48,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  40% 73/183 [01:53<02:48,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  40% 74/183 [01:53<02:47,  1.54s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  40% 74/183 [01:55<02:47,  1.54s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  41% 75/183 [01:55<02:46,  1.54s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  41% 75/183 [01:56<02:46,  1.54s/it, MovingLoss=3.36, Perplexity=28.71]\u001b[A\n",
            "Iteration:  42% 76/183 [01:56<02:44,  1.54s/it, MovingLoss=3.36, Perplexity=28.71]\u001b[A\n",
            "Iteration:  42% 76/183 [01:58<02:44,  1.54s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:  42% 77/183 [01:58<02:42,  1.54s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:  42% 77/183 [02:00<02:42,  1.54s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  43% 78/183 [02:00<02:41,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  43% 78/183 [02:01<02:41,  1.53s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  43% 79/183 [02:01<02:39,  1.54s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  43% 79/183 [02:03<02:39,  1.54s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  44% 80/183 [02:03<02:37,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  44% 80/183 [02:04<02:37,  1.53s/it, MovingLoss=3.36, Perplexity=28.89]\u001b[A\n",
            "Iteration:  44% 81/183 [02:04<02:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.89]\u001b[A\n",
            "Iteration:  44% 81/183 [02:06<02:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.92]\u001b[A\n",
            "Iteration:  45% 82/183 [02:06<02:35,  1.54s/it, MovingLoss=3.36, Perplexity=28.92]\u001b[A\n",
            "Iteration:  45% 82/183 [02:07<02:35,  1.54s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  45% 83/183 [02:07<02:33,  1.54s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  45% 83/183 [02:09<02:33,  1.54s/it, MovingLoss=3.37, Perplexity=28.98]\u001b[A\n",
            "Iteration:  46% 84/183 [02:09<02:31,  1.53s/it, MovingLoss=3.37, Perplexity=28.98]\u001b[A\n",
            "Iteration:  46% 84/183 [02:10<02:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.00]\u001b[A\n",
            "Iteration:  46% 85/183 [02:10<02:30,  1.53s/it, MovingLoss=3.37, Perplexity=29.00]\u001b[A\n",
            "Iteration:  46% 85/183 [02:12<02:30,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  47% 86/183 [02:12<02:28,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  47% 86/183 [02:13<02:28,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  48% 87/183 [02:13<02:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  48% 87/183 [02:15<02:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  48% 88/183 [02:15<02:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  48% 88/183 [02:16<02:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  49% 89/183 [02:16<02:23,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  49% 89/183 [02:18<02:23,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  49% 90/183 [02:18<02:22,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  49% 90/183 [02:19<02:22,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  50% 91/183 [02:19<02:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  50% 91/183 [02:21<02:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  50% 92/183 [02:21<02:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  50% 92/183 [02:23<02:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  51% 93/183 [02:23<02:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  51% 93/183 [02:24<02:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  51% 94/183 [02:24<02:15,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  51% 94/183 [02:26<02:15,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  52% 95/183 [02:26<02:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  52% 95/183 [02:27<02:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  52% 96/183 [02:27<02:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  52% 96/183 [02:29<02:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  53% 97/183 [02:29<02:11,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  53% 97/183 [02:30<02:11,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  54% 98/183 [02:30<02:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  54% 98/183 [02:32<02:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  54% 99/183 [02:32<02:08,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  54% 99/183 [02:33<02:08,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  55% 100/183 [02:33<02:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  55% 100/183 [02:35<02:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  55% 101/183 [02:35<02:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  55% 101/183 [02:36<02:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  56% 102/183 [02:36<02:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  56% 102/183 [02:38<02:03,  1.53s/it, MovingLoss=3.38, Perplexity=29.25]\u001b[A\n",
            "Iteration:  56% 103/183 [02:38<02:02,  1.53s/it, MovingLoss=3.38, Perplexity=29.25]\u001b[A\n",
            "Iteration:  56% 103/183 [02:39<02:02,  1.53s/it, MovingLoss=3.38, Perplexity=29.26]\u001b[A\n",
            "Iteration:  57% 104/183 [02:39<02:00,  1.53s/it, MovingLoss=3.38, Perplexity=29.26]\u001b[A\n",
            "Iteration:  57% 104/183 [02:41<02:00,  1.53s/it, MovingLoss=3.38, Perplexity=29.25]\u001b[A\n",
            "Iteration:  57% 105/183 [02:41<01:59,  1.53s/it, MovingLoss=3.38, Perplexity=29.25]\u001b[A\n",
            "Iteration:  57% 105/183 [02:42<01:59,  1.53s/it, MovingLoss=3.38, Perplexity=29.27]\u001b[A\n",
            "Iteration:  58% 106/183 [02:42<01:57,  1.53s/it, MovingLoss=3.38, Perplexity=29.27]\u001b[A\n",
            "Iteration:  58% 106/183 [02:44<01:57,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  58% 107/183 [02:44<01:56,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  58% 107/183 [02:45<01:56,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  59% 108/183 [02:45<01:55,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  59% 108/183 [02:47<01:55,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  60% 109/183 [02:47<01:53,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  60% 109/183 [02:49<01:53,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  60% 110/183 [02:49<01:51,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  60% 110/183 [02:50<01:51,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  61% 111/183 [02:50<01:49,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  61% 111/183 [02:52<01:49,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  61% 112/183 [02:52<01:48,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  61% 112/183 [02:53<01:48,  1.53s/it, MovingLoss=3.37, Perplexity=29.22]\u001b[A\n",
            "Iteration:  62% 113/183 [02:53<01:46,  1.53s/it, MovingLoss=3.37, Perplexity=29.22]\u001b[A\n",
            "Iteration:  62% 113/183 [02:55<01:46,  1.53s/it, MovingLoss=3.38, Perplexity=29.23]\u001b[A\n",
            "Iteration:  62% 114/183 [02:55<01:45,  1.53s/it, MovingLoss=3.38, Perplexity=29.23]\u001b[A\n",
            "Iteration:  62% 114/183 [02:56<01:45,  1.53s/it, MovingLoss=3.37, Perplexity=29.22]\u001b[A\n",
            "Iteration:  63% 115/183 [02:56<01:43,  1.53s/it, MovingLoss=3.37, Perplexity=29.22]\u001b[A\n",
            "Iteration:  63% 115/183 [02:58<01:43,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  63% 116/183 [02:58<01:42,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  63% 116/183 [02:59<01:42,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  64% 117/183 [02:59<01:41,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  64% 117/183 [03:01<01:41,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  64% 118/183 [03:01<01:39,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  64% 118/183 [03:02<01:39,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  65% 119/183 [03:02<01:37,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  65% 119/183 [03:04<01:37,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  66% 120/183 [03:04<01:36,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  66% 120/183 [03:05<01:36,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  66% 121/183 [03:05<01:34,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  66% 121/183 [03:07<01:34,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  67% 122/183 [03:07<01:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  67% 122/183 [03:08<01:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  67% 123/183 [03:08<01:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  67% 123/183 [03:10<01:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  68% 124/183 [03:10<01:30,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  68% 124/183 [03:11<01:30,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  68% 125/183 [03:11<01:28,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  68% 125/183 [03:13<01:28,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  69% 126/183 [03:13<01:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  69% 126/183 [03:15<01:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  69% 127/183 [03:15<01:26,  1.54s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  69% 127/183 [03:16<01:26,  1.54s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  70% 128/183 [03:16<01:24,  1.54s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  70% 128/183 [03:18<01:24,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  70% 129/183 [03:18<01:22,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  70% 129/183 [03:19<01:22,  1.54s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  71% 130/183 [03:19<01:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  71% 130/183 [03:21<01:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  72% 131/183 [03:21<01:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  72% 131/183 [03:22<01:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  72% 132/183 [03:22<01:18,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  72% 132/183 [03:24<01:18,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  73% 133/183 [03:24<01:16,  1.54s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  73% 133/183 [03:25<01:16,  1.54s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  73% 134/183 [03:25<01:15,  1.54s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  73% 134/183 [03:27<01:15,  1.54s/it, MovingLoss=3.37, Perplexity=29.22]\u001b[A\n",
            "Iteration:  74% 135/183 [03:27<01:13,  1.54s/it, MovingLoss=3.37, Perplexity=29.22]\u001b[A\n",
            "Iteration:  74% 135/183 [03:28<01:13,  1.54s/it, MovingLoss=3.38, Perplexity=29.32]\u001b[A\n",
            "Iteration:  74% 136/183 [03:28<01:12,  1.54s/it, MovingLoss=3.38, Perplexity=29.32]\u001b[A\n",
            "Iteration:  74% 136/183 [03:30<01:12,  1.54s/it, MovingLoss=3.38, Perplexity=29.32]\u001b[A\n",
            "Iteration:  75% 137/183 [03:30<01:10,  1.53s/it, MovingLoss=3.38, Perplexity=29.32]\u001b[A\n",
            "Iteration:  75% 137/183 [03:31<01:10,  1.53s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  75% 138/183 [03:31<01:09,  1.54s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  75% 138/183 [03:33<01:09,  1.54s/it, MovingLoss=3.38, Perplexity=29.26]\u001b[A\n",
            "Iteration:  76% 139/183 [03:33<01:07,  1.53s/it, MovingLoss=3.38, Perplexity=29.26]\u001b[A\n",
            "Iteration:  76% 139/183 [03:35<01:07,  1.53s/it, MovingLoss=3.38, Perplexity=29.24]\u001b[A\n",
            "Iteration:  77% 140/183 [03:35<01:06,  1.54s/it, MovingLoss=3.38, Perplexity=29.24]\u001b[A\n",
            "Iteration:  77% 140/183 [03:36<01:06,  1.54s/it, MovingLoss=3.38, Perplexity=29.25]\u001b[A\n",
            "Iteration:  77% 141/183 [03:36<01:04,  1.54s/it, MovingLoss=3.38, Perplexity=29.25]\u001b[A\n",
            "Iteration:  77% 141/183 [03:38<01:04,  1.54s/it, MovingLoss=3.38, Perplexity=29.26]\u001b[A\n",
            "Iteration:  78% 142/183 [03:38<01:02,  1.54s/it, MovingLoss=3.38, Perplexity=29.26]\u001b[A\n",
            "Iteration:  78% 142/183 [03:39<01:02,  1.54s/it, MovingLoss=3.38, Perplexity=29.25]\u001b[A\n",
            "Iteration:  78% 143/183 [03:39<01:01,  1.54s/it, MovingLoss=3.38, Perplexity=29.25]\u001b[A\n",
            "Iteration:  78% 143/183 [03:41<01:01,  1.54s/it, MovingLoss=3.38, Perplexity=29.28]\u001b[A\n",
            "Iteration:  79% 144/183 [03:41<00:59,  1.53s/it, MovingLoss=3.38, Perplexity=29.28]\u001b[A\n",
            "Iteration:  79% 144/183 [03:42<00:59,  1.53s/it, MovingLoss=3.38, Perplexity=29.31]\u001b[A\n",
            "Iteration:  79% 145/183 [03:42<00:58,  1.53s/it, MovingLoss=3.38, Perplexity=29.31]\u001b[A\n",
            "Iteration:  79% 145/183 [03:44<00:58,  1.53s/it, MovingLoss=3.38, Perplexity=29.33]\u001b[A\n",
            "Iteration:  80% 146/183 [03:44<00:56,  1.53s/it, MovingLoss=3.38, Perplexity=29.33]\u001b[A\n",
            "Iteration:  80% 146/183 [03:45<00:56,  1.53s/it, MovingLoss=3.38, Perplexity=29.34]\u001b[A\n",
            "Iteration:  80% 147/183 [03:45<00:55,  1.53s/it, MovingLoss=3.38, Perplexity=29.34]\u001b[A\n",
            "Iteration:  80% 147/183 [03:47<00:55,  1.53s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  81% 148/183 [03:47<00:53,  1.53s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  81% 148/183 [03:48<00:53,  1.53s/it, MovingLoss=3.38, Perplexity=29.38]\u001b[A\n",
            "Iteration:  81% 149/183 [03:48<00:52,  1.54s/it, MovingLoss=3.38, Perplexity=29.38]\u001b[A\n",
            "Iteration:  81% 149/183 [03:50<00:52,  1.54s/it, MovingLoss=3.38, Perplexity=29.41]\u001b[A\n",
            "Iteration:  82% 150/183 [03:50<00:50,  1.54s/it, MovingLoss=3.38, Perplexity=29.41]\u001b[A\n",
            "Iteration:  82% 150/183 [03:51<00:50,  1.54s/it, MovingLoss=3.38, Perplexity=29.43]\u001b[A\n",
            "Iteration:  83% 151/183 [03:51<00:49,  1.53s/it, MovingLoss=3.38, Perplexity=29.43]\u001b[A\n",
            "Iteration:  83% 151/183 [03:53<00:49,  1.53s/it, MovingLoss=3.38, Perplexity=29.43]\u001b[A\n",
            "Iteration:  83% 152/183 [03:53<00:47,  1.53s/it, MovingLoss=3.38, Perplexity=29.43]\u001b[A\n",
            "Iteration:  83% 152/183 [03:54<00:47,  1.53s/it, MovingLoss=3.38, Perplexity=29.45]\u001b[A\n",
            "Iteration:  84% 153/183 [03:54<00:45,  1.53s/it, MovingLoss=3.38, Perplexity=29.45]\u001b[A\n",
            "Iteration:  84% 153/183 [03:56<00:45,  1.53s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  84% 154/183 [03:56<00:44,  1.53s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  84% 154/183 [03:58<00:44,  1.53s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  85% 155/183 [03:58<00:42,  1.53s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  85% 155/183 [03:59<00:42,  1.53s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  85% 156/183 [03:59<00:41,  1.53s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  85% 156/183 [04:01<00:41,  1.53s/it, MovingLoss=3.38, Perplexity=29.37]\u001b[A\n",
            "Iteration:  86% 157/183 [04:01<00:39,  1.53s/it, MovingLoss=3.38, Perplexity=29.37]\u001b[A\n",
            "Iteration:  86% 157/183 [04:02<00:39,  1.53s/it, MovingLoss=3.38, Perplexity=29.41]\u001b[A\n",
            "Iteration:  86% 158/183 [04:02<00:38,  1.53s/it, MovingLoss=3.38, Perplexity=29.41]\u001b[A\n",
            "Iteration:  86% 158/183 [04:04<00:38,  1.53s/it, MovingLoss=3.38, Perplexity=29.40]\u001b[A\n",
            "Iteration:  87% 159/183 [04:04<00:36,  1.53s/it, MovingLoss=3.38, Perplexity=29.40]\u001b[A\n",
            "Iteration:  87% 159/183 [04:05<00:36,  1.53s/it, MovingLoss=3.38, Perplexity=29.41]\u001b[A\n",
            "Iteration:  87% 160/183 [04:05<00:35,  1.53s/it, MovingLoss=3.38, Perplexity=29.41]\u001b[A\n",
            "Iteration:  87% 160/183 [04:07<00:35,  1.53s/it, MovingLoss=3.38, Perplexity=29.41]\u001b[A\n",
            "Iteration:  88% 161/183 [04:07<00:33,  1.53s/it, MovingLoss=3.38, Perplexity=29.41]\u001b[A\n",
            "Iteration:  88% 161/183 [04:08<00:33,  1.53s/it, MovingLoss=3.38, Perplexity=29.42]\u001b[A\n",
            "Iteration:  89% 162/183 [04:08<00:32,  1.53s/it, MovingLoss=3.38, Perplexity=29.42]\u001b[A\n",
            "Iteration:  89% 162/183 [04:10<00:32,  1.53s/it, MovingLoss=3.38, Perplexity=29.44]\u001b[A\n",
            "Iteration:  89% 163/183 [04:10<00:30,  1.53s/it, MovingLoss=3.38, Perplexity=29.44]\u001b[A\n",
            "Iteration:  89% 163/183 [04:11<00:30,  1.53s/it, MovingLoss=3.38, Perplexity=29.44]\u001b[A\n",
            "Iteration:  90% 164/183 [04:11<00:29,  1.53s/it, MovingLoss=3.38, Perplexity=29.44]\u001b[A\n",
            "Iteration:  90% 164/183 [04:13<00:29,  1.53s/it, MovingLoss=3.38, Perplexity=29.34]\u001b[A\n",
            "Iteration:  90% 165/183 [04:13<00:27,  1.53s/it, MovingLoss=3.38, Perplexity=29.34]\u001b[A\n",
            "Iteration:  90% 165/183 [04:14<00:27,  1.53s/it, MovingLoss=3.38, Perplexity=29.33]\u001b[A\n",
            "Iteration:  91% 166/183 [04:14<00:26,  1.53s/it, MovingLoss=3.38, Perplexity=29.33]\u001b[A\n",
            "Iteration:  91% 166/183 [04:16<00:26,  1.53s/it, MovingLoss=3.38, Perplexity=29.34]\u001b[A\n",
            "Iteration:  91% 167/183 [04:16<00:24,  1.53s/it, MovingLoss=3.38, Perplexity=29.34]\u001b[A\n",
            "Iteration:  91% 167/183 [04:17<00:24,  1.53s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  92% 168/183 [04:17<00:22,  1.53s/it, MovingLoss=3.38, Perplexity=29.36]\u001b[A\n",
            "Iteration:  92% 168/183 [04:19<00:22,  1.53s/it, MovingLoss=3.38, Perplexity=29.37]\u001b[A\n",
            "Iteration:  92% 169/183 [04:19<00:21,  1.53s/it, MovingLoss=3.38, Perplexity=29.37]\u001b[A\n",
            "Iteration:  92% 169/183 [04:20<00:21,  1.53s/it, MovingLoss=3.38, Perplexity=29.28]\u001b[A\n",
            "Iteration:  93% 170/183 [04:20<00:19,  1.53s/it, MovingLoss=3.38, Perplexity=29.28]\u001b[A\n",
            "Iteration:  93% 170/183 [04:22<00:19,  1.53s/it, MovingLoss=3.38, Perplexity=29.29]\u001b[A\n",
            "Iteration:  93% 171/183 [04:22<00:18,  1.53s/it, MovingLoss=3.38, Perplexity=29.29]\u001b[A\n",
            "Iteration:  93% 171/183 [04:24<00:18,  1.53s/it, MovingLoss=3.38, Perplexity=29.28]\u001b[A\n",
            "Iteration:  94% 172/183 [04:24<00:16,  1.53s/it, MovingLoss=3.38, Perplexity=29.28]\u001b[A\n",
            "Iteration:  94% 172/183 [04:25<00:16,  1.53s/it, MovingLoss=3.38, Perplexity=29.27]\u001b[A\n",
            "Iteration:  95% 173/183 [04:25<00:15,  1.53s/it, MovingLoss=3.38, Perplexity=29.27]\u001b[A\n",
            "Iteration:  95% 173/183 [04:27<00:15,  1.53s/it, MovingLoss=3.38, Perplexity=29.28]\u001b[A\n",
            "Iteration:  95% 174/183 [04:27<00:13,  1.53s/it, MovingLoss=3.38, Perplexity=29.28]\u001b[A\n",
            "Iteration:  95% 174/183 [04:28<00:13,  1.53s/it, MovingLoss=3.38, Perplexity=29.29]\u001b[A\n",
            "Iteration:  96% 175/183 [04:28<00:12,  1.53s/it, MovingLoss=3.38, Perplexity=29.29]\u001b[A\n",
            "Iteration:  96% 175/183 [04:30<00:12,  1.53s/it, MovingLoss=3.38, Perplexity=29.29]\u001b[A\n",
            "Iteration:  96% 176/183 [04:30<00:10,  1.53s/it, MovingLoss=3.38, Perplexity=29.29]\u001b[A\n",
            "Iteration:  96% 176/183 [04:31<00:10,  1.53s/it, MovingLoss=3.38, Perplexity=29.30]\u001b[A\n",
            "Iteration:  97% 177/183 [04:31<00:09,  1.53s/it, MovingLoss=3.38, Perplexity=29.30]\u001b[A\n",
            "Iteration:  97% 177/183 [04:33<00:09,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  97% 178/183 [04:33<00:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  97% 178/183 [04:34<00:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  98% 179/183 [04:34<00:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  98% 179/183 [04:36<00:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.22]\u001b[A\n",
            "Iteration:  98% 180/183 [04:36<00:04,  1.53s/it, MovingLoss=3.37, Perplexity=29.22]\u001b[A\n",
            "Iteration:  98% 180/183 [04:37<00:04,  1.53s/it, MovingLoss=3.38, Perplexity=29.23]\u001b[A\n",
            "Iteration:  99% 181/183 [04:37<00:03,  1.53s/it, MovingLoss=3.38, Perplexity=29.23]\u001b[A\n",
            "Iteration:  99% 181/183 [04:39<00:03,  1.53s/it, MovingLoss=3.38, Perplexity=29.24]\u001b[A\n",
            "Iteration:  99% 182/183 [04:39<00:01,  1.53s/it, MovingLoss=3.38, Perplexity=29.24]\u001b[A\n",
            "Iteration:  99% 182/183 [04:40<00:01,  1.53s/it, MovingLoss=3.38, Perplexity=29.24]\u001b[A\n",
            "Iteration: 100% 183/183 [04:40<00:00,  1.53s/it, MovingLoss=3.38, Perplexity=29.24]\n",
            "\n",
            "  0% 0/500 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 5/500 [00:00<00:11, 43.32it/s]\u001b[A\n",
            "  2% 9/500 [00:00<00:12, 40.50it/s]\u001b[A\n",
            "  2% 12/500 [00:00<00:13, 36.03it/s]\u001b[A\n",
            "  3% 16/500 [00:00<00:14, 33.96it/s]\u001b[A\n",
            "  4% 19/500 [00:00<00:14, 32.46it/s]\u001b[A\n",
            "  4% 22/500 [00:00<00:15, 31.43it/s]\u001b[A\n",
            "  5% 25/500 [00:00<00:15, 30.67it/s]\u001b[A\n",
            "  6% 28/500 [00:00<00:15, 29.99it/s]\u001b[A\n",
            "  6% 31/500 [00:00<00:15, 29.44it/s]\u001b[A\n",
            "  7% 34/500 [00:01<00:16, 29.06it/s]\u001b[A\n",
            "  7% 37/500 [00:01<00:16, 28.80it/s]\u001b[A\n",
            "  8% 40/500 [00:01<00:16, 28.60it/s]\u001b[A\n",
            "  9% 43/500 [00:01<00:16, 28.35it/s]\u001b[A\n",
            "  9% 46/500 [00:01<00:16, 28.05it/s]\u001b[A\n",
            " 10% 49/500 [00:01<00:16, 27.91it/s]\u001b[A\n",
            " 10% 52/500 [00:01<00:16, 27.73it/s]\u001b[A\n",
            " 11% 55/500 [00:01<00:16, 27.53it/s]\u001b[A\n",
            " 12% 58/500 [00:01<00:16, 26.35it/s]\u001b[A\n",
            " 12% 61/500 [00:02<00:17, 25.53it/s]\u001b[A\n",
            " 13% 64/500 [00:02<00:17, 25.03it/s]\u001b[A\n",
            " 13% 67/500 [00:02<00:17, 24.53it/s]\u001b[A\n",
            " 14% 70/500 [00:02<00:17, 24.29it/s]\u001b[A\n",
            " 15% 73/500 [00:02<00:17, 24.07it/s]\u001b[A\n",
            " 15% 76/500 [00:02<00:17, 23.83it/s]\u001b[A\n",
            " 16% 79/500 [00:02<00:17, 23.65it/s]\u001b[A\n",
            " 16% 82/500 [00:03<00:17, 23.38it/s]\u001b[A\n",
            " 17% 85/500 [00:03<00:17, 23.28it/s]\u001b[A\n",
            " 18% 88/500 [00:03<00:17, 23.12it/s]\u001b[A\n",
            " 18% 91/500 [00:03<00:17, 22.76it/s]\u001b[A\n",
            " 19% 94/500 [00:03<00:18, 22.47it/s]\u001b[A\n",
            " 19% 97/500 [00:03<00:18, 22.23it/s]\u001b[A\n",
            " 20% 100/500 [00:03<00:18, 22.01it/s]\u001b[A\n",
            " 21% 103/500 [00:03<00:18, 21.83it/s]\u001b[A\n",
            " 21% 106/500 [00:04<00:18, 21.59it/s]\u001b[A\n",
            " 22% 109/500 [00:04<00:18, 21.51it/s]\u001b[A\n",
            " 22% 112/500 [00:04<00:18, 21.42it/s]\u001b[A\n",
            " 23% 115/500 [00:04<00:18, 21.33it/s]\u001b[A\n",
            " 24% 118/500 [00:04<00:17, 21.23it/s]\u001b[A\n",
            " 24% 121/500 [00:04<00:18, 20.61it/s]\u001b[A\n",
            " 25% 124/500 [00:04<00:18, 19.92it/s]\u001b[A\n",
            " 25% 127/500 [00:05<00:19, 19.40it/s]\u001b[A\n",
            " 26% 129/500 [00:05<00:19, 18.95it/s]\u001b[A\n",
            " 26% 131/500 [00:05<00:19, 18.65it/s]\u001b[A\n",
            " 27% 133/500 [00:05<00:19, 18.42it/s]\u001b[A\n",
            " 27% 135/500 [00:05<00:19, 18.26it/s]\u001b[A\n",
            " 27% 137/500 [00:05<00:20, 18.11it/s]\u001b[A\n",
            " 28% 139/500 [00:05<00:20, 17.99it/s]\u001b[A\n",
            " 28% 141/500 [00:05<00:20, 17.84it/s]\u001b[A\n",
            " 29% 143/500 [00:06<00:20, 17.84it/s]\u001b[A\n",
            " 29% 145/500 [00:06<00:19, 17.79it/s]\u001b[A\n",
            " 29% 147/500 [00:06<00:19, 17.69it/s]\u001b[A\n",
            " 30% 149/500 [00:06<00:19, 17.59it/s]\u001b[A\n",
            " 30% 151/500 [00:06<00:19, 17.53it/s]\u001b[A\n",
            " 31% 153/500 [00:06<00:20, 17.14it/s]\u001b[A\n",
            " 31% 155/500 [00:06<00:20, 16.86it/s]\u001b[A\n",
            " 31% 157/500 [00:06<00:20, 16.63it/s]\u001b[A\n",
            " 32% 159/500 [00:06<00:20, 16.45it/s]\u001b[A\n",
            " 32% 161/500 [00:07<00:20, 16.31it/s]\u001b[A\n",
            " 33% 163/500 [00:07<00:20, 16.19it/s]\u001b[A\n",
            " 33% 165/500 [00:07<00:20, 16.11it/s]\u001b[A\n",
            " 33% 167/500 [00:07<00:20, 16.04it/s]\u001b[A\n",
            " 34% 169/500 [00:07<00:20, 15.95it/s]\u001b[A\n",
            " 34% 171/500 [00:07<00:20, 15.88it/s]\u001b[A\n",
            " 35% 173/500 [00:07<00:20, 15.82it/s]\u001b[A\n",
            " 35% 175/500 [00:08<00:20, 15.79it/s]\u001b[A\n",
            " 35% 177/500 [00:08<00:20, 15.70it/s]\u001b[A\n",
            " 36% 179/500 [00:08<00:20, 15.63it/s]\u001b[A\n",
            " 36% 181/500 [00:08<00:20, 15.59it/s]\u001b[A\n",
            " 37% 183/500 [00:08<00:20, 15.60it/s]\u001b[A\n",
            " 37% 185/500 [00:08<00:20, 15.19it/s]\u001b[A\n",
            " 37% 187/500 [00:08<00:21, 14.87it/s]\u001b[A\n",
            " 38% 189/500 [00:08<00:21, 14.61it/s]\u001b[A\n",
            " 38% 191/500 [00:09<00:21, 14.38it/s]\u001b[A\n",
            " 39% 193/500 [00:09<00:21, 14.18it/s]\u001b[A\n",
            " 39% 195/500 [00:09<00:21, 14.08it/s]\u001b[A\n",
            " 39% 197/500 [00:09<00:21, 13.93it/s]\u001b[A\n",
            " 40% 199/500 [00:09<00:21, 13.86it/s]\u001b[A\n",
            " 40% 201/500 [00:09<00:21, 13.79it/s]\u001b[A\n",
            " 41% 203/500 [00:09<00:21, 13.76it/s]\u001b[A\n",
            " 41% 205/500 [00:10<00:21, 13.77it/s]\u001b[A\n",
            " 41% 207/500 [00:10<00:21, 13.69it/s]\u001b[A\n",
            " 42% 209/500 [00:10<00:21, 13.59it/s]\u001b[A\n",
            " 42% 211/500 [00:10<00:21, 13.56it/s]\u001b[A\n",
            " 43% 213/500 [00:10<00:21, 13.53it/s]\u001b[A\n",
            " 43% 215/500 [00:10<00:21, 13.55it/s]\u001b[A\n",
            " 43% 217/500 [00:11<00:21, 13.44it/s]\u001b[A\n",
            " 44% 219/500 [00:11<00:21, 13.32it/s]\u001b[A\n",
            " 44% 221/500 [00:11<00:21, 13.18it/s]\u001b[A\n",
            " 45% 223/500 [00:11<00:21, 13.09it/s]\u001b[A\n",
            " 45% 225/500 [00:11<00:21, 13.02it/s]\u001b[A\n",
            " 45% 227/500 [00:11<00:20, 13.01it/s]\u001b[A\n",
            " 46% 229/500 [00:11<00:20, 12.97it/s]\u001b[A\n",
            " 46% 231/500 [00:12<00:20, 12.97it/s]\u001b[A\n",
            " 47% 233/500 [00:12<00:20, 12.88it/s]\u001b[A\n",
            " 47% 235/500 [00:12<00:20, 12.82it/s]\u001b[A\n",
            " 47% 237/500 [00:12<00:20, 12.78it/s]\u001b[A\n",
            " 48% 239/500 [00:12<00:20, 12.73it/s]\u001b[A\n",
            " 48% 241/500 [00:12<00:20, 12.70it/s]\u001b[A\n",
            " 49% 243/500 [00:13<00:20, 12.71it/s]\u001b[A\n",
            " 49% 245/500 [00:13<00:20, 12.69it/s]\u001b[A\n",
            " 49% 247/500 [00:13<00:19, 12.65it/s]\u001b[A\n",
            " 50% 249/500 [00:13<00:20, 12.25it/s]\u001b[A\n",
            " 50% 251/500 [00:13<00:20, 11.97it/s]\u001b[A\n",
            " 51% 253/500 [00:13<00:21, 11.70it/s]\u001b[A\n",
            " 51% 255/500 [00:14<00:21, 11.55it/s]\u001b[A\n",
            " 51% 257/500 [00:14<00:21, 11.44it/s]\u001b[A\n",
            " 52% 259/500 [00:14<00:21, 11.35it/s]\u001b[A\n",
            " 52% 261/500 [00:14<00:21, 11.30it/s]\u001b[A\n",
            " 53% 263/500 [00:14<00:21, 11.27it/s]\u001b[A\n",
            " 53% 265/500 [00:14<00:20, 11.22it/s]\u001b[A\n",
            " 53% 267/500 [00:15<00:20, 11.18it/s]\u001b[A\n",
            " 54% 269/500 [00:15<00:20, 11.17it/s]\u001b[A\n",
            " 54% 271/500 [00:15<00:20, 11.10it/s]\u001b[A\n",
            " 55% 273/500 [00:15<00:20, 11.03it/s]\u001b[A\n",
            " 55% 275/500 [00:15<00:20, 11.03it/s]\u001b[A\n",
            " 55% 277/500 [00:16<00:20, 11.02it/s]\u001b[A\n",
            " 56% 279/500 [00:16<00:20, 11.02it/s]\u001b[A\n",
            " 56% 281/500 [00:16<00:19, 10.95it/s]\u001b[A\n",
            " 57% 283/500 [00:16<00:20, 10.76it/s]\u001b[A\n",
            " 57% 285/500 [00:16<00:20, 10.68it/s]\u001b[A\n",
            " 57% 287/500 [00:16<00:19, 10.68it/s]\u001b[A\n",
            " 58% 289/500 [00:17<00:19, 10.64it/s]\u001b[A\n",
            " 58% 291/500 [00:17<00:19, 10.59it/s]\u001b[A\n",
            " 59% 293/500 [00:17<00:19, 10.56it/s]\u001b[A\n",
            " 59% 295/500 [00:17<00:19, 10.60it/s]\u001b[A\n",
            " 59% 297/500 [00:17<00:19, 10.59it/s]\u001b[A\n",
            " 60% 299/500 [00:18<00:19, 10.56it/s]\u001b[A\n",
            " 60% 301/500 [00:18<00:19, 10.43it/s]\u001b[A\n",
            " 61% 303/500 [00:18<00:19, 10.35it/s]\u001b[A\n",
            " 61% 305/500 [00:18<00:18, 10.29it/s]\u001b[A\n",
            " 61% 307/500 [00:18<00:18, 10.29it/s]\u001b[A\n",
            " 62% 309/500 [00:19<00:18, 10.29it/s]\u001b[A\n",
            " 62% 311/500 [00:19<00:18, 10.30it/s]\u001b[A\n",
            " 63% 313/500 [00:19<00:18, 10.08it/s]\u001b[A\n",
            " 63% 315/500 [00:19<00:18,  9.92it/s]\u001b[A\n",
            " 63% 316/500 [00:19<00:18,  9.82it/s]\u001b[A\n",
            " 63% 317/500 [00:19<00:18,  9.74it/s]\u001b[A\n",
            " 64% 318/500 [00:20<00:18,  9.63it/s]\u001b[A\n",
            " 64% 319/500 [00:20<00:18,  9.54it/s]\u001b[A\n",
            " 64% 320/500 [00:20<00:18,  9.51it/s]\u001b[A\n",
            " 64% 321/500 [00:20<00:18,  9.52it/s]\u001b[A\n",
            " 64% 322/500 [00:20<00:18,  9.57it/s]\u001b[A\n",
            " 65% 323/500 [00:20<00:18,  9.60it/s]\u001b[A\n",
            " 65% 324/500 [00:20<00:18,  9.61it/s]\u001b[A\n",
            " 65% 325/500 [00:20<00:18,  9.57it/s]\u001b[A\n",
            " 65% 326/500 [00:20<00:18,  9.53it/s]\u001b[A\n",
            " 65% 327/500 [00:20<00:18,  9.53it/s]\u001b[A\n",
            " 66% 328/500 [00:21<00:18,  9.51it/s]\u001b[A\n",
            " 66% 329/500 [00:21<00:18,  9.48it/s]\u001b[A\n",
            " 66% 330/500 [00:21<00:17,  9.47it/s]\u001b[A\n",
            " 66% 331/500 [00:21<00:17,  9.45it/s]\u001b[A\n",
            " 66% 332/500 [00:21<00:17,  9.43it/s]\u001b[A\n",
            " 67% 333/500 [00:21<00:17,  9.43it/s]\u001b[A\n",
            " 67% 334/500 [00:21<00:17,  9.42it/s]\u001b[A\n",
            " 67% 335/500 [00:21<00:17,  9.41it/s]\u001b[A\n",
            " 67% 336/500 [00:21<00:17,  9.40it/s]\u001b[A\n",
            " 67% 337/500 [00:22<00:17,  9.33it/s]\u001b[A\n",
            " 68% 338/500 [00:22<00:17,  9.28it/s]\u001b[A\n",
            " 68% 339/500 [00:22<00:17,  9.28it/s]\u001b[A\n",
            " 68% 340/500 [00:22<00:17,  9.30it/s]\u001b[A\n",
            " 68% 341/500 [00:22<00:16,  9.37it/s]\u001b[A\n",
            " 68% 342/500 [00:22<00:16,  9.38it/s]\u001b[A\n",
            " 69% 343/500 [00:22<00:16,  9.38it/s]\u001b[A\n",
            " 69% 344/500 [00:22<00:16,  9.25it/s]\u001b[A\n",
            " 69% 345/500 [00:22<00:16,  9.14it/s]\u001b[A\n",
            " 69% 346/500 [00:23<00:16,  9.07it/s]\u001b[A\n",
            " 69% 347/500 [00:23<00:17,  8.98it/s]\u001b[A\n",
            " 70% 348/500 [00:23<00:17,  8.90it/s]\u001b[A\n",
            " 70% 349/500 [00:23<00:17,  8.86it/s]\u001b[A\n",
            " 70% 350/500 [00:23<00:16,  8.93it/s]\u001b[A\n",
            " 70% 351/500 [00:23<00:16,  8.97it/s]\u001b[A\n",
            " 70% 352/500 [00:23<00:16,  8.98it/s]\u001b[A\n",
            " 71% 353/500 [00:23<00:16,  8.96it/s]\u001b[A\n",
            " 71% 354/500 [00:23<00:16,  8.93it/s]\u001b[A\n",
            " 71% 355/500 [00:24<00:16,  8.91it/s]\u001b[A\n",
            " 71% 356/500 [00:24<00:16,  8.84it/s]\u001b[A\n",
            " 71% 357/500 [00:24<00:16,  8.74it/s]\u001b[A\n",
            " 72% 358/500 [00:24<00:16,  8.69it/s]\u001b[A\n",
            " 72% 359/500 [00:24<00:16,  8.75it/s]\u001b[A\n",
            " 72% 360/500 [00:24<00:15,  8.80it/s]\u001b[A\n",
            " 72% 361/500 [00:24<00:15,  8.81it/s]\u001b[A\n",
            " 72% 362/500 [00:24<00:15,  8.80it/s]\u001b[A\n",
            " 73% 363/500 [00:24<00:15,  8.80it/s]\u001b[A\n",
            " 73% 364/500 [00:25<00:15,  8.75it/s]\u001b[A\n",
            " 73% 365/500 [00:25<00:15,  8.71it/s]\u001b[A\n",
            " 73% 366/500 [00:25<00:15,  8.73it/s]\u001b[A\n",
            " 73% 367/500 [00:25<00:15,  8.74it/s]\u001b[A\n",
            " 74% 368/500 [00:25<00:15,  8.75it/s]\u001b[A\n",
            " 74% 369/500 [00:25<00:14,  8.76it/s]\u001b[A\n",
            " 74% 370/500 [00:25<00:14,  8.70it/s]\u001b[A\n",
            " 74% 371/500 [00:25<00:14,  8.61it/s]\u001b[A\n",
            " 74% 372/500 [00:25<00:14,  8.63it/s]\u001b[A\n",
            " 75% 373/500 [00:26<00:14,  8.69it/s]\u001b[A\n",
            " 75% 374/500 [00:26<00:14,  8.71it/s]\u001b[A\n",
            " 75% 375/500 [00:26<00:14,  8.73it/s]\u001b[A\n",
            " 75% 376/500 [00:26<00:14,  8.58it/s]\u001b[A\n",
            " 75% 377/500 [00:26<00:14,  8.45it/s]\u001b[A\n",
            " 76% 378/500 [00:26<00:14,  8.36it/s]\u001b[A\n",
            " 76% 379/500 [00:26<00:14,  8.35it/s]\u001b[A\n",
            " 76% 380/500 [00:26<00:14,  8.33it/s]\u001b[A\n",
            " 76% 381/500 [00:27<00:14,  8.29it/s]\u001b[A\n",
            " 76% 382/500 [00:27<00:14,  8.20it/s]\u001b[A\n",
            " 77% 383/500 [00:27<00:14,  8.18it/s]\u001b[A\n",
            " 77% 384/500 [00:27<00:14,  8.18it/s]\u001b[A\n",
            " 77% 385/500 [00:27<00:14,  8.20it/s]\u001b[A\n",
            " 77% 386/500 [00:27<00:13,  8.18it/s]\u001b[A\n",
            " 77% 387/500 [00:27<00:13,  8.15it/s]\u001b[A\n",
            " 78% 388/500 [00:27<00:13,  8.14it/s]\u001b[A\n",
            " 78% 389/500 [00:28<00:13,  8.12it/s]\u001b[A\n",
            " 78% 390/500 [00:28<00:13,  8.10it/s]\u001b[A\n",
            " 78% 391/500 [00:28<00:13,  8.06it/s]\u001b[A\n",
            " 78% 392/500 [00:28<00:13,  8.03it/s]\u001b[A\n",
            " 79% 393/500 [00:28<00:13,  8.04it/s]\u001b[A\n",
            " 79% 394/500 [00:28<00:13,  8.10it/s]\u001b[A\n",
            " 79% 395/500 [00:28<00:12,  8.09it/s]\u001b[A\n",
            " 79% 396/500 [00:28<00:12,  8.08it/s]\u001b[A\n",
            " 79% 397/500 [00:29<00:12,  8.11it/s]\u001b[A\n",
            " 80% 398/500 [00:29<00:12,  8.13it/s]\u001b[A\n",
            " 80% 399/500 [00:29<00:12,  8.08it/s]\u001b[A\n",
            " 80% 400/500 [00:29<00:12,  8.00it/s]\u001b[A\n",
            " 80% 401/500 [00:29<00:12,  8.03it/s]\u001b[A\n",
            " 80% 402/500 [00:29<00:12,  8.09it/s]\u001b[A\n",
            " 81% 403/500 [00:29<00:11,  8.10it/s]\u001b[A\n",
            " 81% 404/500 [00:29<00:11,  8.01it/s]\u001b[A\n",
            " 81% 405/500 [00:30<00:11,  7.99it/s]\u001b[A\n",
            " 81% 406/500 [00:30<00:11,  8.02it/s]\u001b[A\n",
            " 81% 407/500 [00:30<00:11,  8.07it/s]\u001b[A\n",
            " 82% 408/500 [00:30<00:11,  7.90it/s]\u001b[A\n",
            " 82% 409/500 [00:30<00:11,  7.86it/s]\u001b[A\n",
            " 82% 410/500 [00:30<00:11,  7.83it/s]\u001b[A\n",
            " 82% 411/500 [00:30<00:11,  7.76it/s]\u001b[A\n",
            " 82% 412/500 [00:30<00:11,  7.72it/s]\u001b[A\n",
            " 83% 413/500 [00:31<00:11,  7.72it/s]\u001b[A\n",
            " 83% 414/500 [00:31<00:11,  7.68it/s]\u001b[A\n",
            " 83% 415/500 [00:31<00:11,  7.65it/s]\u001b[A\n",
            " 83% 416/500 [00:31<00:10,  7.64it/s]\u001b[A\n",
            " 83% 417/500 [00:31<00:10,  7.67it/s]\u001b[A\n",
            " 84% 418/500 [00:31<00:10,  7.60it/s]\u001b[A\n",
            " 84% 419/500 [00:31<00:10,  7.56it/s]\u001b[A\n",
            " 84% 420/500 [00:31<00:10,  7.55it/s]\u001b[A\n",
            " 84% 421/500 [00:32<00:10,  7.51it/s]\u001b[A\n",
            " 84% 422/500 [00:32<00:10,  7.49it/s]\u001b[A\n",
            " 85% 423/500 [00:32<00:10,  7.55it/s]\u001b[A\n",
            " 85% 424/500 [00:32<00:10,  7.50it/s]\u001b[A\n",
            " 85% 425/500 [00:32<00:10,  7.50it/s]\u001b[A\n",
            " 85% 426/500 [00:32<00:09,  7.49it/s]\u001b[A\n",
            " 85% 427/500 [00:32<00:09,  7.45it/s]\u001b[A\n",
            " 86% 428/500 [00:33<00:09,  7.47it/s]\u001b[A\n",
            " 86% 429/500 [00:33<00:09,  7.47it/s]\u001b[A\n",
            " 86% 430/500 [00:33<00:09,  7.44it/s]\u001b[A\n",
            " 86% 431/500 [00:33<00:09,  7.45it/s]\u001b[A\n",
            " 86% 432/500 [00:33<00:09,  7.50it/s]\u001b[A\n",
            " 87% 433/500 [00:33<00:09,  7.44it/s]\u001b[A\n",
            " 87% 434/500 [00:33<00:08,  7.44it/s]\u001b[A\n",
            " 87% 435/500 [00:33<00:08,  7.44it/s]\u001b[A\n",
            " 87% 436/500 [00:34<00:08,  7.42it/s]\u001b[A\n",
            " 87% 437/500 [00:34<00:08,  7.40it/s]\u001b[A\n",
            " 88% 438/500 [00:34<00:08,  7.40it/s]\u001b[A\n",
            " 88% 439/500 [00:34<00:08,  7.42it/s]\u001b[A\n",
            " 88% 440/500 [00:34<00:08,  7.33it/s]\u001b[A\n",
            " 88% 441/500 [00:34<00:08,  7.27it/s]\u001b[A\n",
            " 88% 442/500 [00:34<00:08,  7.22it/s]\u001b[A\n",
            " 89% 443/500 [00:35<00:07,  7.18it/s]\u001b[A\n",
            " 89% 444/500 [00:35<00:07,  7.13it/s]\u001b[A\n",
            " 89% 445/500 [00:35<00:07,  7.12it/s]\u001b[A\n",
            " 89% 446/500 [00:35<00:07,  7.12it/s]\u001b[A\n",
            " 89% 447/500 [00:35<00:07,  7.14it/s]\u001b[A\n",
            " 90% 448/500 [00:35<00:07,  7.13it/s]\u001b[A\n",
            " 90% 449/500 [00:35<00:07,  7.08it/s]\u001b[A\n",
            " 90% 450/500 [00:36<00:07,  7.08it/s]\u001b[A\n",
            " 90% 451/500 [00:36<00:06,  7.08it/s]\u001b[A\n",
            " 90% 452/500 [00:36<00:06,  7.11it/s]\u001b[A\n",
            " 91% 453/500 [00:36<00:06,  7.11it/s]\u001b[A\n",
            " 91% 454/500 [00:36<00:06,  7.07it/s]\u001b[A\n",
            " 91% 455/500 [00:36<00:06,  7.08it/s]\u001b[A\n",
            " 91% 456/500 [00:36<00:06,  7.07it/s]\u001b[A\n",
            " 91% 457/500 [00:37<00:06,  7.11it/s]\u001b[A\n",
            " 92% 458/500 [00:37<00:05,  7.09it/s]\u001b[A\n",
            " 92% 459/500 [00:37<00:05,  7.04it/s]\u001b[A\n",
            " 92% 460/500 [00:37<00:05,  7.00it/s]\u001b[A\n",
            " 92% 461/500 [00:37<00:05,  6.98it/s]\u001b[A\n",
            " 92% 462/500 [00:37<00:05,  6.99it/s]\u001b[A\n",
            " 93% 463/500 [00:37<00:05,  7.01it/s]\u001b[A\n",
            " 93% 464/500 [00:38<00:05,  7.00it/s]\u001b[A\n",
            " 93% 465/500 [00:38<00:05,  6.99it/s]\u001b[A\n",
            " 93% 466/500 [00:38<00:04,  6.96it/s]\u001b[A\n",
            " 93% 467/500 [00:38<00:04,  6.94it/s]\u001b[A\n",
            " 94% 468/500 [00:38<00:04,  6.95it/s]\u001b[A\n",
            " 94% 469/500 [00:38<00:04,  7.00it/s]\u001b[A\n",
            " 94% 470/500 [00:38<00:04,  7.00it/s]\u001b[A\n",
            " 94% 471/500 [00:39<00:04,  7.00it/s]\u001b[A\n",
            " 94% 472/500 [00:39<00:04,  6.91it/s]\u001b[A\n",
            " 95% 473/500 [00:39<00:03,  6.82it/s]\u001b[A\n",
            " 95% 474/500 [00:39<00:03,  6.77it/s]\u001b[A\n",
            " 95% 475/500 [00:39<00:03,  6.75it/s]\u001b[A\n",
            " 95% 476/500 [00:39<00:03,  6.72it/s]\u001b[A\n",
            " 95% 477/500 [00:39<00:03,  6.69it/s]\u001b[A\n",
            " 96% 478/500 [00:40<00:03,  6.69it/s]\u001b[A\n",
            " 96% 479/500 [00:40<00:03,  6.67it/s]\u001b[A\n",
            " 96% 480/500 [00:40<00:02,  6.67it/s]\u001b[A\n",
            " 96% 481/500 [00:40<00:02,  6.65it/s]\u001b[A\n",
            " 96% 482/500 [00:40<00:02,  6.65it/s]\u001b[A\n",
            " 97% 483/500 [00:40<00:02,  6.66it/s]\u001b[A\n",
            " 97% 484/500 [00:41<00:02,  6.66it/s]\u001b[A\n",
            " 97% 485/500 [00:41<00:02,  6.64it/s]\u001b[A\n",
            " 97% 486/500 [00:41<00:02,  6.64it/s]\u001b[A\n",
            " 97% 487/500 [00:41<00:01,  6.63it/s]\u001b[A\n",
            " 98% 488/500 [00:41<00:01,  6.63it/s]\u001b[A\n",
            " 98% 489/500 [00:41<00:01,  6.60it/s]\u001b[A\n",
            " 98% 490/500 [00:41<00:01,  6.61it/s]\u001b[A\n",
            " 98% 491/500 [00:42<00:01,  6.62it/s]\u001b[A\n",
            " 98% 492/500 [00:42<00:01,  6.62it/s]\u001b[A\n",
            " 99% 493/500 [00:42<00:01,  6.62it/s]\u001b[A\n",
            " 99% 494/500 [00:42<00:00,  6.63it/s]\u001b[A\n",
            " 99% 495/500 [00:42<00:00,  6.63it/s]\u001b[A\n",
            " 99% 496/500 [00:42<00:00,  6.62it/s]\u001b[A\n",
            " 99% 497/500 [00:42<00:00,  6.62it/s]\u001b[A\n",
            "100% 498/500 [00:43<00:00,  6.61it/s]\u001b[A\n",
            "100% 499/500 [00:43<00:00,  6.61it/s]\u001b[A\n",
            "100% 500/500 [00:43<00:00, 11.51it/s]\n",
            "  Будьте практичны. Этот день может положить начало длительному исследованию на траверзе моря, и это даст надежду на приближение бога к океану. Нам с мамой казалось, что этого может не произойти. А если так, то что может случиться, если мы столкнемся с чем?\n",
            "\n",
            "Марино сверилась с записями.\n",
            "\n",
            "—  В лагере нет флагов, — сообщила она.\n",
            "\n",
            "—  И много воды на горизонте? — спросила Холли.\n",
            "\n",
            "—  Понятия не имею. Возможно, совсем немного. Ветер снова меняется.\n",
            "\n",
            "—  А почему бы нам не поплыть обратно в лагерь?\n",
            "\n",
            "Марино покачала головой:\n",
            "\n",
            "—  Вы должны мне помочь. Я вижу, что вы здесь трудитесь, что вы не можете уехать без меня.\n",
            "\n",
            "Но Марино засомневалась в этом:\n",
            "\n",
            "—  Нет, я остаюсь с вами, чтобы помочь вам.\n",
            "\n",
            "Она взглянула на Кито, который стоял на шкафуте и присматривал за шлангами.\n",
            "\n",
            "—  Мне все равно, что с вами будет, — наконец сказала Марино, — если я пойду в лагерь.\n",
            "\n",
            "Кито кивнул.\n",
            "\n",
            "—  Спасибо. Очень признателен, — тихо сказал он.\n",
            "\n",
            "—  Если вы разрешите мне остаться с вами, я соглашусь на работу, — ответила Марино и побежала наверх, чтобы Кито не видел ее в таком состоянии.\n",
            "\n",
            "Она взяла такси и направилась к дому.\n",
            "\n",
            "—  Я должна сделать наброски, — сказала она ему. — Помогу вам и перережу ленточку при каждой вспышке. — Она отвернулась от Кито, наблюдавшего за ней. — Но можно пойти мне на выручку. Вы все будете рядом.\n",
            "\n",
            "Он ничего не ответил.\n",
            "\n",
            "Они стояли на кухне и пытались придумать какой-нибудь план, который выведет их из этого кошмара. Кито не понимал, что же она задумала. Но у него были веские основания считать, что ей удастся заставить его снова встретиться с Лизой. Марино кивнула ему, и он вместе с ней спустился в кухню.\n",
            "\n",
            "—  Я собираюсь повесить на шкафт знак «Сирены». Я знаю, как это делают, — сказала Марино.\n",
            "\n",
            "—  Она мертва, — сказал Кито.\n",
            "\n",
            "Он и вправду это знал.\n",
            "\n",
            "—  Она мертва? — спросил он, подходя к раковине и вытирая руки полотенцем.\n",
            "\n",
            "—  Я не знаю, — ответила Марино, — но, кажется, что-то нечисто.\n",
            "\n",
            "Она наклонила над раковиной зеркало, провела им по раковине и нахмурилась от нахлынувшего воспоминания. Она долго смотрела в зеркало на мертвого человека, и теперь его очертания стали совсем призрачными.\n",
            "\n",
            "—  Я помню, что видела его, — сказала Марино.\n",
            "\n",
            "Она снова подняла на него взгляд.\n",
            "\n",
            "—  Как вы думаете, что это было? — спросила она.\n",
            "\n",
            "Он наклонился\n",
            "Epoch:  20% 1/5 [05:24<21:37, 324.34s/it]\n",
            "Iteration:   0% 0/183 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 0/183 [00:01<?, ?it/s, MovingLoss=3.38, Perplexity=29.25]\u001b[A\n",
            "Iteration:   1% 1/183 [00:01<04:36,  1.52s/it, MovingLoss=3.38, Perplexity=29.25]\u001b[A\n",
            "Iteration:   1% 1/183 [00:03<04:36,  1.52s/it, MovingLoss=3.38, Perplexity=29.24]\u001b[A\n",
            "Iteration:   1% 2/183 [00:03<04:35,  1.52s/it, MovingLoss=3.38, Perplexity=29.24]\u001b[A\n",
            "Iteration:   1% 2/183 [00:04<04:35,  1.52s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   2% 3/183 [00:04<04:34,  1.52s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   2% 3/183 [00:06<04:34,  1.52s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   2% 4/183 [00:06<04:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   2% 4/183 [00:07<04:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:   3% 5/183 [00:07<04:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:   3% 5/183 [00:09<04:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:   3% 6/183 [00:09<04:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:   3% 6/183 [00:10<04:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:   4% 7/183 [00:10<04:29,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:   4% 7/183 [00:12<04:29,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:   4% 8/183 [00:12<04:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:   4% 8/183 [00:13<04:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:   5% 9/183 [00:13<04:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:   5% 9/183 [00:15<04:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:   5% 10/183 [00:15<04:24,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:   5% 10/183 [00:16<04:24,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:   6% 11/183 [00:16<04:23,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:   6% 11/183 [00:18<04:23,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:   7% 12/183 [00:18<04:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:   7% 12/183 [00:19<04:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:   7% 13/183 [00:19<04:20,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:   7% 13/183 [00:21<04:20,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:   8% 14/183 [00:21<04:18,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:   8% 14/183 [00:22<04:18,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:   8% 15/183 [00:22<04:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:   8% 15/183 [00:24<04:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:   9% 16/183 [00:24<04:15,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:   9% 16/183 [00:26<04:15,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:   9% 17/183 [00:26<04:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:   9% 17/183 [00:27<04:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  10% 18/183 [00:27<04:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  10% 18/183 [00:29<04:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  10% 19/183 [00:29<04:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  10% 19/183 [00:30<04:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  11% 20/183 [00:30<04:09,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  11% 20/183 [00:32<04:09,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  11% 21/183 [00:32<04:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  11% 21/183 [00:33<04:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  12% 22/183 [00:33<04:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  12% 22/183 [00:35<04:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  13% 23/183 [00:35<04:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  13% 23/183 [00:36<04:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  13% 24/183 [00:36<04:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  13% 24/183 [00:38<04:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  14% 25/183 [00:38<04:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  14% 25/183 [00:39<04:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  14% 26/183 [00:39<04:00,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  14% 26/183 [00:41<04:00,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  15% 27/183 [00:41<03:58,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  15% 27/183 [00:42<03:58,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  15% 28/183 [00:42<03:56,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  15% 28/183 [00:44<03:56,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  16% 29/183 [00:44<03:55,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  16% 29/183 [00:45<03:55,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  16% 30/183 [00:45<03:54,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  16% 30/183 [00:47<03:54,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  17% 31/183 [00:47<03:52,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  17% 31/183 [00:48<03:52,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  17% 32/183 [00:48<03:51,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  17% 32/183 [00:50<03:51,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  18% 33/183 [00:50<03:49,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  18% 33/183 [00:51<03:49,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  19% 34/183 [00:51<03:47,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  19% 34/183 [00:53<03:47,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  19% 35/183 [00:53<03:46,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  19% 35/183 [00:55<03:46,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  20% 36/183 [00:55<03:44,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  20% 36/183 [00:56<03:44,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  20% 37/183 [00:56<03:43,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  20% 37/183 [00:58<03:43,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  21% 38/183 [00:58<03:41,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  21% 38/183 [00:59<03:41,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  21% 39/183 [00:59<03:40,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  21% 39/183 [01:01<03:40,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  22% 40/183 [01:01<03:39,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  22% 40/183 [01:02<03:39,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  22% 41/183 [01:02<03:37,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  22% 41/183 [01:04<03:37,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  23% 42/183 [01:04<03:35,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  23% 42/183 [01:05<03:35,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  23% 43/183 [01:05<03:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  23% 43/183 [01:07<03:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  24% 44/183 [01:07<03:32,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  24% 44/183 [01:08<03:32,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  25% 45/183 [01:08<03:30,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  25% 45/183 [01:10<03:30,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  25% 46/183 [01:10<03:29,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  25% 46/183 [01:11<03:29,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  26% 47/183 [01:11<03:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  26% 47/183 [01:13<03:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  26% 48/183 [01:13<03:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  26% 48/183 [01:14<03:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  27% 49/183 [01:14<03:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  27% 49/183 [01:16<03:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  27% 50/183 [01:16<03:24,  1.54s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  27% 50/183 [01:18<03:24,  1.54s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  28% 51/183 [01:18<03:23,  1.54s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  28% 51/183 [01:19<03:23,  1.54s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  28% 52/183 [01:19<03:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  28% 52/183 [01:21<03:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  29% 53/183 [01:21<03:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  29% 53/183 [01:22<03:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  30% 54/183 [01:22<03:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  30% 54/183 [01:24<03:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  30% 55/183 [01:24<03:16,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  30% 55/183 [01:25<03:16,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  31% 56/183 [01:25<03:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  31% 56/183 [01:27<03:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  31% 57/183 [01:27<03:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  31% 57/183 [01:28<03:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  32% 58/183 [01:28<03:12,  1.54s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  32% 58/183 [01:30<03:12,  1.54s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  32% 59/183 [01:30<03:10,  1.54s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  32% 59/183 [01:31<03:10,  1.54s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  33% 60/183 [01:31<03:09,  1.54s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  33% 60/183 [01:33<03:09,  1.54s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  33% 61/183 [01:33<03:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  33% 61/183 [01:34<03:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  34% 62/183 [01:34<03:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  34% 62/183 [01:36<03:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  34% 63/183 [01:36<03:04,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  34% 63/183 [01:37<03:04,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  35% 64/183 [01:37<03:02,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  35% 64/183 [01:39<03:02,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  36% 65/183 [01:39<03:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  36% 65/183 [01:41<03:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  36% 66/183 [01:41<02:59,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  36% 66/183 [01:42<02:59,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  37% 67/183 [01:42<02:58,  1.54s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  37% 67/183 [01:44<02:58,  1.54s/it, MovingLoss=3.37, Perplexity=28.98]\u001b[A\n",
            "Iteration:  37% 68/183 [01:44<02:56,  1.53s/it, MovingLoss=3.37, Perplexity=28.98]\u001b[A\n",
            "Iteration:  37% 68/183 [01:45<02:56,  1.53s/it, MovingLoss=3.37, Perplexity=28.99]\u001b[A\n",
            "Iteration:  38% 69/183 [01:45<02:54,  1.53s/it, MovingLoss=3.37, Perplexity=28.99]\u001b[A\n",
            "Iteration:  38% 69/183 [01:47<02:54,  1.53s/it, MovingLoss=3.37, Perplexity=29.00]\u001b[A\n",
            "Iteration:  38% 70/183 [01:47<02:53,  1.53s/it, MovingLoss=3.37, Perplexity=29.00]\u001b[A\n",
            "Iteration:  38% 70/183 [01:48<02:53,  1.53s/it, MovingLoss=3.37, Perplexity=28.98]\u001b[A\n",
            "Iteration:  39% 71/183 [01:48<02:51,  1.53s/it, MovingLoss=3.37, Perplexity=28.98]\u001b[A\n",
            "Iteration:  39% 71/183 [01:50<02:51,  1.53s/it, MovingLoss=3.36, Perplexity=28.92]\u001b[A\n",
            "Iteration:  39% 72/183 [01:50<02:50,  1.53s/it, MovingLoss=3.36, Perplexity=28.92]\u001b[A\n",
            "Iteration:  39% 72/183 [01:51<02:50,  1.53s/it, MovingLoss=3.36, Perplexity=28.92]\u001b[A\n",
            "Iteration:  40% 73/183 [01:51<02:48,  1.54s/it, MovingLoss=3.36, Perplexity=28.92]\u001b[A\n",
            "Iteration:  40% 73/183 [01:53<02:48,  1.54s/it, MovingLoss=3.36, Perplexity=28.92]\u001b[A\n",
            "Iteration:  40% 74/183 [01:53<02:47,  1.54s/it, MovingLoss=3.36, Perplexity=28.92]\u001b[A\n",
            "Iteration:  40% 74/183 [01:54<02:47,  1.54s/it, MovingLoss=3.36, Perplexity=28.93]\u001b[A\n",
            "Iteration:  41% 75/183 [01:54<02:45,  1.54s/it, MovingLoss=3.36, Perplexity=28.93]\u001b[A\n",
            "Iteration:  41% 75/183 [01:56<02:45,  1.54s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  42% 76/183 [01:56<02:44,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  42% 76/183 [01:57<02:44,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  42% 77/183 [01:57<02:42,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[AGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "\n",
            "Iteration:  42% 77/183 [01:59<02:42,  1.53s/it, MovingLoss=3.37, Perplexity=28.99]\u001b[A\n",
            "Iteration:  43% 78/183 [01:59<02:40,  1.53s/it, MovingLoss=3.37, Perplexity=28.99]\u001b[A\n",
            "Iteration:  43% 78/183 [02:00<02:40,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  43% 79/183 [02:00<02:38,  1.52s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  43% 79/183 [02:02<02:38,  1.52s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  44% 80/183 [02:02<02:37,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  44% 80/183 [02:04<02:37,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  44% 81/183 [02:04<02:35,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  44% 81/183 [02:05<02:35,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  45% 82/183 [02:05<02:34,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  45% 82/183 [02:07<02:34,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  45% 83/183 [02:07<02:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  45% 83/183 [02:08<02:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  46% 84/183 [02:08<02:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  46% 84/183 [02:10<02:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  46% 85/183 [02:10<02:29,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  46% 85/183 [02:11<02:29,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  47% 86/183 [02:11<02:28,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  47% 86/183 [02:13<02:28,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  48% 87/183 [02:13<02:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  48% 87/183 [02:14<02:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  48% 88/183 [02:14<02:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  48% 88/183 [02:16<02:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  49% 89/183 [02:16<02:23,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  49% 89/183 [02:17<02:23,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  49% 90/183 [02:17<02:22,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  49% 90/183 [02:19<02:22,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  50% 91/183 [02:19<02:20,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  50% 91/183 [02:20<02:20,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  50% 92/183 [02:20<02:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  50% 92/183 [02:22<02:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  51% 93/183 [02:22<02:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  51% 93/183 [02:23<02:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  51% 94/183 [02:23<02:15,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  51% 94/183 [02:25<02:15,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  52% 95/183 [02:25<02:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  52% 95/183 [02:26<02:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  52% 96/183 [02:26<02:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  52% 96/183 [02:28<02:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  53% 97/183 [02:28<02:11,  1.52s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  53% 97/183 [02:30<02:11,  1.52s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  54% 98/183 [02:30<02:09,  1.53s/it, MovingLoss=3.37, Perplexity=29.09]\u001b[A\n",
            "Iteration:  54% 98/183 [02:31<02:09,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  54% 99/183 [02:31<02:08,  1.53s/it, MovingLoss=3.37, Perplexity=29.10]\u001b[A\n",
            "Iteration:  54% 99/183 [02:33<02:08,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  55% 100/183 [02:33<02:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  55% 100/183 [02:34<02:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  55% 101/183 [02:34<02:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  55% 101/183 [02:36<02:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  56% 102/183 [02:36<02:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  56% 102/183 [02:37<02:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  56% 103/183 [02:37<02:02,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  56% 103/183 [02:39<02:02,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  57% 104/183 [02:39<02:00,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  57% 104/183 [02:40<02:00,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  57% 105/183 [02:40<01:59,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  57% 105/183 [02:42<01:59,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  58% 106/183 [02:42<01:57,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  58% 106/183 [02:43<01:57,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  58% 107/183 [02:43<01:56,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  58% 107/183 [02:45<01:56,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  59% 108/183 [02:45<01:54,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  59% 108/183 [02:46<01:54,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  60% 109/183 [02:46<01:53,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  60% 109/183 [02:48<01:53,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  60% 110/183 [02:48<01:51,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  60% 110/183 [02:49<01:51,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  61% 111/183 [02:49<01:50,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  61% 111/183 [02:51<01:50,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  61% 112/183 [02:51<01:48,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  61% 112/183 [02:52<01:48,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  62% 113/183 [02:52<01:47,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  62% 113/183 [02:54<01:47,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  62% 114/183 [02:54<01:45,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  62% 114/183 [02:55<01:45,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  63% 115/183 [02:55<01:43,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  63% 115/183 [02:57<01:43,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  63% 116/183 [02:57<01:42,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  63% 116/183 [02:59<01:42,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  64% 117/183 [02:59<01:40,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  64% 117/183 [03:00<01:40,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  64% 118/183 [03:00<01:39,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  64% 118/183 [03:02<01:39,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  65% 119/183 [03:02<01:38,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  65% 119/183 [03:03<01:38,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  66% 120/183 [03:03<01:36,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  66% 120/183 [03:05<01:36,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  66% 121/183 [03:05<01:34,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  66% 121/183 [03:06<01:34,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  67% 122/183 [03:06<01:32,  1.52s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  67% 122/183 [03:08<01:32,  1.52s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  67% 123/183 [03:08<01:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  67% 123/183 [03:09<01:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  68% 124/183 [03:09<01:29,  1.52s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  68% 124/183 [03:11<01:29,  1.52s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  68% 125/183 [03:11<01:28,  1.52s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  68% 125/183 [03:12<01:28,  1.52s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  69% 126/183 [03:12<01:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  69% 126/183 [03:14<01:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  69% 127/183 [03:14<01:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  69% 127/183 [03:15<01:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  70% 128/183 [03:15<01:24,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  70% 128/183 [03:17<01:24,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  70% 129/183 [03:17<01:22,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  70% 129/183 [03:18<01:22,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  71% 130/183 [03:18<01:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  71% 130/183 [03:20<01:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  72% 131/183 [03:20<01:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  72% 131/183 [03:21<01:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  72% 132/183 [03:21<01:18,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  72% 132/183 [03:23<01:18,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  73% 133/183 [03:23<01:16,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  73% 133/183 [03:25<01:16,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  73% 134/183 [03:25<01:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  73% 134/183 [03:26<01:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  74% 135/183 [03:26<01:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  74% 135/183 [03:28<01:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  74% 136/183 [03:28<01:11,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  74% 136/183 [03:29<01:11,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  75% 137/183 [03:29<01:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  75% 137/183 [03:31<01:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  75% 138/183 [03:31<01:08,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  75% 138/183 [03:32<01:08,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  76% 139/183 [03:32<01:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  76% 139/183 [03:34<01:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  77% 140/183 [03:34<01:06,  1.54s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  77% 140/183 [03:35<01:06,  1.54s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  77% 141/183 [03:35<01:04,  1.54s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  77% 141/183 [03:37<01:04,  1.54s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  78% 142/183 [03:37<01:02,  1.54s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  78% 142/183 [03:38<01:02,  1.54s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  78% 143/183 [03:38<01:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  78% 143/183 [03:40<01:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  79% 144/183 [03:40<00:59,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  79% 144/183 [03:41<00:59,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  79% 145/183 [03:41<00:58,  1.54s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  79% 145/183 [03:43<00:58,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  80% 146/183 [03:43<00:56,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  80% 146/183 [03:44<00:56,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  80% 147/183 [03:44<00:55,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  80% 147/183 [03:46<00:55,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  81% 148/183 [03:46<00:53,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  81% 148/183 [03:48<00:53,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  81% 149/183 [03:48<00:52,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  81% 149/183 [03:49<00:52,  1.54s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  82% 150/183 [03:49<00:50,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  82% 150/183 [03:51<00:50,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  83% 151/183 [03:51<00:49,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  83% 151/183 [03:52<00:49,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  83% 152/183 [03:52<00:47,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  83% 152/183 [03:54<00:47,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  84% 153/183 [03:54<00:45,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  84% 153/183 [03:55<00:45,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  84% 154/183 [03:55<00:44,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  84% 154/183 [03:57<00:44,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  85% 155/183 [03:57<00:42,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  85% 155/183 [03:58<00:42,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  85% 156/183 [03:58<00:41,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  85% 156/183 [04:00<00:41,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  86% 157/183 [04:00<00:39,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  86% 157/183 [04:01<00:39,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  86% 158/183 [04:01<00:38,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  86% 158/183 [04:03<00:38,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  87% 159/183 [04:03<00:36,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  87% 159/183 [04:04<00:36,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  87% 160/183 [04:04<00:35,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  87% 160/183 [04:06<00:35,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  88% 161/183 [04:06<00:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  88% 161/183 [04:07<00:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  89% 162/183 [04:07<00:32,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  89% 162/183 [04:09<00:32,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  89% 163/183 [04:09<00:30,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  89% 163/183 [04:11<00:30,  1.53s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  90% 164/183 [04:11<00:29,  1.54s/it, MovingLoss=3.37, Perplexity=29.21]\u001b[A\n",
            "Iteration:  90% 164/183 [04:12<00:29,  1.54s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  90% 165/183 [04:12<00:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  90% 165/183 [04:14<00:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  91% 166/183 [04:14<00:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  91% 166/183 [04:15<00:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  91% 167/183 [04:15<00:24,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  91% 167/183 [04:17<00:24,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  92% 168/183 [04:17<00:22,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  92% 168/183 [04:18<00:22,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  92% 169/183 [04:18<00:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  92% 169/183 [04:20<00:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  93% 170/183 [04:20<00:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  93% 170/183 [04:21<00:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  93% 171/183 [04:21<00:18,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  93% 171/183 [04:23<00:18,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  94% 172/183 [04:23<00:16,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  94% 172/183 [04:24<00:16,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  95% 173/183 [04:24<00:15,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  95% 173/183 [04:26<00:15,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  95% 174/183 [04:26<00:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  95% 174/183 [04:27<00:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  96% 175/183 [04:27<00:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  96% 175/183 [04:29<00:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  96% 176/183 [04:29<00:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  96% 176/183 [04:30<00:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  97% 177/183 [04:30<00:09,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  97% 177/183 [04:32<00:09,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  97% 178/183 [04:32<00:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  97% 178/183 [04:33<00:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  98% 179/183 [04:33<00:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  98% 179/183 [04:35<00:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  98% 180/183 [04:35<00:04,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  98% 180/183 [04:37<00:04,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  99% 181/183 [04:37<00:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  99% 181/183 [04:38<00:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  99% 182/183 [04:38<00:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  99% 182/183 [04:40<00:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration: 100% 183/183 [04:40<00:00,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\n",
            "\n",
            "  0% 0/500 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 5/500 [00:00<00:11, 44.88it/s]\u001b[A\n",
            "  2% 9/500 [00:00<00:11, 41.42it/s]\u001b[A\n",
            "  3% 13/500 [00:00<00:13, 37.20it/s]\u001b[A\n",
            "  3% 16/500 [00:00<00:14, 34.47it/s]\u001b[A\n",
            "  4% 19/500 [00:00<00:14, 32.88it/s]\u001b[A\n",
            "  4% 22/500 [00:00<00:15, 31.74it/s]\u001b[A\n",
            "  5% 25/500 [00:00<00:15, 30.90it/s]\u001b[A\n",
            "  6% 28/500 [00:00<00:15, 30.21it/s]\u001b[A\n",
            "  6% 31/500 [00:00<00:15, 29.69it/s]\u001b[A\n",
            "  7% 34/500 [00:01<00:15, 29.17it/s]\u001b[A\n",
            "  7% 37/500 [00:01<00:16, 28.84it/s]\u001b[A\n",
            "  8% 40/500 [00:01<00:16, 28.60it/s]\u001b[A\n",
            "  9% 43/500 [00:01<00:16, 28.37it/s]\u001b[A\n",
            "  9% 46/500 [00:01<00:16, 28.16it/s]\u001b[A\n",
            " 10% 49/500 [00:01<00:16, 27.95it/s]\u001b[A\n",
            " 10% 52/500 [00:01<00:16, 27.75it/s]\u001b[A\n",
            " 11% 55/500 [00:01<00:16, 27.53it/s]\u001b[A\n",
            " 12% 58/500 [00:01<00:16, 26.40it/s]\u001b[A\n",
            " 12% 61/500 [00:02<00:17, 25.67it/s]\u001b[A\n",
            " 13% 64/500 [00:02<00:17, 25.04it/s]\u001b[A\n",
            " 13% 67/500 [00:02<00:17, 24.59it/s]\u001b[A\n",
            " 14% 70/500 [00:02<00:17, 24.24it/s]\u001b[A\n",
            " 15% 73/500 [00:02<00:17, 24.03it/s]\u001b[A\n",
            " 15% 76/500 [00:02<00:17, 23.84it/s]\u001b[A\n",
            " 16% 79/500 [00:02<00:17, 23.69it/s]\u001b[A\n",
            " 16% 82/500 [00:02<00:17, 23.51it/s]\u001b[A\n",
            " 17% 85/500 [00:03<00:17, 23.41it/s]\u001b[A\n",
            " 18% 88/500 [00:03<00:17, 23.17it/s]\u001b[A\n",
            " 18% 91/500 [00:03<00:17, 22.76it/s]\u001b[A\n",
            " 19% 94/500 [00:03<00:18, 22.48it/s]\u001b[A\n",
            " 19% 97/500 [00:03<00:18, 22.27it/s]\u001b[A\n",
            " 20% 100/500 [00:03<00:18, 22.09it/s]\u001b[A\n",
            " 21% 103/500 [00:03<00:18, 21.96it/s]\u001b[A\n",
            " 21% 106/500 [00:04<00:18, 21.81it/s]\u001b[A\n",
            " 22% 109/500 [00:04<00:18, 21.64it/s]\u001b[A\n",
            " 22% 112/500 [00:04<00:18, 21.50it/s]\u001b[A\n",
            " 23% 115/500 [00:04<00:18, 21.35it/s]\u001b[A\n",
            " 24% 118/500 [00:04<00:18, 21.00it/s]\u001b[A\n",
            " 24% 121/500 [00:04<00:18, 20.36it/s]\u001b[A\n",
            " 25% 124/500 [00:04<00:19, 19.72it/s]\u001b[A\n",
            " 25% 126/500 [00:05<00:19, 19.32it/s]\u001b[A\n",
            " 26% 128/500 [00:05<00:19, 19.00it/s]\u001b[A\n",
            " 26% 130/500 [00:05<00:19, 18.72it/s]\u001b[A\n",
            " 26% 132/500 [00:05<00:19, 18.46it/s]\u001b[A\n",
            " 27% 134/500 [00:05<00:20, 18.28it/s]\u001b[A\n",
            " 27% 136/500 [00:05<00:20, 18.11it/s]\u001b[A\n",
            " 28% 138/500 [00:05<00:20, 17.99it/s]\u001b[A\n",
            " 28% 140/500 [00:05<00:20, 17.92it/s]\u001b[A\n",
            " 28% 142/500 [00:05<00:20, 17.82it/s]\u001b[A\n",
            " 29% 144/500 [00:06<00:20, 17.79it/s]\u001b[A\n",
            " 29% 146/500 [00:06<00:19, 17.77it/s]\u001b[A\n",
            " 30% 148/500 [00:06<00:19, 17.66it/s]\u001b[A\n",
            " 30% 150/500 [00:06<00:19, 17.58it/s]\u001b[A\n",
            " 30% 152/500 [00:06<00:20, 17.37it/s]\u001b[A\n",
            " 31% 154/500 [00:06<00:20, 16.99it/s]\u001b[A\n",
            " 31% 156/500 [00:06<00:20, 16.71it/s]\u001b[A\n",
            " 32% 158/500 [00:06<00:20, 16.50it/s]\u001b[A\n",
            " 32% 160/500 [00:07<00:20, 16.32it/s]\u001b[A\n",
            " 32% 162/500 [00:07<00:20, 16.21it/s]\u001b[A\n",
            " 33% 164/500 [00:07<00:20, 16.13it/s]\u001b[A\n",
            " 33% 166/500 [00:07<00:20, 16.08it/s]\u001b[A\n",
            " 34% 168/500 [00:07<00:20, 16.03it/s]\u001b[A\n",
            " 34% 170/500 [00:07<00:20, 15.90it/s]\u001b[A\n",
            " 34% 172/500 [00:07<00:20, 15.84it/s]\u001b[A\n",
            " 35% 174/500 [00:07<00:20, 15.79it/s]\u001b[A\n",
            " 35% 176/500 [00:08<00:20, 15.72it/s]\u001b[A\n",
            " 36% 178/500 [00:08<00:20, 15.66it/s]\u001b[A\n",
            " 36% 180/500 [00:08<00:20, 15.63it/s]\u001b[A\n",
            " 36% 182/500 [00:08<00:20, 15.59it/s]\u001b[A\n",
            " 37% 184/500 [00:08<00:20, 15.38it/s]\u001b[A\n",
            " 37% 186/500 [00:08<00:20, 14.97it/s]\u001b[A\n",
            " 38% 188/500 [00:08<00:21, 14.65it/s]\u001b[A\n",
            " 38% 190/500 [00:09<00:21, 14.44it/s]\u001b[A\n",
            " 38% 192/500 [00:09<00:21, 14.27it/s]\u001b[A\n",
            " 39% 194/500 [00:09<00:21, 14.13it/s]\u001b[A\n",
            " 39% 196/500 [00:09<00:21, 14.02it/s]\u001b[A\n",
            " 40% 198/500 [00:09<00:21, 13.96it/s]\u001b[A\n",
            " 40% 200/500 [00:09<00:21, 13.88it/s]\u001b[A\n",
            " 40% 202/500 [00:09<00:21, 13.80it/s]\u001b[A\n",
            " 41% 204/500 [00:10<00:21, 13.75it/s]\u001b[A\n",
            " 41% 206/500 [00:10<00:21, 13.66it/s]\u001b[A\n",
            " 42% 208/500 [00:10<00:21, 13.63it/s]\u001b[A\n",
            " 42% 210/500 [00:10<00:21, 13.64it/s]\u001b[A\n",
            " 42% 212/500 [00:10<00:21, 13.65it/s]\u001b[A\n",
            " 43% 214/500 [00:10<00:21, 13.60it/s]\u001b[A\n",
            " 43% 216/500 [00:10<00:20, 13.53it/s]\u001b[A\n",
            " 44% 218/500 [00:11<00:21, 13.39it/s]\u001b[A\n",
            " 44% 220/500 [00:11<00:21, 13.30it/s]\u001b[A\n",
            " 44% 222/500 [00:11<00:21, 13.16it/s]\u001b[A\n",
            " 45% 224/500 [00:11<00:21, 13.07it/s]\u001b[A\n",
            " 45% 226/500 [00:11<00:21, 12.92it/s]\u001b[A\n",
            " 46% 228/500 [00:11<00:21, 12.89it/s]\u001b[A\n",
            " 46% 230/500 [00:12<00:20, 12.92it/s]\u001b[A\n",
            " 46% 232/500 [00:12<00:20, 12.93it/s]\u001b[A\n",
            " 47% 234/500 [00:12<00:20, 12.90it/s]\u001b[A\n",
            " 47% 236/500 [00:12<00:20, 12.83it/s]\u001b[A\n",
            " 48% 238/500 [00:12<00:20, 12.79it/s]\u001b[A\n",
            " 48% 240/500 [00:12<00:20, 12.77it/s]\u001b[A\n",
            " 48% 242/500 [00:12<00:20, 12.73it/s]\u001b[A\n",
            " 49% 244/500 [00:13<00:20, 12.67it/s]\u001b[A\n",
            " 49% 246/500 [00:13<00:20, 12.62it/s]\u001b[A\n",
            " 50% 248/500 [00:13<00:20, 12.42it/s]\u001b[A\n",
            " 50% 250/500 [00:13<00:20, 12.07it/s]\u001b[A\n",
            " 50% 252/500 [00:13<00:20, 11.83it/s]\u001b[A\n",
            " 51% 254/500 [00:13<00:21, 11.63it/s]\u001b[A\n",
            " 51% 256/500 [00:14<00:21, 11.52it/s]\u001b[A\n",
            " 52% 258/500 [00:14<00:21, 11.36it/s]\u001b[A\n",
            " 52% 260/500 [00:14<00:21, 11.27it/s]\u001b[A\n",
            " 52% 262/500 [00:14<00:21, 11.25it/s]\u001b[A\n",
            " 53% 264/500 [00:14<00:20, 11.25it/s]\u001b[A\n",
            " 53% 266/500 [00:15<00:20, 11.17it/s]\u001b[A\n",
            " 54% 268/500 [00:15<00:20, 11.09it/s]\u001b[A\n",
            " 54% 270/500 [00:15<00:20, 11.06it/s]\u001b[A\n",
            " 54% 272/500 [00:15<00:20, 11.08it/s]\u001b[A\n",
            " 55% 274/500 [00:15<00:20, 11.10it/s]\u001b[A\n",
            " 55% 276/500 [00:15<00:20, 11.02it/s]\u001b[A\n",
            " 56% 278/500 [00:16<00:20, 10.95it/s]\u001b[A\n",
            " 56% 280/500 [00:16<00:20, 10.89it/s]\u001b[A\n",
            " 56% 282/500 [00:16<00:20, 10.85it/s]\u001b[A\n",
            " 57% 284/500 [00:16<00:19, 10.81it/s]\u001b[A\n",
            " 57% 286/500 [00:16<00:19, 10.77it/s]\u001b[A\n",
            " 58% 288/500 [00:17<00:19, 10.75it/s]\u001b[A\n",
            " 58% 290/500 [00:17<00:19, 10.62it/s]\u001b[A\n",
            " 58% 292/500 [00:17<00:19, 10.51it/s]\u001b[A\n",
            " 59% 294/500 [00:17<00:19, 10.43it/s]\u001b[A\n",
            " 59% 296/500 [00:17<00:19, 10.44it/s]\u001b[A\n",
            " 60% 298/500 [00:18<00:19, 10.43it/s]\u001b[A\n",
            " 60% 300/500 [00:18<00:19, 10.40it/s]\u001b[A\n",
            " 60% 302/500 [00:18<00:19, 10.38it/s]\u001b[A\n",
            " 61% 304/500 [00:18<00:18, 10.36it/s]\u001b[A\n",
            " 61% 306/500 [00:18<00:18, 10.35it/s]\u001b[A\n",
            " 62% 308/500 [00:19<00:18, 10.39it/s]\u001b[A\n",
            " 62% 310/500 [00:19<00:18, 10.41it/s]\u001b[A\n",
            " 62% 312/500 [00:19<00:18, 10.33it/s]\u001b[A\n",
            " 63% 314/500 [00:19<00:18, 10.15it/s]\u001b[A\n",
            " 63% 316/500 [00:19<00:18,  9.97it/s]\u001b[A\n",
            " 63% 317/500 [00:19<00:18,  9.84it/s]\u001b[A\n",
            " 64% 318/500 [00:20<00:18,  9.73it/s]\u001b[A\n",
            " 64% 319/500 [00:20<00:18,  9.67it/s]\u001b[A\n",
            " 64% 320/500 [00:20<00:18,  9.62it/s]\u001b[A\n",
            " 64% 321/500 [00:20<00:18,  9.58it/s]\u001b[A\n",
            " 64% 322/500 [00:20<00:18,  9.55it/s]\u001b[A\n",
            " 65% 323/500 [00:20<00:18,  9.53it/s]\u001b[A\n",
            " 65% 324/500 [00:20<00:18,  9.51it/s]\u001b[A\n",
            " 65% 325/500 [00:20<00:18,  9.49it/s]\u001b[A\n",
            " 65% 326/500 [00:20<00:18,  9.49it/s]\u001b[A\n",
            " 65% 327/500 [00:20<00:18,  9.49it/s]\u001b[A\n",
            " 66% 328/500 [00:21<00:18,  9.46it/s]\u001b[A\n",
            " 66% 329/500 [00:21<00:18,  9.44it/s]\u001b[A\n",
            " 66% 330/500 [00:21<00:18,  9.38it/s]\u001b[A\n",
            " 66% 331/500 [00:21<00:18,  9.33it/s]\u001b[A\n",
            " 66% 332/500 [00:21<00:18,  9.31it/s]\u001b[A\n",
            " 67% 333/500 [00:21<00:17,  9.34it/s]\u001b[A\n",
            " 67% 334/500 [00:21<00:17,  9.39it/s]\u001b[A\n",
            " 67% 335/500 [00:21<00:17,  9.43it/s]\u001b[A\n",
            " 67% 336/500 [00:21<00:17,  9.45it/s]\u001b[A\n",
            " 67% 337/500 [00:22<00:17,  9.42it/s]\u001b[A\n",
            " 68% 338/500 [00:22<00:17,  9.39it/s]\u001b[A\n",
            " 68% 339/500 [00:22<00:17,  9.37it/s]\u001b[A\n",
            " 68% 340/500 [00:22<00:17,  9.35it/s]\u001b[A\n",
            " 68% 341/500 [00:22<00:17,  9.33it/s]\u001b[A\n",
            " 68% 342/500 [00:22<00:16,  9.30it/s]\u001b[A\n",
            " 69% 343/500 [00:22<00:16,  9.32it/s]\u001b[A\n",
            " 69% 344/500 [00:22<00:16,  9.21it/s]\u001b[A\n",
            " 69% 345/500 [00:22<00:17,  9.06it/s]\u001b[A\n",
            " 69% 346/500 [00:23<00:17,  8.98it/s]\u001b[A\n",
            " 69% 347/500 [00:23<00:17,  8.95it/s]\u001b[A\n",
            " 70% 348/500 [00:23<00:16,  8.98it/s]\u001b[A\n",
            " 70% 349/500 [00:23<00:16,  9.00it/s]\u001b[A\n",
            " 70% 350/500 [00:23<00:16,  8.99it/s]\u001b[A\n",
            " 70% 351/500 [00:23<00:16,  8.97it/s]\u001b[A\n",
            " 70% 352/500 [00:23<00:16,  8.89it/s]\u001b[A\n",
            " 71% 353/500 [00:23<00:16,  8.84it/s]\u001b[A\n",
            " 71% 354/500 [00:23<00:16,  8.80it/s]\u001b[A\n",
            " 71% 355/500 [00:24<00:16,  8.78it/s]\u001b[A\n",
            " 71% 356/500 [00:24<00:16,  8.79it/s]\u001b[A\n",
            " 71% 357/500 [00:24<00:16,  8.79it/s]\u001b[A\n",
            " 72% 358/500 [00:24<00:16,  8.81it/s]\u001b[A\n",
            " 72% 359/500 [00:24<00:15,  8.83it/s]\u001b[A\n",
            " 72% 360/500 [00:24<00:15,  8.82it/s]\u001b[A\n",
            " 72% 361/500 [00:24<00:15,  8.75it/s]\u001b[A\n",
            " 72% 362/500 [00:24<00:15,  8.73it/s]\u001b[A\n",
            " 73% 363/500 [00:24<00:15,  8.75it/s]\u001b[A\n",
            " 73% 364/500 [00:25<00:15,  8.75it/s]\u001b[A\n",
            " 73% 365/500 [00:25<00:15,  8.74it/s]\u001b[A\n",
            " 73% 366/500 [00:25<00:15,  8.74it/s]\u001b[A\n",
            " 73% 367/500 [00:25<00:15,  8.70it/s]\u001b[A\n",
            " 74% 368/500 [00:25<00:15,  8.67it/s]\u001b[A\n",
            " 74% 369/500 [00:25<00:15,  8.70it/s]\u001b[A\n",
            " 74% 370/500 [00:25<00:14,  8.74it/s]\u001b[A\n",
            " 74% 371/500 [00:25<00:14,  8.75it/s]\u001b[A\n",
            " 74% 372/500 [00:25<00:14,  8.74it/s]\u001b[A\n",
            " 75% 373/500 [00:26<00:14,  8.73it/s]\u001b[A\n",
            " 75% 374/500 [00:26<00:14,  8.67it/s]\u001b[A\n",
            " 75% 375/500 [00:26<00:14,  8.60it/s]\u001b[A\n",
            " 75% 376/500 [00:26<00:14,  8.52it/s]\u001b[A\n",
            " 75% 377/500 [00:26<00:14,  8.47it/s]\u001b[A\n",
            " 76% 378/500 [00:26<00:14,  8.44it/s]\u001b[A\n",
            " 76% 379/500 [00:26<00:14,  8.36it/s]\u001b[A\n",
            " 76% 380/500 [00:26<00:14,  8.25it/s]\u001b[A\n",
            " 76% 381/500 [00:27<00:14,  8.19it/s]\u001b[A\n",
            " 76% 382/500 [00:27<00:14,  8.17it/s]\u001b[A\n",
            " 77% 383/500 [00:27<00:14,  8.21it/s]\u001b[A\n",
            " 77% 384/500 [00:27<00:14,  8.19it/s]\u001b[A\n",
            " 77% 385/500 [00:27<00:14,  8.17it/s]\u001b[A\n",
            " 77% 386/500 [00:27<00:13,  8.19it/s]\u001b[A\n",
            " 77% 387/500 [00:27<00:13,  8.21it/s]\u001b[A\n",
            " 78% 388/500 [00:27<00:13,  8.18it/s]\u001b[A\n",
            " 78% 389/500 [00:28<00:13,  8.12it/s]\u001b[A\n",
            " 78% 390/500 [00:28<00:13,  8.16it/s]\u001b[A\n",
            " 78% 391/500 [00:28<00:13,  8.20it/s]\u001b[A\n",
            " 78% 392/500 [00:28<00:13,  8.17it/s]\u001b[A\n",
            " 79% 393/500 [00:28<00:13,  8.10it/s]\u001b[A\n",
            " 79% 394/500 [00:28<00:13,  8.05it/s]\u001b[A\n",
            " 79% 395/500 [00:28<00:13,  8.03it/s]\u001b[A\n",
            " 79% 396/500 [00:28<00:12,  8.04it/s]\u001b[A\n",
            " 79% 397/500 [00:29<00:12,  8.08it/s]\u001b[A\n",
            " 80% 398/500 [00:29<00:12,  8.06it/s]\u001b[A\n",
            " 80% 399/500 [00:29<00:12,  8.08it/s]\u001b[A\n",
            " 80% 400/500 [00:29<00:12,  8.11it/s]\u001b[A\n",
            " 80% 401/500 [00:29<00:12,  8.08it/s]\u001b[A\n",
            " 80% 402/500 [00:29<00:12,  8.00it/s]\u001b[A\n",
            " 81% 403/500 [00:29<00:12,  7.98it/s]\u001b[A\n",
            " 81% 404/500 [00:29<00:12,  8.00it/s]\u001b[A\n",
            " 81% 405/500 [00:30<00:11,  8.04it/s]\u001b[A\n",
            " 81% 406/500 [00:30<00:11,  7.97it/s]\u001b[A\n",
            " 81% 407/500 [00:30<00:11,  7.97it/s]\u001b[A\n",
            " 82% 408/500 [00:30<00:11,  7.88it/s]\u001b[A\n",
            " 82% 409/500 [00:30<00:11,  7.84it/s]\u001b[A\n",
            " 82% 410/500 [00:30<00:11,  7.77it/s]\u001b[A\n",
            " 82% 411/500 [00:30<00:11,  7.70it/s]\u001b[A\n",
            " 82% 412/500 [00:30<00:11,  7.66it/s]\u001b[A\n",
            " 83% 413/500 [00:31<00:11,  7.62it/s]\u001b[A\n",
            " 83% 414/500 [00:31<00:11,  7.65it/s]\u001b[A\n",
            " 83% 415/500 [00:31<00:11,  7.64it/s]\u001b[A\n",
            " 83% 416/500 [00:31<00:11,  7.58it/s]\u001b[A\n",
            " 83% 417/500 [00:31<00:10,  7.55it/s]\u001b[A\n",
            " 84% 418/500 [00:31<00:10,  7.55it/s]\u001b[A\n",
            " 84% 419/500 [00:31<00:10,  7.59it/s]\u001b[A\n",
            " 84% 420/500 [00:31<00:10,  7.62it/s]\u001b[A\n",
            " 84% 421/500 [00:32<00:10,  7.61it/s]\u001b[A\n",
            " 84% 422/500 [00:32<00:10,  7.56it/s]\u001b[A\n",
            " 85% 423/500 [00:32<00:10,  7.52it/s]\u001b[A\n",
            " 85% 424/500 [00:32<00:10,  7.55it/s]\u001b[A\n",
            " 85% 425/500 [00:32<00:09,  7.55it/s]\u001b[A\n",
            " 85% 426/500 [00:32<00:09,  7.53it/s]\u001b[A\n",
            " 85% 427/500 [00:32<00:09,  7.51it/s]\u001b[A\n",
            " 86% 428/500 [00:33<00:09,  7.51it/s]\u001b[A\n",
            " 86% 429/500 [00:33<00:09,  7.50it/s]\u001b[A\n",
            " 86% 430/500 [00:33<00:09,  7.53it/s]\u001b[A\n",
            " 86% 431/500 [00:33<00:09,  7.51it/s]\u001b[A\n",
            " 86% 432/500 [00:33<00:09,  7.50it/s]\u001b[A\n",
            " 87% 433/500 [00:33<00:08,  7.53it/s]\u001b[A\n",
            " 87% 434/500 [00:33<00:08,  7.51it/s]\u001b[A\n",
            " 87% 435/500 [00:33<00:08,  7.46it/s]\u001b[A\n",
            " 87% 436/500 [00:34<00:08,  7.45it/s]\u001b[A\n",
            " 87% 437/500 [00:34<00:08,  7.49it/s]\u001b[A\n",
            " 88% 438/500 [00:34<00:08,  7.47it/s]\u001b[A\n",
            " 88% 439/500 [00:34<00:08,  7.48it/s]\u001b[A\n",
            " 88% 440/500 [00:34<00:08,  7.37it/s]\u001b[A\n",
            " 88% 441/500 [00:34<00:08,  7.30it/s]\u001b[A\n",
            " 88% 442/500 [00:34<00:08,  7.25it/s]\u001b[A\n",
            " 89% 443/500 [00:35<00:07,  7.18it/s]\u001b[A\n",
            " 89% 444/500 [00:35<00:07,  7.15it/s]\u001b[A\n",
            " 89% 445/500 [00:35<00:07,  7.14it/s]\u001b[A\n",
            " 89% 446/500 [00:35<00:07,  7.11it/s]\u001b[A\n",
            " 89% 447/500 [00:35<00:07,  7.09it/s]\u001b[A\n",
            " 90% 448/500 [00:35<00:07,  7.05it/s]\u001b[A\n",
            " 90% 449/500 [00:35<00:07,  7.03it/s]\u001b[A\n",
            " 90% 450/500 [00:36<00:07,  7.03it/s]\u001b[A\n",
            " 90% 451/500 [00:36<00:06,  7.09it/s]\u001b[A\n",
            " 90% 452/500 [00:36<00:06,  7.09it/s]\u001b[A\n",
            " 91% 453/500 [00:36<00:06,  7.05it/s]\u001b[A\n",
            " 91% 454/500 [00:36<00:06,  7.03it/s]\u001b[A\n",
            " 91% 455/500 [00:36<00:06,  7.05it/s]\u001b[A\n",
            " 91% 456/500 [00:36<00:06,  7.05it/s]\u001b[A\n",
            " 91% 457/500 [00:37<00:06,  7.04it/s]\u001b[A\n",
            " 92% 458/500 [00:37<00:05,  7.04it/s]\u001b[A\n",
            " 92% 459/500 [00:37<00:05,  7.03it/s]\u001b[A\n",
            " 92% 460/500 [00:37<00:05,  7.00it/s]\u001b[A\n",
            " 92% 461/500 [00:37<00:05,  6.98it/s]\u001b[A\n",
            " 92% 462/500 [00:37<00:05,  6.98it/s]\u001b[A\n",
            " 93% 463/500 [00:37<00:05,  7.00it/s]\u001b[A\n",
            " 93% 464/500 [00:38<00:05,  6.99it/s]\u001b[A\n",
            " 93% 465/500 [00:38<00:05,  6.96it/s]\u001b[A\n",
            " 93% 466/500 [00:38<00:04,  6.95it/s]\u001b[A\n",
            " 93% 467/500 [00:38<00:04,  6.92it/s]\u001b[A\n",
            " 94% 468/500 [00:38<00:04,  6.91it/s]\u001b[A\n",
            " 94% 469/500 [00:38<00:04,  6.93it/s]\u001b[A\n",
            " 94% 470/500 [00:38<00:04,  6.94it/s]\u001b[A\n",
            " 94% 471/500 [00:39<00:04,  6.95it/s]\u001b[A\n",
            " 94% 472/500 [00:39<00:04,  6.88it/s]\u001b[A\n",
            " 95% 473/500 [00:39<00:03,  6.83it/s]\u001b[A\n",
            " 95% 474/500 [00:39<00:03,  6.80it/s]\u001b[A\n",
            " 95% 475/500 [00:39<00:03,  6.77it/s]\u001b[A\n",
            " 95% 476/500 [00:39<00:03,  6.73it/s]\u001b[A\n",
            " 95% 477/500 [00:39<00:03,  6.70it/s]\u001b[A\n",
            " 96% 478/500 [00:40<00:03,  6.68it/s]\u001b[A\n",
            " 96% 479/500 [00:40<00:03,  6.68it/s]\u001b[A\n",
            " 96% 480/500 [00:40<00:03,  6.65it/s]\u001b[A\n",
            " 96% 481/500 [00:40<00:02,  6.66it/s]\u001b[A\n",
            " 96% 482/500 [00:40<00:02,  6.64it/s]\u001b[A\n",
            " 97% 483/500 [00:40<00:02,  6.65it/s]\u001b[A\n",
            " 97% 484/500 [00:41<00:02,  6.63it/s]\u001b[A\n",
            " 97% 485/500 [00:41<00:02,  6.63it/s]\u001b[A\n",
            " 97% 486/500 [00:41<00:02,  6.63it/s]\u001b[A\n",
            " 97% 487/500 [00:41<00:01,  6.64it/s]\u001b[A\n",
            " 98% 488/500 [00:41<00:01,  6.61it/s]\u001b[A\n",
            " 98% 489/500 [00:41<00:01,  6.62it/s]\u001b[A\n",
            " 98% 490/500 [00:41<00:01,  6.60it/s]\u001b[A\n",
            " 98% 491/500 [00:42<00:01,  6.61it/s]\u001b[A\n",
            " 98% 492/500 [00:42<00:01,  6.62it/s]\u001b[A\n",
            " 99% 493/500 [00:42<00:01,  6.62it/s]\u001b[A\n",
            " 99% 494/500 [00:42<00:00,  6.60it/s]\u001b[A\n",
            " 99% 495/500 [00:42<00:00,  6.60it/s]\u001b[A\n",
            " 99% 496/500 [00:42<00:00,  6.60it/s]\u001b[A\n",
            " 99% 497/500 [00:42<00:00,  6.60it/s]\u001b[A\n",
            "100% 498/500 [00:43<00:00,  6.61it/s]\u001b[A\n",
            "100% 499/500 [00:43<00:00,  6.61it/s]\u001b[A\n",
            "100% 500/500 [00:43<00:00, 11.51it/s]\n",
            "  Будьте практичны. Этот день может положить начало длительному периоду развития. И верно, когда он примет оны меру, будет опять делать свое дело. Увидимся с тобой на этом месте; другое время нам предстоит еще окончить совершенствование человеческого разума для соединения всей вселенской мудрости с христианской, а это требует не менее необходимого опыта. Не забудем об отце, он также знает и о себе и о нас, – тогда мы начнем, наверное, рассматривать его как на своем пути к знанию истины, который оставляет после себя наследие для будущих веков.\n",
            "\n",
            "По мере того как я живу в этом маленьком уединенном мирке, я получаю все более от материальную помощь, и теперь я могу снабдить ее целыми лесами, которыми мы с нею славим ее. Мысль о ней – в сто раз сильнее, чем в строении духа и разума. Сколько еще будет при мне, сколько времени придется ей отращивать и шить, сколько накопится за годы жизни и какое внутреннее чувство будет проявляться у нее ко мне, когда наконец я оставлю меня одного?\n",
            "\n",
            "Я забыл сказать тебе еще что-то, так как работа многих отшельников этого ума не должна остаться в стороне, а переходить на службу к другой по крайней мере кажется ненужным; здесь существуют разные шаманы и мастера, называемые шаманами поколения. Они живут вместе с ближними и разными народами, находящимися на том же пути; но они уже в состоянии почтить память этого учителя после того, как он умер. Как отмечал Марк Аврелий, в бытность мою учеником священника его ученик вступил на путь свободы и уже отошел от всяких учений, чтобы посвятить себя своему учению. Но если бы тебе хотелось знать, что говорит мой отец, то запомни, что он всегда говорил то, что хотел, но что внушал нам. Когда его учение подверглось разрушению и исчез последний остаток философии, о которой он нас вдохновлял, так что господствующей истине нечего больше сказать, и все духи из прошлого ушли из нашего ума и создали мир с человеком, которого считали его святым, – тогда каждый понял бы свою ошибку. Однако теперь он сказал нам, что он не может сам развить свой разум, если не подчинится его авторитетам, и именно его нужно назвать хранителем старых верований в религии Отца-Отца. У него не остается людей, и даже мысли его теперь принадлежит народу. Также не осталось имени другого хранителя истины, который мог бы исполнить труд нашего великого учителя – отца наших учений. Без сомнения, он тоже будет иметь семью, и мы уверены, что многие люди этого народа принесут ему много пользы. Мы всегда будем его почитать, как единственного, кто может преподавать истины и помогает людям обходиться без постоянного поклонения. А твой отец, твой брат, твои братья, все должны нам\n",
            "Epoch:  40% 2/5 [10:47<16:12, 324.11s/it]\n",
            "Iteration:   0% 0/183 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 0/183 [00:01<?, ?it/s, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:   1% 1/183 [00:01<04:37,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:   1% 1/183 [00:03<04:37,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:   1% 2/183 [00:03<04:37,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:   1% 2/183 [00:04<04:37,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   2% 3/183 [00:04<04:35,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   2% 3/183 [00:06<04:35,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   2% 4/183 [00:06<04:34,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   2% 4/183 [00:07<04:34,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:   3% 5/183 [00:07<04:32,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:   3% 5/183 [00:09<04:32,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:   3% 6/183 [00:09<04:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:   3% 6/183 [00:10<04:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:   4% 7/183 [00:10<04:29,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:   4% 7/183 [00:12<04:29,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:   4% 8/183 [00:12<04:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:   4% 8/183 [00:13<04:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:   5% 9/183 [00:13<04:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:   5% 9/183 [00:15<04:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:   5% 10/183 [00:15<04:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:   5% 10/183 [00:16<04:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   6% 11/183 [00:16<04:24,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   6% 11/183 [00:18<04:24,  1.54s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   7% 12/183 [00:18<04:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   7% 12/183 [00:19<04:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   7% 13/183 [00:19<04:20,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   7% 13/183 [00:21<04:20,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:   8% 14/183 [00:21<04:18,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:   8% 14/183 [00:22<04:18,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   8% 15/183 [00:22<04:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   8% 15/183 [00:24<04:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   9% 16/183 [00:24<04:15,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:   9% 16/183 [00:26<04:15,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:   9% 17/183 [00:26<04:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:   9% 17/183 [00:27<04:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  10% 18/183 [00:27<04:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  10% 18/183 [00:29<04:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  10% 19/183 [00:29<04:11,  1.54s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  10% 19/183 [00:30<04:11,  1.54s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  11% 20/183 [00:30<04:09,  1.53s/it, MovingLoss=3.37, Perplexity=29.17]\u001b[A\n",
            "Iteration:  11% 20/183 [00:32<04:09,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  11% 21/183 [00:32<04:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  11% 21/183 [00:33<04:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  12% 22/183 [00:33<04:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  12% 22/183 [00:35<04:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  13% 23/183 [00:35<04:04,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  13% 23/183 [00:36<04:04,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  13% 24/183 [00:36<04:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  13% 24/183 [00:38<04:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  14% 25/183 [00:38<04:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  14% 25/183 [00:39<04:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  14% 26/183 [00:39<04:00,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  14% 26/183 [00:41<04:00,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  15% 27/183 [00:41<03:59,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  15% 27/183 [00:42<03:59,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  15% 28/183 [00:42<03:57,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  15% 28/183 [00:44<03:57,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  16% 29/183 [00:44<03:55,  1.53s/it, MovingLoss=3.37, Perplexity=29.18]\u001b[A\n",
            "Iteration:  16% 29/183 [00:45<03:55,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  16% 30/183 [00:45<03:53,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  16% 30/183 [00:47<03:53,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  17% 31/183 [00:47<03:52,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  17% 31/183 [00:48<03:52,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  17% 32/183 [00:48<03:50,  1.53s/it, MovingLoss=3.37, Perplexity=29.20]\u001b[A\n",
            "Iteration:  17% 32/183 [00:50<03:50,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  18% 33/183 [00:50<03:49,  1.53s/it, MovingLoss=3.37, Perplexity=29.19]\u001b[A\n",
            "Iteration:  18% 33/183 [00:52<03:49,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  19% 34/183 [00:52<03:47,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  19% 34/183 [00:53<03:47,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  19% 35/183 [00:53<03:46,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  19% 35/183 [00:55<03:46,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  20% 36/183 [00:55<03:45,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  20% 36/183 [00:56<03:45,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  20% 37/183 [00:56<03:43,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  20% 37/183 [00:58<03:43,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  21% 38/183 [00:58<03:41,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  21% 38/183 [00:59<03:41,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  21% 39/183 [00:59<03:39,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  21% 39/183 [01:01<03:39,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  22% 40/183 [01:01<03:38,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  22% 40/183 [01:02<03:38,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  22% 41/183 [01:02<03:36,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  22% 41/183 [01:04<03:36,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  23% 42/183 [01:04<03:35,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  23% 42/183 [01:05<03:35,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  23% 43/183 [01:05<03:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  23% 43/183 [01:07<03:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  24% 44/183 [01:07<03:32,  1.53s/it, MovingLoss=3.37, Perplexity=29.16]\u001b[A\n",
            "Iteration:  24% 44/183 [01:08<03:32,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  25% 45/183 [01:08<03:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  25% 45/183 [01:10<03:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  25% 46/183 [01:10<03:29,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  25% 46/183 [01:11<03:29,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  26% 47/183 [01:11<03:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  26% 47/183 [01:13<03:27,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  26% 48/183 [01:13<03:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  26% 48/183 [01:14<03:26,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  27% 49/183 [01:14<03:24,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  27% 49/183 [01:16<03:24,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  27% 50/183 [01:16<03:23,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  27% 50/183 [01:18<03:23,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  28% 51/183 [01:18<03:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  28% 51/183 [01:19<03:21,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  28% 52/183 [01:19<03:20,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  28% 52/183 [01:21<03:20,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  29% 53/183 [01:21<03:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.12]\u001b[A\n",
            "Iteration:  29% 53/183 [01:22<03:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  30% 54/183 [01:22<03:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  30% 54/183 [01:24<03:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  30% 55/183 [01:24<03:16,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  30% 55/183 [01:25<03:16,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  31% 56/183 [01:25<03:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  31% 56/183 [01:27<03:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  31% 57/183 [01:27<03:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  31% 57/183 [01:28<03:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  32% 58/183 [01:28<03:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.13]\u001b[A\n",
            "Iteration:  32% 58/183 [01:30<03:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  32% 59/183 [01:30<03:09,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  32% 59/183 [01:31<03:09,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  33% 60/183 [01:31<03:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  33% 60/183 [01:33<03:07,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  33% 61/183 [01:33<03:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  33% 61/183 [01:34<03:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  34% 62/183 [01:34<03:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  34% 62/183 [01:36<03:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  34% 63/183 [01:36<03:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.14]\u001b[A\n",
            "Iteration:  34% 63/183 [01:37<03:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  35% 64/183 [01:37<03:02,  1.53s/it, MovingLoss=3.37, Perplexity=29.15]\u001b[A\n",
            "Iteration:  35% 64/183 [01:39<03:02,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  36% 65/183 [01:39<03:01,  1.54s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  36% 65/183 [01:41<03:01,  1.54s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  36% 66/183 [01:41<02:59,  1.53s/it, MovingLoss=3.37, Perplexity=29.11]\u001b[A\n",
            "Iteration:  36% 66/183 [01:42<02:59,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  37% 67/183 [01:42<02:57,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  37% 67/183 [01:44<02:57,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  37% 68/183 [01:44<02:55,  1.53s/it, MovingLoss=3.37, Perplexity=29.08]\u001b[A\n",
            "Iteration:  37% 68/183 [01:45<02:55,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  38% 69/183 [01:45<02:54,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  38% 69/183 [01:47<02:54,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  38% 70/183 [01:47<02:52,  1.53s/it, MovingLoss=3.37, Perplexity=29.06]\u001b[A\n",
            "Iteration:  38% 70/183 [01:48<02:52,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  39% 71/183 [01:48<02:51,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  39% 71/183 [01:50<02:51,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  39% 72/183 [01:50<02:50,  1.54s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  39% 72/183 [01:51<02:50,  1.54s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  40% 73/183 [01:51<02:48,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  40% 73/183 [01:53<02:48,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  40% 74/183 [01:53<02:47,  1.54s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  40% 74/183 [01:54<02:47,  1.54s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  41% 75/183 [01:54<02:45,  1.54s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  41% 75/183 [01:56<02:45,  1.54s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  42% 76/183 [01:56<02:44,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  42% 76/183 [01:57<02:44,  1.53s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  42% 77/183 [01:57<02:42,  1.54s/it, MovingLoss=3.37, Perplexity=29.07]\u001b[A\n",
            "Iteration:  42% 77/183 [01:59<02:42,  1.54s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  43% 78/183 [01:59<02:41,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  43% 78/183 [02:00<02:41,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  43% 79/183 [02:00<02:39,  1.54s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  43% 79/183 [02:02<02:39,  1.54s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  44% 80/183 [02:02<02:38,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  44% 80/183 [02:04<02:38,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  44% 81/183 [02:04<02:36,  1.54s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  44% 81/183 [02:05<02:36,  1.54s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  45% 82/183 [02:05<02:35,  1.54s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  45% 82/183 [02:07<02:35,  1.54s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  45% 83/183 [02:07<02:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  45% 83/183 [02:08<02:33,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  46% 84/183 [02:08<02:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  46% 84/183 [02:10<02:31,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  46% 85/183 [02:10<02:30,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  46% 85/183 [02:11<02:30,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  47% 86/183 [02:11<02:28,  1.54s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  47% 86/183 [02:13<02:28,  1.54s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  48% 87/183 [02:13<02:27,  1.54s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  48% 87/183 [02:14<02:27,  1.54s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  48% 88/183 [02:14<02:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  48% 88/183 [02:16<02:25,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  49% 89/183 [02:16<02:24,  1.54s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  49% 89/183 [02:17<02:24,  1.54s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  49% 90/183 [02:17<02:22,  1.53s/it, MovingLoss=3.37, Perplexity=29.03]\u001b[A\n",
            "Iteration:  49% 90/183 [02:19<02:22,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  50% 91/183 [02:19<02:20,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  50% 91/183 [02:20<02:20,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  50% 92/183 [02:20<02:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  50% 92/183 [02:22<02:19,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  51% 93/183 [02:22<02:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  51% 93/183 [02:23<02:17,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  51% 94/183 [02:23<02:16,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  51% 94/183 [02:25<02:16,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  52% 95/183 [02:25<02:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  52% 95/183 [02:27<02:14,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  52% 96/183 [02:27<02:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  52% 96/183 [02:28<02:13,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  53% 97/183 [02:28<02:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  53% 97/183 [02:30<02:12,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  54% 98/183 [02:30<02:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  54% 98/183 [02:31<02:10,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  54% 99/183 [02:31<02:08,  1.53s/it, MovingLoss=3.37, Perplexity=29.04]\u001b[A\n",
            "Iteration:  54% 99/183 [02:33<02:08,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  55% 100/183 [02:33<02:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  55% 100/183 [02:34<02:06,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  55% 101/183 [02:34<02:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  55% 101/183 [02:36<02:05,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  56% 102/183 [02:36<02:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.05]\u001b[A\n",
            "Iteration:  56% 102/183 [02:37<02:03,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  56% 103/183 [02:37<02:02,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  56% 103/183 [02:39<02:02,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  57% 104/183 [02:39<02:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  57% 104/183 [02:40<02:01,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  57% 105/183 [02:40<01:59,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  57% 105/183 [02:42<01:59,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  58% 106/183 [02:42<01:57,  1.53s/it, MovingLoss=3.37, Perplexity=29.02]\u001b[A\n",
            "Iteration:  58% 106/183 [02:43<01:57,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  58% 107/183 [02:43<01:56,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  58% 107/183 [02:45<01:56,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  59% 108/183 [02:45<01:54,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  59% 108/183 [02:46<01:54,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  60% 109/183 [02:46<01:52,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  60% 109/183 [02:48<01:52,  1.53s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  60% 110/183 [02:48<01:51,  1.52s/it, MovingLoss=3.37, Perplexity=29.01]\u001b[A\n",
            "Iteration:  60% 110/183 [02:49<01:51,  1.52s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  61% 111/183 [02:49<01:49,  1.52s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  61% 111/183 [02:51<01:49,  1.52s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  61% 112/183 [02:51<01:48,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  61% 112/183 [02:52<01:48,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  62% 113/183 [02:52<01:46,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  62% 113/183 [02:54<01:46,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  62% 114/183 [02:54<01:45,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  62% 114/183 [02:56<01:45,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  63% 115/183 [02:56<01:44,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  63% 115/183 [02:57<01:44,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  63% 116/183 [02:57<01:42,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  63% 116/183 [02:59<01:42,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  64% 117/183 [02:59<01:40,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  64% 117/183 [03:00<01:40,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  64% 118/183 [03:00<01:39,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  64% 118/183 [03:02<01:39,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  65% 119/183 [03:02<01:37,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  65% 119/183 [03:03<01:37,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  66% 120/183 [03:03<01:36,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  66% 120/183 [03:05<01:36,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  66% 121/183 [03:05<01:34,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  66% 121/183 [03:06<01:34,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  67% 122/183 [03:06<01:33,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  67% 122/183 [03:08<01:33,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  67% 123/183 [03:08<01:31,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  67% 123/183 [03:09<01:31,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  68% 124/183 [03:09<01:30,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  68% 124/183 [03:11<01:30,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  68% 125/183 [03:11<01:28,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  68% 125/183 [03:12<01:28,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  69% 126/183 [03:12<01:26,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  69% 126/183 [03:14<01:26,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  69% 127/183 [03:14<01:25,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  69% 127/183 [03:15<01:25,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  70% 128/183 [03:15<01:23,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  70% 128/183 [03:17<01:23,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  70% 129/183 [03:17<01:22,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  70% 129/183 [03:18<01:22,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  71% 130/183 [03:18<01:20,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  71% 130/183 [03:20<01:20,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  72% 131/183 [03:20<01:19,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  72% 131/183 [03:22<01:19,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  72% 132/183 [03:22<01:18,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  72% 132/183 [03:23<01:18,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  73% 133/183 [03:23<01:16,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  73% 133/183 [03:25<01:16,  1.53s/it, MovingLoss=3.36, Perplexity=28.93]\u001b[A\n",
            "Iteration:  73% 134/183 [03:25<01:15,  1.53s/it, MovingLoss=3.36, Perplexity=28.93]\u001b[A\n",
            "Iteration:  73% 134/183 [03:26<01:15,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  74% 135/183 [03:26<01:13,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  74% 135/183 [03:28<01:13,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  74% 136/183 [03:28<01:11,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  74% 136/183 [03:29<01:11,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  75% 137/183 [03:29<01:10,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  75% 137/183 [03:31<01:10,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  75% 138/183 [03:31<01:08,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  75% 138/183 [03:32<01:08,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  76% 139/183 [03:32<01:07,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  76% 139/183 [03:34<01:07,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  77% 140/183 [03:34<01:05,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  77% 140/183 [03:35<01:05,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  77% 141/183 [03:35<01:04,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  77% 141/183 [03:37<01:04,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  78% 142/183 [03:37<01:02,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  78% 142/183 [03:38<01:02,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  78% 143/183 [03:38<01:01,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  78% 143/183 [03:40<01:01,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  79% 144/183 [03:40<00:59,  1.54s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  79% 144/183 [03:41<00:59,  1.54s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  79% 145/183 [03:41<00:58,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  79% 145/183 [03:43<00:58,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  80% 146/183 [03:43<00:56,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  80% 146/183 [03:44<00:56,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  80% 147/183 [03:44<00:54,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  80% 147/183 [03:46<00:54,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  81% 148/183 [03:46<00:53,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  81% 148/183 [03:48<00:53,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  81% 149/183 [03:48<00:51,  1.53s/it, MovingLoss=3.37, Perplexity=28.95]\u001b[A\n",
            "Iteration:  81% 149/183 [03:49<00:51,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  82% 150/183 [03:49<00:50,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  82% 150/183 [03:51<00:50,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  83% 151/183 [03:51<00:48,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  83% 151/183 [03:52<00:48,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  83% 152/183 [03:52<00:47,  1.53s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  83% 152/183 [03:54<00:47,  1.53s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  84% 153/183 [03:54<00:46,  1.54s/it, MovingLoss=3.37, Perplexity=28.97]\u001b[A\n",
            "Iteration:  84% 153/183 [03:55<00:46,  1.54s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  84% 154/183 [03:55<00:44,  1.54s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  84% 154/183 [03:57<00:44,  1.54s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  85% 155/183 [03:57<00:43,  1.54s/it, MovingLoss=3.37, Perplexity=28.96]\u001b[A\n",
            "Iteration:  85% 155/183 [03:58<00:43,  1.54s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  85% 156/183 [03:58<00:41,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  85% 156/183 [04:00<00:41,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  86% 157/183 [04:00<00:39,  1.53s/it, MovingLoss=3.37, Perplexity=28.94]\u001b[A\n",
            "Iteration:  86% 157/183 [04:01<00:39,  1.53s/it, MovingLoss=3.36, Perplexity=28.91]\u001b[A\n",
            "Iteration:  86% 158/183 [04:01<00:38,  1.53s/it, MovingLoss=3.36, Perplexity=28.91]\u001b[A\n",
            "Iteration:  86% 158/183 [04:03<00:38,  1.53s/it, MovingLoss=3.36, Perplexity=28.89]\u001b[A\n",
            "Iteration:  87% 159/183 [04:03<00:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.89]\u001b[A\n",
            "Iteration:  87% 159/183 [04:04<00:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.89]\u001b[A\n",
            "Iteration:  87% 160/183 [04:04<00:35,  1.53s/it, MovingLoss=3.36, Perplexity=28.89]\u001b[A\n",
            "Iteration:  87% 160/183 [04:06<00:35,  1.53s/it, MovingLoss=3.36, Perplexity=28.89]\u001b[A\n",
            "Iteration:  88% 161/183 [04:06<00:33,  1.53s/it, MovingLoss=3.36, Perplexity=28.89]\u001b[A\n",
            "Iteration:  88% 161/183 [04:07<00:33,  1.53s/it, MovingLoss=3.36, Perplexity=28.89]\u001b[A\n",
            "Iteration:  89% 162/183 [04:07<00:32,  1.54s/it, MovingLoss=3.36, Perplexity=28.89]\u001b[A\n",
            "Iteration:  89% 162/183 [04:09<00:32,  1.54s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  89% 163/183 [04:09<00:30,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  89% 163/183 [04:11<00:30,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  90% 164/183 [04:11<00:29,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  90% 164/183 [04:12<00:29,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  90% 165/183 [04:12<00:27,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  90% 165/183 [04:14<00:27,  1.53s/it, MovingLoss=3.36, Perplexity=28.87]\u001b[A\n",
            "Iteration:  91% 166/183 [04:14<00:26,  1.53s/it, MovingLoss=3.36, Perplexity=28.87]\u001b[A\n",
            "Iteration:  91% 166/183 [04:15<00:26,  1.53s/it, MovingLoss=3.36, Perplexity=28.87]\u001b[A\n",
            "Iteration:  91% 167/183 [04:15<00:24,  1.53s/it, MovingLoss=3.36, Perplexity=28.87]\u001b[A\n",
            "Iteration:  91% 167/183 [04:17<00:24,  1.53s/it, MovingLoss=3.36, Perplexity=28.87]\u001b[A\n",
            "Iteration:  92% 168/183 [04:17<00:23,  1.54s/it, MovingLoss=3.36, Perplexity=28.87]\u001b[A\n",
            "Iteration:  92% 168/183 [04:18<00:23,  1.54s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  92% 169/183 [04:18<00:21,  1.54s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  92% 169/183 [04:20<00:21,  1.54s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  93% 170/183 [04:20<00:19,  1.53s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  93% 170/183 [04:21<00:19,  1.53s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  93% 171/183 [04:21<00:18,  1.53s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  93% 171/183 [04:23<00:18,  1.53s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  94% 172/183 [04:23<00:16,  1.53s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  94% 172/183 [04:24<00:16,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  95% 173/183 [04:24<00:15,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  95% 173/183 [04:26<00:15,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  95% 174/183 [04:26<00:13,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  95% 174/183 [04:27<00:13,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  96% 175/183 [04:27<00:12,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  96% 175/183 [04:29<00:12,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  96% 176/183 [04:29<00:10,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  96% 176/183 [04:30<00:10,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  97% 177/183 [04:30<00:09,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  97% 177/183 [04:32<00:09,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  97% 178/183 [04:32<00:07,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  97% 178/183 [04:34<00:07,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  98% 179/183 [04:34<00:06,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  98% 179/183 [04:35<00:06,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  98% 180/183 [04:35<00:04,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  98% 180/183 [04:37<00:04,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  99% 181/183 [04:37<00:03,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  99% 181/183 [04:38<00:03,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  99% 182/183 [04:38<00:01,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  99% 182/183 [04:40<00:01,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration: 100% 183/183 [04:40<00:00,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\n",
            "\n",
            "  0% 0/500 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 4/500 [00:00<00:12, 38.89it/s]\u001b[A\n",
            "  2% 8/500 [00:00<00:12, 38.71it/s]\u001b[A\n",
            "  2% 11/500 [00:00<00:13, 35.45it/s]\u001b[A\n",
            "  3% 14/500 [00:00<00:14, 33.59it/s]\u001b[A\n",
            "  3% 17/500 [00:00<00:14, 32.34it/s]\u001b[A\n",
            "  4% 20/500 [00:00<00:15, 31.37it/s]\u001b[A\n",
            "  5% 23/500 [00:00<00:15, 30.61it/s]\u001b[A\n",
            "  5% 26/500 [00:00<00:15, 29.99it/s]\u001b[A\n",
            "  6% 29/500 [00:00<00:15, 29.46it/s]\u001b[A\n",
            "  6% 32/500 [00:01<00:16, 29.15it/s]\u001b[A\n",
            "  7% 35/500 [00:01<00:16, 28.79it/s]\u001b[A\n",
            "  8% 38/500 [00:01<00:16, 28.57it/s]\u001b[A\n",
            "  8% 41/500 [00:01<00:16, 28.38it/s]\u001b[A\n",
            "  9% 44/500 [00:01<00:16, 28.08it/s]\u001b[A\n",
            "  9% 47/500 [00:01<00:16, 27.96it/s]\u001b[A\n",
            " 10% 50/500 [00:01<00:16, 27.82it/s]\u001b[A\n",
            " 11% 53/500 [00:01<00:16, 27.68it/s]\u001b[A\n",
            " 11% 56/500 [00:01<00:16, 27.20it/s]\u001b[A\n",
            " 12% 59/500 [00:02<00:16, 26.23it/s]\u001b[A\n",
            " 12% 62/500 [00:02<00:17, 25.45it/s]\u001b[A\n",
            " 13% 65/500 [00:02<00:17, 24.95it/s]\u001b[A\n",
            " 14% 68/500 [00:02<00:17, 24.53it/s]\u001b[A\n",
            " 14% 71/500 [00:02<00:17, 24.26it/s]\u001b[A\n",
            " 15% 74/500 [00:02<00:17, 23.99it/s]\u001b[A\n",
            " 15% 77/500 [00:02<00:17, 23.77it/s]\u001b[A\n",
            " 16% 80/500 [00:02<00:17, 23.54it/s]\u001b[A\n",
            " 17% 83/500 [00:03<00:17, 23.37it/s]\u001b[A\n",
            " 17% 86/500 [00:03<00:17, 23.16it/s]\u001b[A\n",
            " 18% 89/500 [00:03<00:17, 22.91it/s]\u001b[A\n",
            " 18% 92/500 [00:03<00:18, 22.60it/s]\u001b[A\n",
            " 19% 95/500 [00:03<00:18, 22.32it/s]\u001b[A\n",
            " 20% 98/500 [00:03<00:18, 22.11it/s]\u001b[A\n",
            " 20% 101/500 [00:03<00:18, 21.96it/s]\u001b[A\n",
            " 21% 104/500 [00:04<00:18, 21.80it/s]\u001b[A\n",
            " 21% 107/500 [00:04<00:18, 21.66it/s]\u001b[A\n",
            " 22% 110/500 [00:04<00:18, 21.47it/s]\u001b[A\n",
            " 23% 113/500 [00:04<00:18, 21.37it/s]\u001b[A\n",
            " 23% 116/500 [00:04<00:18, 21.23it/s]\u001b[A\n",
            " 24% 119/500 [00:04<00:18, 21.15it/s]\u001b[A\n",
            " 24% 122/500 [00:04<00:18, 20.27it/s]\u001b[A\n",
            " 25% 125/500 [00:05<00:19, 19.52it/s]\u001b[A\n",
            " 25% 127/500 [00:05<00:19, 19.05it/s]\u001b[A\n",
            " 26% 129/500 [00:05<00:19, 18.66it/s]\u001b[A\n",
            " 26% 131/500 [00:05<00:20, 18.42it/s]\u001b[A\n",
            " 27% 133/500 [00:05<00:20, 18.24it/s]\u001b[A\n",
            " 27% 135/500 [00:05<00:20, 18.08it/s]\u001b[A\n",
            " 27% 137/500 [00:05<00:20, 17.97it/s]\u001b[A\n",
            " 28% 139/500 [00:05<00:20, 17.89it/s]\u001b[A\n",
            " 28% 141/500 [00:05<00:20, 17.82it/s]\u001b[A\n",
            " 29% 143/500 [00:06<00:20, 17.72it/s]\u001b[A\n",
            " 29% 145/500 [00:06<00:20, 17.61it/s]\u001b[A\n",
            " 29% 147/500 [00:06<00:20, 17.53it/s]\u001b[A\n",
            " 30% 149/500 [00:06<00:20, 17.49it/s]\u001b[A\n",
            " 30% 151/500 [00:06<00:20, 17.43it/s]\u001b[A\n",
            " 31% 153/500 [00:06<00:20, 17.06it/s]\u001b[A\n",
            " 31% 155/500 [00:06<00:20, 16.74it/s]\u001b[A\n",
            " 31% 157/500 [00:06<00:20, 16.55it/s]\u001b[A\n",
            " 32% 159/500 [00:07<00:20, 16.41it/s]\u001b[A\n",
            " 32% 161/500 [00:07<00:20, 16.30it/s]\u001b[A\n",
            " 33% 163/500 [00:07<00:20, 16.06it/s]\u001b[A\n",
            " 33% 165/500 [00:07<00:20, 16.00it/s]\u001b[A\n",
            " 33% 167/500 [00:07<00:20, 15.94it/s]\u001b[A\n",
            " 34% 169/500 [00:07<00:20, 15.87it/s]\u001b[A\n",
            " 34% 171/500 [00:07<00:20, 15.78it/s]\u001b[A\n",
            " 35% 173/500 [00:07<00:20, 15.75it/s]\u001b[A\n",
            " 35% 175/500 [00:08<00:20, 15.71it/s]\u001b[A\n",
            " 35% 177/500 [00:08<00:20, 15.65it/s]\u001b[A\n",
            " 36% 179/500 [00:08<00:20, 15.59it/s]\u001b[A\n",
            " 36% 181/500 [00:08<00:20, 15.56it/s]\u001b[A\n",
            " 37% 183/500 [00:08<00:20, 15.56it/s]\u001b[A\n",
            " 37% 185/500 [00:08<00:20, 15.14it/s]\u001b[A\n",
            " 37% 187/500 [00:08<00:21, 14.78it/s]\u001b[A\n",
            " 38% 189/500 [00:08<00:21, 14.51it/s]\u001b[A\n",
            " 38% 191/500 [00:09<00:21, 14.31it/s]\u001b[A\n",
            " 39% 193/500 [00:09<00:21, 14.15it/s]\u001b[A\n",
            " 39% 195/500 [00:09<00:21, 14.01it/s]\u001b[A\n",
            " 39% 197/500 [00:09<00:21, 13.94it/s]\u001b[A\n",
            " 40% 199/500 [00:09<00:21, 13.91it/s]\u001b[A\n",
            " 40% 201/500 [00:09<00:21, 13.87it/s]\u001b[A\n",
            " 41% 203/500 [00:10<00:21, 13.80it/s]\u001b[A\n",
            " 41% 205/500 [00:10<00:21, 13.74it/s]\u001b[A\n",
            " 41% 207/500 [00:10<00:21, 13.71it/s]\u001b[A\n",
            " 42% 209/500 [00:10<00:21, 13.64it/s]\u001b[A\n",
            " 42% 211/500 [00:10<00:21, 13.63it/s]\u001b[A\n",
            " 43% 213/500 [00:10<00:21, 13.61it/s]\u001b[A\n",
            " 43% 215/500 [00:10<00:21, 13.57it/s]\u001b[A\n",
            " 43% 217/500 [00:11<00:21, 13.42it/s]\u001b[A\n",
            " 44% 219/500 [00:11<00:21, 13.28it/s]\u001b[A\n",
            " 44% 221/500 [00:11<00:21, 13.16it/s]\u001b[A\n",
            " 45% 223/500 [00:11<00:21, 13.10it/s]\u001b[A\n",
            " 45% 225/500 [00:11<00:21, 13.06it/s]\u001b[A\n",
            " 45% 227/500 [00:11<00:21, 13.00it/s]\u001b[A\n",
            " 46% 229/500 [00:11<00:20, 12.92it/s]\u001b[A\n",
            " 46% 231/500 [00:12<00:20, 12.92it/s]\u001b[A\n",
            " 47% 233/500 [00:12<00:20, 12.86it/s]\u001b[A\n",
            " 47% 235/500 [00:12<00:20, 12.82it/s]\u001b[A\n",
            " 47% 237/500 [00:12<00:20, 12.77it/s]\u001b[A\n",
            " 48% 239/500 [00:12<00:20, 12.73it/s]\u001b[A\n",
            " 48% 241/500 [00:12<00:20, 12.68it/s]\u001b[A\n",
            " 49% 243/500 [00:13<00:20, 12.63it/s]\u001b[A\n",
            " 49% 245/500 [00:13<00:20, 12.61it/s]\u001b[A\n",
            " 49% 247/500 [00:13<00:20, 12.64it/s]\u001b[A\n",
            " 50% 249/500 [00:13<00:20, 12.21it/s]\u001b[A\n",
            " 50% 251/500 [00:13<00:20, 11.92it/s]\u001b[A\n",
            " 51% 253/500 [00:13<00:21, 11.64it/s]\u001b[A\n",
            " 51% 255/500 [00:14<00:21, 11.50it/s]\u001b[A\n",
            " 51% 257/500 [00:14<00:21, 11.41it/s]\u001b[A\n",
            " 52% 259/500 [00:14<00:21, 11.38it/s]\u001b[A\n",
            " 52% 261/500 [00:14<00:21, 11.29it/s]\u001b[A\n",
            " 53% 263/500 [00:14<00:21, 11.19it/s]\u001b[A\n",
            " 53% 265/500 [00:15<00:21, 11.13it/s]\u001b[A\n",
            " 53% 267/500 [00:15<00:20, 11.15it/s]\u001b[A\n",
            " 54% 269/500 [00:15<00:20, 11.15it/s]\u001b[A\n",
            " 54% 271/500 [00:15<00:20, 11.07it/s]\u001b[A\n",
            " 55% 273/500 [00:15<00:20, 10.98it/s]\u001b[A\n",
            " 55% 275/500 [00:15<00:20, 10.93it/s]\u001b[A\n",
            " 55% 277/500 [00:16<00:20, 10.94it/s]\u001b[A\n",
            " 56% 279/500 [00:16<00:20, 10.95it/s]\u001b[A\n",
            " 56% 281/500 [00:16<00:20, 10.89it/s]\u001b[A\n",
            " 57% 283/500 [00:16<00:20, 10.82it/s]\u001b[A\n",
            " 57% 285/500 [00:16<00:20, 10.65it/s]\u001b[A\n",
            " 57% 287/500 [00:17<00:20, 10.60it/s]\u001b[A\n",
            " 58% 289/500 [00:17<00:19, 10.61it/s]\u001b[A\n",
            " 58% 291/500 [00:17<00:19, 10.61it/s]\u001b[A\n",
            " 59% 293/500 [00:17<00:19, 10.55it/s]\u001b[A\n",
            " 59% 295/500 [00:17<00:19, 10.54it/s]\u001b[A\n",
            " 59% 297/500 [00:17<00:19, 10.54it/s]\u001b[A\n",
            " 60% 299/500 [00:18<00:19, 10.55it/s]\u001b[A\n",
            " 60% 301/500 [00:18<00:18, 10.52it/s]\u001b[A\n",
            " 61% 303/500 [00:18<00:18, 10.39it/s]\u001b[A\n",
            " 61% 305/500 [00:18<00:18, 10.30it/s]\u001b[A\n",
            " 61% 307/500 [00:18<00:18, 10.22it/s]\u001b[A\n",
            " 62% 309/500 [00:19<00:18, 10.17it/s]\u001b[A\n",
            " 62% 311/500 [00:19<00:18, 10.18it/s]\u001b[A\n",
            " 63% 313/500 [00:19<00:18, 10.00it/s]\u001b[A\n",
            " 63% 315/500 [00:19<00:18,  9.79it/s]\u001b[A\n",
            " 63% 316/500 [00:19<00:19,  9.65it/s]\u001b[A\n",
            " 63% 317/500 [00:19<00:18,  9.67it/s]\u001b[A\n",
            " 64% 318/500 [00:20<00:18,  9.70it/s]\u001b[A\n",
            " 64% 319/500 [00:20<00:18,  9.74it/s]\u001b[A\n",
            " 64% 320/500 [00:20<00:18,  9.70it/s]\u001b[A\n",
            " 64% 321/500 [00:20<00:18,  9.63it/s]\u001b[A\n",
            " 64% 322/500 [00:20<00:18,  9.59it/s]\u001b[A\n",
            " 65% 323/500 [00:20<00:18,  9.54it/s]\u001b[A\n",
            " 65% 324/500 [00:20<00:18,  9.50it/s]\u001b[A\n",
            " 65% 325/500 [00:20<00:18,  9.54it/s]\u001b[A\n",
            " 65% 326/500 [00:20<00:18,  9.53it/s]\u001b[A\n",
            " 65% 327/500 [00:21<00:18,  9.52it/s]\u001b[A\n",
            " 66% 328/500 [00:21<00:18,  9.48it/s]\u001b[A\n",
            " 66% 329/500 [00:21<00:18,  9.46it/s]\u001b[A\n",
            " 66% 330/500 [00:21<00:18,  9.44it/s]\u001b[A\n",
            " 66% 331/500 [00:21<00:17,  9.42it/s]\u001b[A\n",
            " 66% 332/500 [00:21<00:17,  9.41it/s]\u001b[A\n",
            " 67% 333/500 [00:21<00:17,  9.40it/s]\u001b[A\n",
            " 67% 334/500 [00:21<00:17,  9.34it/s]\u001b[A\n",
            " 67% 335/500 [00:21<00:17,  9.29it/s]\u001b[A\n",
            " 67% 336/500 [00:22<00:17,  9.31it/s]\u001b[A\n",
            " 67% 337/500 [00:22<00:17,  9.34it/s]\u001b[A\n",
            " 68% 338/500 [00:22<00:17,  9.40it/s]\u001b[A\n",
            " 68% 339/500 [00:22<00:17,  9.42it/s]\u001b[A\n",
            " 68% 340/500 [00:22<00:17,  9.38it/s]\u001b[A\n",
            " 68% 341/500 [00:22<00:16,  9.36it/s]\u001b[A\n",
            " 68% 342/500 [00:22<00:16,  9.34it/s]\u001b[A\n",
            " 69% 343/500 [00:22<00:16,  9.35it/s]\u001b[A\n",
            " 69% 344/500 [00:22<00:16,  9.20it/s]\u001b[A\n",
            " 69% 345/500 [00:22<00:17,  9.11it/s]\u001b[A\n",
            " 69% 346/500 [00:23<00:17,  9.05it/s]\u001b[A\n",
            " 69% 347/500 [00:23<00:17,  8.95it/s]\u001b[A\n",
            " 70% 348/500 [00:23<00:17,  8.89it/s]\u001b[A\n",
            " 70% 349/500 [00:23<00:17,  8.84it/s]\u001b[A\n",
            " 70% 350/500 [00:23<00:16,  8.86it/s]\u001b[A\n",
            " 70% 351/500 [00:23<00:16,  8.88it/s]\u001b[A\n",
            " 70% 352/500 [00:23<00:16,  8.88it/s]\u001b[A\n",
            " 71% 353/500 [00:23<00:16,  8.87it/s]\u001b[A\n",
            " 71% 354/500 [00:23<00:16,  8.83it/s]\u001b[A\n",
            " 71% 355/500 [00:24<00:16,  8.78it/s]\u001b[A\n",
            " 71% 356/500 [00:24<00:16,  8.74it/s]\u001b[A\n",
            " 71% 357/500 [00:24<00:16,  8.76it/s]\u001b[A\n",
            " 72% 358/500 [00:24<00:16,  8.78it/s]\u001b[A\n",
            " 72% 359/500 [00:24<00:16,  8.80it/s]\u001b[A\n",
            " 72% 360/500 [00:24<00:15,  8.80it/s]\u001b[A\n",
            " 72% 361/500 [00:24<00:15,  8.73it/s]\u001b[A\n",
            " 72% 362/500 [00:24<00:15,  8.66it/s]\u001b[A\n",
            " 73% 363/500 [00:25<00:15,  8.69it/s]\u001b[A\n",
            " 73% 364/500 [00:25<00:15,  8.71it/s]\u001b[A\n",
            " 73% 365/500 [00:25<00:15,  8.73it/s]\u001b[A\n",
            " 73% 366/500 [00:25<00:15,  8.74it/s]\u001b[A\n",
            " 73% 367/500 [00:25<00:15,  8.75it/s]\u001b[A\n",
            " 74% 368/500 [00:25<00:15,  8.69it/s]\u001b[A\n",
            " 74% 369/500 [00:25<00:15,  8.62it/s]\u001b[A\n",
            " 74% 370/500 [00:25<00:15,  8.62it/s]\u001b[A\n",
            " 74% 371/500 [00:25<00:14,  8.65it/s]\u001b[A\n",
            " 74% 372/500 [00:26<00:14,  8.67it/s]\u001b[A\n",
            " 75% 373/500 [00:26<00:14,  8.68it/s]\u001b[A\n",
            " 75% 374/500 [00:26<00:14,  8.67it/s]\u001b[A\n",
            " 75% 375/500 [00:26<00:14,  8.65it/s]\u001b[A\n",
            " 75% 376/500 [00:26<00:14,  8.51it/s]\u001b[A\n",
            " 75% 377/500 [00:26<00:14,  8.44it/s]\u001b[A\n",
            " 76% 378/500 [00:26<00:14,  8.40it/s]\u001b[A\n",
            " 76% 379/500 [00:26<00:14,  8.34it/s]\u001b[A\n",
            " 76% 380/500 [00:27<00:14,  8.26it/s]\u001b[A\n",
            " 76% 381/500 [00:27<00:14,  8.21it/s]\u001b[A\n",
            " 76% 382/500 [00:27<00:14,  8.19it/s]\u001b[A\n",
            " 77% 383/500 [00:27<00:14,  8.18it/s]\u001b[A\n",
            " 77% 384/500 [00:27<00:14,  8.15it/s]\u001b[A\n",
            " 77% 385/500 [00:27<00:14,  8.09it/s]\u001b[A\n",
            " 77% 386/500 [00:27<00:14,  8.10it/s]\u001b[A\n",
            " 77% 387/500 [00:27<00:13,  8.09it/s]\u001b[A\n",
            " 78% 388/500 [00:28<00:13,  8.05it/s]\u001b[A\n",
            " 78% 389/500 [00:28<00:13,  8.02it/s]\u001b[A\n",
            " 78% 390/500 [00:28<00:13,  8.03it/s]\u001b[A\n",
            " 78% 391/500 [00:28<00:13,  8.07it/s]\u001b[A\n",
            " 78% 392/500 [00:28<00:13,  8.08it/s]\u001b[A\n",
            " 79% 393/500 [00:28<00:13,  8.07it/s]\u001b[A\n",
            " 79% 394/500 [00:28<00:13,  8.06it/s]\u001b[A\n",
            " 79% 395/500 [00:28<00:12,  8.09it/s]\u001b[A\n",
            " 79% 396/500 [00:28<00:12,  8.12it/s]\u001b[A\n",
            " 79% 397/500 [00:29<00:12,  8.10it/s]\u001b[A\n",
            " 80% 398/500 [00:29<00:12,  8.05it/s]\u001b[A\n",
            " 80% 399/500 [00:29<00:12,  8.03it/s]\u001b[A\n",
            " 80% 400/500 [00:29<00:12,  8.03it/s]\u001b[A\n",
            " 80% 401/500 [00:29<00:12,  8.02it/s]\u001b[A\n",
            " 80% 402/500 [00:29<00:12,  8.01it/s]\u001b[A\n",
            " 81% 403/500 [00:29<00:12,  8.03it/s]\u001b[A\n",
            " 81% 404/500 [00:29<00:11,  8.06it/s]\u001b[A\n",
            " 81% 405/500 [00:30<00:11,  8.04it/s]\u001b[A\n",
            " 81% 406/500 [00:30<00:11,  7.98it/s]\u001b[A\n",
            " 81% 407/500 [00:30<00:11,  7.98it/s]\u001b[A\n",
            " 82% 408/500 [00:30<00:11,  7.88it/s]\u001b[A\n",
            " 82% 409/500 [00:30<00:11,  7.84it/s]\u001b[A\n",
            " 82% 410/500 [00:30<00:11,  7.76it/s]\u001b[A\n",
            " 82% 411/500 [00:30<00:11,  7.71it/s]\u001b[A\n",
            " 82% 412/500 [00:31<00:11,  7.68it/s]\u001b[A\n",
            " 83% 413/500 [00:31<00:11,  7.65it/s]\u001b[A\n",
            " 83% 414/500 [00:31<00:11,  7.68it/s]\u001b[A\n",
            " 83% 415/500 [00:31<00:11,  7.66it/s]\u001b[A\n",
            " 83% 416/500 [00:31<00:11,  7.58it/s]\u001b[A\n",
            " 83% 417/500 [00:31<00:11,  7.54it/s]\u001b[A\n",
            " 84% 418/500 [00:31<00:10,  7.55it/s]\u001b[A\n",
            " 84% 419/500 [00:31<00:10,  7.55it/s]\u001b[A\n",
            " 84% 420/500 [00:32<00:10,  7.58it/s]\u001b[A\n",
            " 84% 421/500 [00:32<00:10,  7.62it/s]\u001b[A\n",
            " 84% 422/500 [00:32<00:10,  7.59it/s]\u001b[A\n",
            " 85% 423/500 [00:32<00:10,  7.59it/s]\u001b[A\n",
            " 85% 424/500 [00:32<00:09,  7.61it/s]\u001b[A\n",
            " 85% 425/500 [00:32<00:09,  7.59it/s]\u001b[A\n",
            " 85% 426/500 [00:32<00:09,  7.56it/s]\u001b[A\n",
            " 85% 427/500 [00:33<00:09,  7.54it/s]\u001b[A\n",
            " 86% 428/500 [00:33<00:09,  7.52it/s]\u001b[A\n",
            " 86% 429/500 [00:33<00:09,  7.51it/s]\u001b[A\n",
            " 86% 430/500 [00:33<00:09,  7.53it/s]\u001b[A\n",
            " 86% 431/500 [00:33<00:09,  7.51it/s]\u001b[A\n",
            " 86% 432/500 [00:33<00:09,  7.50it/s]\u001b[A\n",
            " 87% 433/500 [00:33<00:08,  7.54it/s]\u001b[A\n",
            " 87% 434/500 [00:33<00:08,  7.51it/s]\u001b[A\n",
            " 87% 435/500 [00:34<00:08,  7.46it/s]\u001b[A\n",
            " 87% 436/500 [00:34<00:08,  7.44it/s]\u001b[A\n",
            " 87% 437/500 [00:34<00:08,  7.44it/s]\u001b[A\n",
            " 88% 438/500 [00:34<00:08,  7.43it/s]\u001b[A\n",
            " 88% 439/500 [00:34<00:08,  7.49it/s]\u001b[A\n",
            " 88% 440/500 [00:34<00:08,  7.39it/s]\u001b[A\n",
            " 88% 441/500 [00:34<00:08,  7.32it/s]\u001b[A\n",
            " 88% 442/500 [00:35<00:07,  7.26it/s]\u001b[A\n",
            " 89% 443/500 [00:35<00:07,  7.18it/s]\u001b[A\n",
            " 89% 444/500 [00:35<00:07,  7.15it/s]\u001b[A\n",
            " 89% 445/500 [00:35<00:07,  7.13it/s]\u001b[A\n",
            " 89% 446/500 [00:35<00:07,  7.12it/s]\u001b[A\n",
            " 89% 447/500 [00:35<00:07,  7.12it/s]\u001b[A\n",
            " 90% 448/500 [00:35<00:07,  7.07it/s]\u001b[A\n",
            " 90% 449/500 [00:36<00:07,  7.04it/s]\u001b[A\n",
            " 90% 450/500 [00:36<00:07,  7.05it/s]\u001b[A\n",
            " 90% 451/500 [00:36<00:06,  7.10it/s]\u001b[A\n",
            " 90% 452/500 [00:36<00:06,  7.10it/s]\u001b[A\n",
            " 91% 453/500 [00:36<00:06,  7.05it/s]\u001b[A\n",
            " 91% 454/500 [00:36<00:06,  7.04it/s]\u001b[A\n",
            " 91% 455/500 [00:36<00:06,  7.04it/s]\u001b[A\n",
            " 91% 456/500 [00:37<00:06,  7.05it/s]\u001b[A\n",
            " 91% 457/500 [00:37<00:06,  7.06it/s]\u001b[A\n",
            " 92% 458/500 [00:37<00:05,  7.02it/s]\u001b[A\n",
            " 92% 459/500 [00:37<00:05,  7.01it/s]\u001b[A\n",
            " 92% 460/500 [00:37<00:05,  6.98it/s]\u001b[A\n",
            " 92% 461/500 [00:37<00:05,  6.97it/s]\u001b[A\n",
            " 92% 462/500 [00:37<00:05,  6.98it/s]\u001b[A\n",
            " 93% 463/500 [00:38<00:05,  6.99it/s]\u001b[A\n",
            " 93% 464/500 [00:38<00:05,  6.99it/s]\u001b[A\n",
            " 93% 465/500 [00:38<00:05,  6.98it/s]\u001b[A\n",
            " 93% 466/500 [00:38<00:04,  6.98it/s]\u001b[A\n",
            " 93% 467/500 [00:38<00:04,  6.94it/s]\u001b[A\n",
            " 94% 468/500 [00:38<00:04,  6.93it/s]\u001b[A\n",
            " 94% 469/500 [00:38<00:04,  6.93it/s]\u001b[A\n",
            " 94% 470/500 [00:39<00:04,  6.95it/s]\u001b[A\n",
            " 94% 471/500 [00:39<00:04,  6.96it/s]\u001b[A\n",
            " 94% 472/500 [00:39<00:04,  6.90it/s]\u001b[A\n",
            " 95% 473/500 [00:39<00:03,  6.85it/s]\u001b[A\n",
            " 95% 474/500 [00:39<00:03,  6.81it/s]\u001b[A\n",
            " 95% 475/500 [00:39<00:03,  6.78it/s]\u001b[A\n",
            " 95% 476/500 [00:39<00:03,  6.74it/s]\u001b[A\n",
            " 95% 477/500 [00:40<00:03,  6.71it/s]\u001b[A\n",
            " 96% 478/500 [00:40<00:03,  6.69it/s]\u001b[A\n",
            " 96% 479/500 [00:40<00:03,  6.70it/s]\u001b[A\n",
            " 96% 480/500 [00:40<00:03,  6.66it/s]\u001b[A\n",
            " 96% 481/500 [00:40<00:02,  6.67it/s]\u001b[A\n",
            " 96% 482/500 [00:40<00:02,  6.65it/s]\u001b[A\n",
            " 97% 483/500 [00:40<00:02,  6.63it/s]\u001b[A\n",
            " 97% 484/500 [00:41<00:02,  6.61it/s]\u001b[A\n",
            " 97% 485/500 [00:41<00:02,  6.60it/s]\u001b[A\n",
            " 97% 486/500 [00:41<00:02,  6.60it/s]\u001b[A\n",
            " 97% 487/500 [00:41<00:01,  6.63it/s]\u001b[A\n",
            " 98% 488/500 [00:41<00:01,  6.61it/s]\u001b[A\n",
            " 98% 489/500 [00:41<00:01,  6.62it/s]\u001b[A\n",
            " 98% 490/500 [00:42<00:01,  6.59it/s]\u001b[A\n",
            " 98% 491/500 [00:42<00:01,  6.61it/s]\u001b[A\n",
            " 98% 492/500 [00:42<00:01,  6.62it/s]\u001b[A\n",
            " 99% 493/500 [00:42<00:01,  6.62it/s]\u001b[A\n",
            " 99% 494/500 [00:42<00:00,  6.62it/s]\u001b[A\n",
            " 99% 495/500 [00:42<00:00,  6.61it/s]\u001b[A\n",
            " 99% 496/500 [00:42<00:00,  6.61it/s]\u001b[A\n",
            " 99% 497/500 [00:43<00:00,  6.61it/s]\u001b[A\n",
            "100% 498/500 [00:43<00:00,  6.61it/s]\u001b[A\n",
            "100% 499/500 [00:43<00:00,  6.61it/s]\u001b[A\n",
            "100% 500/500 [00:43<00:00, 11.48it/s]\n",
            "  Будьте практичны. Этот день может положить начало длительному рутину?\n",
            "\n",
            "–  В средние века славяне занимались земледелием, охотой. Брали урожай из земных недр. Со временем земля стала плодородной.\n",
            "\n",
            "–  А, значит, вы со своими младенцами могли спасти мир.\n",
            "\n",
            "–  Могли.\n",
            "\n",
            "–  Вы говорили, что один из ваших детей погиб. Значит, это ваш отец хотел спасти мир. Но это ведь вы проявили необычайный героизм, чтобы спасти мир. Только благодаря вам мир не погиб. С тех пор все, что произошло на земле до появления людей, повторяется: вот здесь разверзлись бездны преисподней, там распались надвое врата, а впереди них вечность!\n",
            "\n",
            "Она снова умолкла.\n",
            "\n",
            "Теперь она знала, почему все так произошло. Она понимала, что, сказав это, не понимает, почему в пещере по-прежнему стоят люди, пытаясь понять, что произошло. Она понимала, что она не знает, почему так случилось, но было так много причин открыть ей этот вопрос.\n",
            "\n",
            "Отец и мать молчали. У некоторых из них тоже было убито сердце; возможно, раны и переломы были не настолько серьезны, как прежде.\n",
            "\n",
            "Анна сложила руки на коленях и положила их на колени.\n",
            "\n",
            "–  Отец, что это был за сон? Почему мне нельзя просыпаться? Почему они не удосужились ответить мне?\n",
            "\n",
            "Она не отвечала ни на один из ее вопросов. Если она чего-то боялась, то боялась не меньше дочери.\n",
            "\n",
            "Вот если бы она была другой девочкой или девушкой, она была бы спокойной, рассудительной и общительной.\n",
            "\n",
            "Но она словно сошла с ума. Она как будто бы уже не ребенок. Анна застонала, еще крепче обхватив колени руками. Она была не живая, она была мертвая.\n",
            "\n",
            "Отец встал и осторожно обнял ее.\n",
            "\n",
            "–  Ты не можешь так умереть. За это ты поплатишься головой. – И добавил твердым голосом: – Подумай обо всем, если ты вообще когда-нибудь об этом задумывалась. Подумай о том, что ты должна думать обо всем, прежде чем ты умрешь.\n",
            "\n",
            "Анна обняла его и начала судорожно плакать, но слезы хлынули из ее глаз, как бы их не было ни на одной из мраморных плит пещеры. Она слабо всхлипывала, прижимая его к себе, словно хотела защитить от любого врага.\n",
            "\n",
            "Отца больше не было в пещере. Все ушли. Больше не было отца!\n",
            "\n",
            "\n",
            "Энн Энн Гринвойя\n",
            "\n",
            "\n",
            "Он часто падал – на какие-то детали, на выражение его лица, на то, как он откидывал голову назад.\n",
            "\n",
            "–  Энн Энн, дорогая, зачем ты это делаешь? Это не сон, не галлюцинация. Ты сошла с ума, ты сошла с ума.\n",
            "\n",
            "Он рассказывал ей все это, сидя в кресле возле очага, глядя на мерцающие огни камина. Энн молчала,\n",
            "Epoch:  60% 3/5 [16:11<10:47, 323.99s/it]\n",
            "Iteration:   0% 0/183 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 0/183 [00:01<?, ?it/s, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   1% 1/183 [00:01<04:36,  1.52s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   1% 1/183 [00:03<04:36,  1.52s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   1% 2/183 [00:03<04:35,  1.52s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   1% 2/183 [00:04<04:35,  1.52s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   2% 3/183 [00:04<04:34,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   2% 3/183 [00:06<04:34,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:   2% 4/183 [00:06<04:33,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:   2% 4/183 [00:07<04:33,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:   3% 5/183 [00:07<04:31,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:   3% 5/183 [00:09<04:31,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:   3% 6/183 [00:09<04:30,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:   3% 6/183 [00:10<04:30,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   4% 7/183 [00:10<04:28,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   4% 7/183 [00:12<04:28,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:   4% 8/183 [00:12<04:27,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:   4% 8/183 [00:13<04:27,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:   5% 9/183 [00:13<04:26,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:   5% 9/183 [00:15<04:26,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   5% 10/183 [00:15<04:24,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   5% 10/183 [00:16<04:24,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   6% 11/183 [00:16<04:23,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   6% 11/183 [00:18<04:23,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   7% 12/183 [00:18<04:22,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:   7% 12/183 [00:19<04:22,  1.53s/it, MovingLoss=3.36, Perplexity=28.79]\u001b[A\n",
            "Iteration:   7% 13/183 [00:19<04:20,  1.53s/it, MovingLoss=3.36, Perplexity=28.79]\u001b[A\n",
            "Iteration:   7% 13/183 [00:21<04:20,  1.53s/it, MovingLoss=3.36, Perplexity=28.79]\u001b[A\n",
            "Iteration:   8% 14/183 [00:21<04:18,  1.53s/it, MovingLoss=3.36, Perplexity=28.79]\u001b[A\n",
            "Iteration:   8% 14/183 [00:22<04:18,  1.53s/it, MovingLoss=3.36, Perplexity=28.79]\u001b[A\n",
            "Iteration:   8% 15/183 [00:22<04:17,  1.53s/it, MovingLoss=3.36, Perplexity=28.79]\u001b[A\n",
            "Iteration:   8% 15/183 [00:24<04:17,  1.53s/it, MovingLoss=3.36, Perplexity=28.79]\u001b[A\n",
            "Iteration:   9% 16/183 [00:24<04:15,  1.53s/it, MovingLoss=3.36, Perplexity=28.79]\u001b[A\n",
            "Iteration:   9% 16/183 [00:26<04:15,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:   9% 17/183 [00:26<04:14,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:   9% 17/183 [00:27<04:14,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  10% 18/183 [00:27<04:12,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  10% 18/183 [00:29<04:12,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  10% 19/183 [00:29<04:11,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  10% 19/183 [00:30<04:11,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  11% 20/183 [00:30<04:10,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  11% 20/183 [00:32<04:10,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  11% 21/183 [00:32<04:08,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  11% 21/183 [00:33<04:08,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  12% 22/183 [00:33<04:06,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  12% 22/183 [00:35<04:06,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  13% 23/183 [00:35<04:04,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  13% 23/183 [00:36<04:04,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  13% 24/183 [00:36<04:03,  1.53s/it, MovingLoss=3.36, Perplexity=28.81]\u001b[A\n",
            "Iteration:  13% 24/183 [00:38<04:03,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  14% 25/183 [00:38<04:01,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  14% 25/183 [00:39<04:01,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  14% 26/183 [00:39<04:00,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  14% 26/183 [00:41<04:00,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  15% 27/183 [00:41<03:59,  1.53s/it, MovingLoss=3.36, Perplexity=28.82]\u001b[A\n",
            "Iteration:  15% 27/183 [00:42<03:59,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  15% 28/183 [00:42<03:57,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  15% 28/183 [00:44<03:57,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  16% 29/183 [00:44<03:56,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  16% 29/183 [00:45<03:56,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  16% 30/183 [00:45<03:54,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  16% 30/183 [00:47<03:54,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  17% 31/183 [00:47<03:52,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  17% 31/183 [00:48<03:52,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  17% 32/183 [00:48<03:50,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  17% 32/183 [00:50<03:50,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  18% 33/183 [00:50<03:49,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  18% 33/183 [00:52<03:49,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  19% 34/183 [00:52<03:47,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  19% 34/183 [00:53<03:47,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  19% 35/183 [00:53<03:46,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  19% 35/183 [00:55<03:46,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  20% 36/183 [00:55<03:44,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  20% 36/183 [00:56<03:44,  1.53s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  20% 37/183 [00:56<03:43,  1.53s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  20% 37/183 [00:58<03:43,  1.53s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  21% 38/183 [00:58<03:41,  1.53s/it, MovingLoss=3.36, Perplexity=28.85]\u001b[A\n",
            "Iteration:  21% 38/183 [00:59<03:41,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  21% 39/183 [00:59<03:39,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  21% 39/183 [01:01<03:39,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  22% 40/183 [01:01<03:38,  1.53s/it, MovingLoss=3.36, Perplexity=28.84]\u001b[A\n",
            "Iteration:  22% 40/183 [01:02<03:38,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  22% 41/183 [01:02<03:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  22% 41/183 [01:04<03:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  23% 42/183 [01:04<03:35,  1.53s/it, MovingLoss=3.36, Perplexity=28.86]\u001b[A\n",
            "Iteration:  23% 42/183 [01:05<03:35,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  23% 43/183 [01:05<03:33,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  23% 43/183 [01:07<03:33,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  24% 44/183 [01:07<03:32,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  24% 44/183 [01:08<03:32,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  25% 45/183 [01:08<03:31,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  25% 45/183 [01:10<03:31,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  25% 46/183 [01:10<03:30,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  25% 46/183 [01:11<03:30,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  26% 47/183 [01:11<03:28,  1.53s/it, MovingLoss=3.36, Perplexity=28.83]\u001b[A\n",
            "Iteration:  26% 47/183 [01:13<03:28,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  26% 48/183 [01:13<03:26,  1.53s/it, MovingLoss=3.36, Perplexity=28.80]\u001b[A\n",
            "Iteration:  26% 48/183 [01:14<03:26,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  27% 49/183 [01:14<03:24,  1.52s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  27% 49/183 [01:16<03:24,  1.52s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  27% 50/183 [01:16<03:23,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  27% 50/183 [01:18<03:23,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  28% 51/183 [01:18<03:21,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  28% 51/183 [01:19<03:21,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  28% 52/183 [01:19<03:19,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  28% 52/183 [01:21<03:19,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  29% 53/183 [01:21<03:18,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  29% 53/183 [01:22<03:18,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  30% 54/183 [01:22<03:17,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  30% 54/183 [01:24<03:17,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  30% 55/183 [01:24<03:16,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  30% 55/183 [01:25<03:16,  1.53s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:  31% 56/183 [01:25<03:14,  1.53s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:  31% 56/183 [01:27<03:14,  1.53s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:  31% 57/183 [01:27<03:13,  1.54s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:  31% 57/183 [01:28<03:13,  1.54s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:  32% 58/183 [01:28<03:11,  1.53s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:  32% 58/183 [01:30<03:11,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  32% 59/183 [01:30<03:09,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  32% 59/183 [01:31<03:09,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  33% 60/183 [01:31<03:08,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  33% 60/183 [01:33<03:08,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  33% 61/183 [01:33<03:06,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  33% 61/183 [01:34<03:06,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  34% 62/183 [01:34<03:05,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  34% 62/183 [01:36<03:05,  1.53s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  34% 63/183 [01:36<03:04,  1.53s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  34% 63/183 [01:37<03:04,  1.53s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  35% 64/183 [01:37<03:02,  1.54s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  35% 64/183 [01:39<03:02,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  36% 65/183 [01:39<03:01,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  36% 65/183 [01:41<03:01,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  36% 66/183 [01:41<03:00,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  36% 66/183 [01:42<03:00,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  37% 67/183 [01:42<02:58,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  37% 67/183 [01:44<02:58,  1.54s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  37% 68/183 [01:44<02:56,  1.53s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  37% 68/183 [01:45<02:56,  1.53s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  38% 69/183 [01:45<02:54,  1.53s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  38% 69/183 [01:47<02:54,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  38% 70/183 [01:47<02:53,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  38% 70/183 [01:48<02:53,  1.54s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  39% 71/183 [01:48<02:52,  1.54s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  39% 71/183 [01:50<02:52,  1.54s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  39% 72/183 [01:50<02:50,  1.54s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  39% 72/183 [01:51<02:50,  1.54s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  40% 73/183 [01:51<02:49,  1.54s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  40% 73/183 [01:53<02:49,  1.54s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  40% 74/183 [01:53<02:47,  1.54s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  40% 74/183 [01:54<02:47,  1.54s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  41% 75/183 [01:54<02:45,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  41% 75/183 [01:56<02:45,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  42% 76/183 [01:56<02:43,  1.53s/it, MovingLoss=3.36, Perplexity=28.77]\u001b[A\n",
            "Iteration:  42% 76/183 [01:57<02:43,  1.53s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  42% 77/183 [01:57<02:42,  1.53s/it, MovingLoss=3.36, Perplexity=28.78]\u001b[A\n",
            "Iteration:  42% 77/183 [01:59<02:42,  1.53s/it, MovingLoss=3.36, Perplexity=28.75]\u001b[A\n",
            "Iteration:  43% 78/183 [01:59<02:41,  1.54s/it, MovingLoss=3.36, Perplexity=28.75]\u001b[A\n",
            "Iteration:  43% 78/183 [02:00<02:41,  1.54s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:  43% 79/183 [02:00<02:39,  1.54s/it, MovingLoss=3.36, Perplexity=28.76]\u001b[A\n",
            "Iteration:  43% 79/183 [02:02<02:39,  1.54s/it, MovingLoss=3.36, Perplexity=28.75]\u001b[A\n",
            "Iteration:  44% 80/183 [02:02<02:38,  1.54s/it, MovingLoss=3.36, Perplexity=28.75]\u001b[A\n",
            "Iteration:  44% 80/183 [02:04<02:38,  1.54s/it, MovingLoss=3.36, Perplexity=28.75]\u001b[A\n",
            "Iteration:  44% 81/183 [02:04<02:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.75]\u001b[A\n",
            "Iteration:  44% 81/183 [02:05<02:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.73]\u001b[A\n",
            "Iteration:  45% 82/183 [02:05<02:34,  1.53s/it, MovingLoss=3.36, Perplexity=28.73]\u001b[A\n",
            "Iteration:  45% 82/183 [02:07<02:34,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  45% 83/183 [02:07<02:33,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  45% 83/183 [02:08<02:33,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  46% 84/183 [02:08<02:31,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  46% 84/183 [02:10<02:31,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  46% 85/183 [02:10<02:30,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  46% 85/183 [02:11<02:30,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  47% 86/183 [02:11<02:28,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  47% 86/183 [02:13<02:28,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  48% 87/183 [02:13<02:27,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  48% 87/183 [02:14<02:27,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  48% 88/183 [02:14<02:25,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  48% 88/183 [02:16<02:25,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  49% 89/183 [02:16<02:24,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  49% 89/183 [02:17<02:24,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  49% 90/183 [02:17<02:22,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  49% 90/183 [02:19<02:22,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  50% 91/183 [02:19<02:20,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  50% 91/183 [02:20<02:20,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  50% 92/183 [02:20<02:19,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  50% 92/183 [02:22<02:19,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  51% 93/183 [02:22<02:17,  1.53s/it, MovingLoss=3.36, Perplexity=28.70]\u001b[A\n",
            "Iteration:  51% 93/183 [02:23<02:17,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  51% 94/183 [02:23<02:16,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  51% 94/183 [02:25<02:16,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  52% 95/183 [02:25<02:14,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  52% 95/183 [02:27<02:14,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  52% 96/183 [02:27<02:13,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  52% 96/183 [02:28<02:13,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  53% 97/183 [02:28<02:11,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  53% 97/183 [02:30<02:11,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  54% 98/183 [02:30<02:09,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  54% 98/183 [02:31<02:09,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  54% 99/183 [02:31<02:08,  1.53s/it, MovingLoss=3.36, Perplexity=28.68]\u001b[A\n",
            "Iteration:  54% 99/183 [02:33<02:08,  1.53s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  55% 100/183 [02:33<02:06,  1.53s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  55% 100/183 [02:34<02:06,  1.53s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  55% 101/183 [02:34<02:05,  1.53s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  55% 101/183 [02:36<02:05,  1.53s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  56% 102/183 [02:36<02:03,  1.53s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  56% 102/183 [02:37<02:03,  1.53s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  56% 103/183 [02:37<02:02,  1.53s/it, MovingLoss=3.36, Perplexity=28.65]\u001b[A\n",
            "Iteration:  56% 103/183 [02:39<02:02,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  57% 104/183 [02:39<02:00,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  57% 104/183 [02:40<02:00,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  57% 105/183 [02:40<01:59,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  57% 105/183 [02:42<01:59,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  58% 106/183 [02:42<01:57,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  58% 106/183 [02:43<01:57,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  58% 107/183 [02:43<01:56,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  58% 107/183 [02:45<01:56,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  59% 108/183 [02:45<01:54,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  59% 108/183 [02:46<01:54,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  60% 109/183 [02:46<01:53,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  60% 109/183 [02:48<01:53,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  60% 110/183 [02:48<01:51,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  60% 110/183 [02:49<01:51,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  61% 111/183 [02:49<01:50,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  61% 111/183 [02:51<01:50,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  61% 112/183 [02:51<01:48,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  61% 112/183 [02:53<01:48,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  62% 113/183 [02:53<01:47,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  62% 113/183 [02:54<01:47,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  62% 114/183 [02:54<01:45,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  62% 114/183 [02:56<01:45,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  63% 115/183 [02:56<01:44,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  63% 115/183 [02:57<01:44,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  63% 116/183 [02:57<01:42,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  63% 116/183 [02:59<01:42,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  64% 117/183 [02:59<01:40,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  64% 117/183 [03:00<01:40,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  64% 118/183 [03:00<01:39,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  64% 118/183 [03:02<01:39,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  65% 119/183 [03:02<01:37,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  65% 119/183 [03:03<01:37,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  66% 120/183 [03:03<01:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  66% 120/183 [03:05<01:36,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  66% 121/183 [03:05<01:35,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  66% 121/183 [03:06<01:35,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  67% 122/183 [03:06<01:33,  1.53s/it, MovingLoss=3.36, Perplexity=28.67]\u001b[A\n",
            "Iteration:  67% 122/183 [03:08<01:33,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  67% 123/183 [03:08<01:32,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  67% 123/183 [03:09<01:32,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  68% 124/183 [03:09<01:30,  1.54s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  68% 124/183 [03:11<01:30,  1.54s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  68% 125/183 [03:11<01:28,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  68% 125/183 [03:12<01:28,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  69% 126/183 [03:12<01:27,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  69% 126/183 [03:14<01:27,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  69% 127/183 [03:14<01:25,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  69% 127/183 [03:15<01:25,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  70% 128/183 [03:15<01:24,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  70% 128/183 [03:17<01:24,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  70% 129/183 [03:17<01:22,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  70% 129/183 [03:19<01:22,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  71% 130/183 [03:19<01:21,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  71% 130/183 [03:20<01:21,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  72% 131/183 [03:20<01:19,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  72% 131/183 [03:22<01:19,  1.53s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  72% 132/183 [03:22<01:18,  1.54s/it, MovingLoss=3.36, Perplexity=28.66]\u001b[A\n",
            "Iteration:  72% 132/183 [03:23<01:18,  1.54s/it, MovingLoss=3.35, Perplexity=28.64]\u001b[A\n",
            "Iteration:  73% 133/183 [03:23<01:16,  1.54s/it, MovingLoss=3.35, Perplexity=28.64]\u001b[A\n",
            "Iteration:  73% 133/183 [03:25<01:16,  1.54s/it, MovingLoss=3.35, Perplexity=28.64]\u001b[A\n",
            "Iteration:  73% 134/183 [03:25<01:15,  1.54s/it, MovingLoss=3.35, Perplexity=28.64]\u001b[A\n",
            "Iteration:  73% 134/183 [03:26<01:15,  1.54s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  74% 135/183 [03:26<01:13,  1.54s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  74% 135/183 [03:28<01:13,  1.54s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  74% 136/183 [03:28<01:12,  1.54s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  74% 136/183 [03:29<01:12,  1.54s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  75% 137/183 [03:29<01:10,  1.53s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  75% 137/183 [03:31<01:10,  1.53s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  75% 138/183 [03:31<01:09,  1.53s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  75% 138/183 [03:32<01:09,  1.53s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  76% 139/183 [03:32<01:07,  1.53s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  76% 139/183 [03:34<01:07,  1.53s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  77% 140/183 [03:34<01:05,  1.53s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  77% 140/183 [03:35<01:05,  1.53s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  77% 141/183 [03:35<01:04,  1.54s/it, MovingLoss=3.35, Perplexity=28.63]\u001b[A\n",
            "Iteration:  77% 141/183 [03:37<01:04,  1.54s/it, MovingLoss=3.35, Perplexity=28.61]\u001b[A\n",
            "Iteration:  78% 142/183 [03:37<01:02,  1.53s/it, MovingLoss=3.35, Perplexity=28.61]\u001b[A\n",
            "Iteration:  78% 142/183 [03:39<01:02,  1.53s/it, MovingLoss=3.35, Perplexity=28.60]\u001b[A\n",
            "Iteration:  78% 143/183 [03:39<01:01,  1.53s/it, MovingLoss=3.35, Perplexity=28.60]\u001b[A\n",
            "Iteration:  78% 143/183 [03:40<01:01,  1.53s/it, MovingLoss=3.35, Perplexity=28.61]\u001b[A\n",
            "Iteration:  79% 144/183 [03:40<00:59,  1.53s/it, MovingLoss=3.35, Perplexity=28.61]\u001b[A\n",
            "Iteration:  79% 144/183 [03:42<00:59,  1.53s/it, MovingLoss=3.35, Perplexity=28.61]\u001b[A\n",
            "Iteration:  79% 145/183 [03:42<00:58,  1.54s/it, MovingLoss=3.35, Perplexity=28.61]\u001b[A\n",
            "Iteration:  79% 145/183 [03:43<00:58,  1.54s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  80% 146/183 [03:43<00:56,  1.53s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  80% 146/183 [03:45<00:56,  1.53s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  80% 147/183 [03:45<00:55,  1.54s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  80% 147/183 [03:46<00:55,  1.54s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  81% 148/183 [03:46<00:53,  1.54s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  81% 148/183 [03:48<00:53,  1.54s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  81% 149/183 [03:48<00:52,  1.53s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  81% 149/183 [03:49<00:52,  1.53s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  82% 150/183 [03:49<00:50,  1.53s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  82% 150/183 [03:51<00:50,  1.53s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  83% 151/183 [03:51<00:48,  1.53s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  83% 151/183 [03:52<00:48,  1.53s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  83% 152/183 [03:52<00:47,  1.53s/it, MovingLoss=3.35, Perplexity=28.58]\u001b[A\n",
            "Iteration:  83% 152/183 [03:54<00:47,  1.53s/it, MovingLoss=3.35, Perplexity=28.59]\u001b[A\n",
            "Iteration:  84% 153/183 [03:54<00:45,  1.53s/it, MovingLoss=3.35, Perplexity=28.59]\u001b[A\n",
            "Iteration:  84% 153/183 [03:55<00:45,  1.53s/it, MovingLoss=3.35, Perplexity=28.57]\u001b[A\n",
            "Iteration:  84% 154/183 [03:55<00:44,  1.53s/it, MovingLoss=3.35, Perplexity=28.57]\u001b[A\n",
            "Iteration:  84% 154/183 [03:57<00:44,  1.53s/it, MovingLoss=3.35, Perplexity=28.57]\u001b[A\n",
            "Iteration:  85% 155/183 [03:57<00:42,  1.53s/it, MovingLoss=3.35, Perplexity=28.57]\u001b[A\n",
            "Iteration:  85% 155/183 [03:58<00:42,  1.53s/it, MovingLoss=3.35, Perplexity=28.56]\u001b[A\n",
            "Iteration:  85% 156/183 [03:58<00:41,  1.53s/it, MovingLoss=3.35, Perplexity=28.56]\u001b[A\n",
            "Iteration:  85% 156/183 [04:00<00:41,  1.53s/it, MovingLoss=3.35, Perplexity=28.57]\u001b[A\n",
            "Iteration:  86% 157/183 [04:00<00:39,  1.53s/it, MovingLoss=3.35, Perplexity=28.57]\u001b[A\n",
            "Iteration:  86% 157/183 [04:01<00:39,  1.53s/it, MovingLoss=3.35, Perplexity=28.56]\u001b[A\n",
            "Iteration:  86% 158/183 [04:01<00:38,  1.53s/it, MovingLoss=3.35, Perplexity=28.56]\u001b[A\n",
            "Iteration:  86% 158/183 [04:03<00:38,  1.53s/it, MovingLoss=3.35, Perplexity=28.56]\u001b[A\n",
            "Iteration:  87% 159/183 [04:03<00:36,  1.53s/it, MovingLoss=3.35, Perplexity=28.56]\u001b[A\n",
            "Iteration:  87% 159/183 [04:05<00:36,  1.53s/it, MovingLoss=3.35, Perplexity=28.56]\u001b[A\n",
            "Iteration:  87% 160/183 [04:05<00:35,  1.53s/it, MovingLoss=3.35, Perplexity=28.56]\u001b[A\n",
            "Iteration:  87% 160/183 [04:06<00:35,  1.53s/it, MovingLoss=3.35, Perplexity=28.56]\u001b[A\n",
            "Iteration:  88% 161/183 [04:06<00:33,  1.53s/it, MovingLoss=3.35, Perplexity=28.56]\u001b[A\n",
            "Iteration:  88% 161/183 [04:08<00:33,  1.53s/it, MovingLoss=3.35, Perplexity=28.54]\u001b[A\n",
            "Iteration:  89% 162/183 [04:08<00:32,  1.53s/it, MovingLoss=3.35, Perplexity=28.54]\u001b[A\n",
            "Iteration:  89% 162/183 [04:09<00:32,  1.53s/it, MovingLoss=3.35, Perplexity=28.54]\u001b[A\n",
            "Iteration:  89% 163/183 [04:09<00:30,  1.53s/it, MovingLoss=3.35, Perplexity=28.54]\u001b[A\n",
            "Iteration:  89% 163/183 [04:11<00:30,  1.53s/it, MovingLoss=3.35, Perplexity=28.54]\u001b[A\n",
            "Iteration:  90% 164/183 [04:11<00:29,  1.53s/it, MovingLoss=3.35, Perplexity=28.54]\u001b[A\n",
            "Iteration:  90% 164/183 [04:12<00:29,  1.53s/it, MovingLoss=3.35, Perplexity=28.53]\u001b[A\n",
            "Iteration:  90% 165/183 [04:12<00:27,  1.53s/it, MovingLoss=3.35, Perplexity=28.53]\u001b[A\n",
            "Iteration:  90% 165/183 [04:14<00:27,  1.53s/it, MovingLoss=3.35, Perplexity=28.53]\u001b[A\n",
            "Iteration:  91% 166/183 [04:14<00:25,  1.53s/it, MovingLoss=3.35, Perplexity=28.53]\u001b[A\n",
            "Iteration:  91% 166/183 [04:15<00:25,  1.53s/it, MovingLoss=3.35, Perplexity=28.53]\u001b[A\n",
            "Iteration:  91% 167/183 [04:15<00:24,  1.53s/it, MovingLoss=3.35, Perplexity=28.53]\u001b[A\n",
            "Iteration:  91% 167/183 [04:17<00:24,  1.53s/it, MovingLoss=3.35, Perplexity=28.53]\u001b[A\n",
            "Iteration:  92% 168/183 [04:17<00:22,  1.53s/it, MovingLoss=3.35, Perplexity=28.53]\u001b[A\n",
            "Iteration:  92% 168/183 [04:18<00:22,  1.53s/it, MovingLoss=3.35, Perplexity=28.53]\u001b[A\n",
            "Iteration:  92% 169/183 [04:18<00:21,  1.53s/it, MovingLoss=3.35, Perplexity=28.53]\u001b[A\n",
            "Iteration:  92% 169/183 [04:20<00:21,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  93% 170/183 [04:20<00:19,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  93% 170/183 [04:21<00:19,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  93% 171/183 [04:21<00:18,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  93% 171/183 [04:23<00:18,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  94% 172/183 [04:23<00:16,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  94% 172/183 [04:24<00:16,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  95% 173/183 [04:24<00:15,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  95% 173/183 [04:26<00:15,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  95% 174/183 [04:26<00:13,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  95% 174/183 [04:27<00:13,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  96% 175/183 [04:27<00:12,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  96% 175/183 [04:29<00:12,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  96% 176/183 [04:29<00:10,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  96% 176/183 [04:31<00:10,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  97% 177/183 [04:31<00:09,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  97% 177/183 [04:32<00:09,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  97% 178/183 [04:32<00:07,  1.53s/it, MovingLoss=3.35, Perplexity=28.51]\u001b[A\n",
            "Iteration:  97% 178/183 [04:34<00:07,  1.53s/it, MovingLoss=3.35, Perplexity=28.52]\u001b[A\n",
            "Iteration:  98% 179/183 [04:34<00:06,  1.53s/it, MovingLoss=3.35, Perplexity=28.52]\u001b[A\n",
            "Iteration:  98% 179/183 [04:35<00:06,  1.53s/it, MovingLoss=3.35, Perplexity=28.52]\u001b[A\n",
            "Iteration:  98% 180/183 [04:35<00:04,  1.53s/it, MovingLoss=3.35, Perplexity=28.52]\u001b[A\n",
            "Iteration:  98% 180/183 [04:37<00:04,  1.53s/it, MovingLoss=3.35, Perplexity=28.52]\u001b[A\n",
            "Iteration:  99% 181/183 [04:37<00:03,  1.53s/it, MovingLoss=3.35, Perplexity=28.52]\u001b[A\n",
            "Iteration:  99% 181/183 [04:38<00:03,  1.53s/it, MovingLoss=3.35, Perplexity=28.50]\u001b[A\n",
            "Iteration:  99% 182/183 [04:38<00:01,  1.53s/it, MovingLoss=3.35, Perplexity=28.50]\u001b[A\n",
            "Iteration:  99% 182/183 [04:40<00:01,  1.53s/it, MovingLoss=3.35, Perplexity=28.49]\u001b[A\n",
            "Iteration: 100% 183/183 [04:40<00:00,  1.53s/it, MovingLoss=3.35, Perplexity=28.49]\n",
            "\n",
            "  0% 0/500 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 5/500 [00:00<00:11, 43.79it/s]\u001b[A\n",
            "  2% 9/500 [00:00<00:12, 40.91it/s]\u001b[A\n",
            "  2% 12/500 [00:00<00:13, 36.84it/s]\u001b[A\n",
            "  3% 15/500 [00:00<00:14, 34.40it/s]\u001b[A\n",
            "  4% 18/500 [00:00<00:14, 32.84it/s]\u001b[A\n",
            "  4% 21/500 [00:00<00:15, 31.70it/s]\u001b[A\n",
            "  5% 24/500 [00:00<00:15, 30.78it/s]\u001b[A\n",
            "  5% 27/500 [00:00<00:15, 30.12it/s]\u001b[A\n",
            "  6% 30/500 [00:00<00:15, 29.42it/s]\u001b[A\n",
            "  7% 33/500 [00:01<00:16, 29.08it/s]\u001b[A\n",
            "  7% 36/500 [00:01<00:16, 28.73it/s]\u001b[A\n",
            "  8% 39/500 [00:01<00:16, 28.51it/s]\u001b[A\n",
            "  8% 42/500 [00:01<00:16, 28.34it/s]\u001b[A\n",
            "  9% 45/500 [00:01<00:16, 28.06it/s]\u001b[A\n",
            " 10% 48/500 [00:01<00:16, 27.89it/s]\u001b[A\n",
            " 10% 51/500 [00:01<00:16, 27.71it/s]\u001b[A\n",
            " 11% 54/500 [00:01<00:16, 27.54it/s]\u001b[A\n",
            " 11% 57/500 [00:01<00:16, 26.67it/s]\u001b[A\n",
            " 12% 60/500 [00:02<00:17, 25.83it/s]\u001b[A\n",
            " 13% 63/500 [00:02<00:17, 25.18it/s]\u001b[A\n",
            " 13% 66/500 [00:02<00:17, 24.70it/s]\u001b[A\n",
            " 14% 69/500 [00:02<00:17, 24.40it/s]\u001b[A\n",
            " 14% 72/500 [00:02<00:17, 24.12it/s]\u001b[A\n",
            " 15% 75/500 [00:02<00:17, 23.85it/s]\u001b[A\n",
            " 16% 78/500 [00:02<00:17, 23.59it/s]\u001b[A\n",
            " 16% 81/500 [00:02<00:17, 23.47it/s]\u001b[A\n",
            " 17% 84/500 [00:03<00:17, 23.30it/s]\u001b[A\n",
            " 17% 87/500 [00:03<00:17, 23.19it/s]\u001b[A\n",
            " 18% 90/500 [00:03<00:18, 22.77it/s]\u001b[A\n",
            " 19% 93/500 [00:03<00:18, 22.51it/s]\u001b[A\n",
            " 19% 96/500 [00:03<00:18, 22.28it/s]\u001b[A\n",
            " 20% 99/500 [00:03<00:18, 22.05it/s]\u001b[A\n",
            " 20% 102/500 [00:03<00:18, 21.85it/s]\u001b[A\n",
            " 21% 105/500 [00:04<00:18, 21.67it/s]\u001b[A\n",
            " 22% 108/500 [00:04<00:18, 21.52it/s]\u001b[A\n",
            " 22% 111/500 [00:04<00:18, 21.38it/s]\u001b[A\n",
            " 23% 114/500 [00:04<00:18, 21.30it/s]\u001b[A\n",
            " 23% 117/500 [00:04<00:18, 21.18it/s]\u001b[A\n",
            " 24% 120/500 [00:04<00:18, 20.74it/s]\u001b[A\n",
            " 25% 123/500 [00:04<00:18, 19.88it/s]\u001b[A\n",
            " 25% 125/500 [00:05<00:19, 19.31it/s]\u001b[A\n",
            " 25% 127/500 [00:05<00:19, 19.04it/s]\u001b[A\n",
            " 26% 129/500 [00:05<00:19, 18.73it/s]\u001b[A\n",
            " 26% 131/500 [00:05<00:19, 18.47it/s]\u001b[A\n",
            " 27% 133/500 [00:05<00:20, 18.29it/s]\u001b[A\n",
            " 27% 135/500 [00:05<00:20, 18.12it/s]\u001b[A\n",
            " 27% 137/500 [00:05<00:20, 17.98it/s]\u001b[A\n",
            " 28% 139/500 [00:05<00:20, 17.96it/s]\u001b[A\n",
            " 28% 141/500 [00:05<00:20, 17.84it/s]\u001b[A\n",
            " 29% 143/500 [00:06<00:20, 17.76it/s]\u001b[A\n",
            " 29% 145/500 [00:06<00:20, 17.67it/s]\u001b[A\n",
            " 29% 147/500 [00:06<00:20, 17.60it/s]\u001b[A\n",
            " 30% 149/500 [00:06<00:20, 17.52it/s]\u001b[A\n",
            " 30% 151/500 [00:06<00:19, 17.50it/s]\u001b[A\n",
            " 31% 153/500 [00:06<00:20, 17.12it/s]\u001b[A\n",
            " 31% 155/500 [00:06<00:20, 16.85it/s]\u001b[A\n",
            " 31% 157/500 [00:06<00:20, 16.61it/s]\u001b[A\n",
            " 32% 159/500 [00:07<00:20, 16.41it/s]\u001b[A\n",
            " 32% 161/500 [00:07<00:20, 16.24it/s]\u001b[A\n",
            " 33% 163/500 [00:07<00:20, 16.11it/s]\u001b[A\n",
            " 33% 165/500 [00:07<00:20, 16.04it/s]\u001b[A\n",
            " 33% 167/500 [00:07<00:20, 15.99it/s]\u001b[A\n",
            " 34% 169/500 [00:07<00:20, 15.90it/s]\u001b[A\n",
            " 34% 171/500 [00:07<00:20, 15.83it/s]\u001b[A\n",
            " 35% 173/500 [00:07<00:20, 15.76it/s]\u001b[A\n",
            " 35% 175/500 [00:08<00:20, 15.68it/s]\u001b[A\n",
            " 35% 177/500 [00:08<00:20, 15.64it/s]\u001b[A\n",
            " 36% 179/500 [00:08<00:20, 15.59it/s]\u001b[A\n",
            " 36% 181/500 [00:08<00:20, 15.55it/s]\u001b[A\n",
            " 37% 183/500 [00:08<00:20, 15.55it/s]\u001b[A\n",
            " 37% 185/500 [00:08<00:20, 15.13it/s]\u001b[A\n",
            " 37% 187/500 [00:08<00:21, 14.83it/s]\u001b[A\n",
            " 38% 189/500 [00:08<00:21, 14.54it/s]\u001b[A\n",
            " 38% 191/500 [00:09<00:21, 14.28it/s]\u001b[A\n",
            " 39% 193/500 [00:09<00:21, 14.08it/s]\u001b[A\n",
            " 39% 195/500 [00:09<00:21, 13.99it/s]\u001b[A\n",
            " 39% 197/500 [00:09<00:21, 13.91it/s]\u001b[A\n",
            " 40% 199/500 [00:09<00:21, 13.86it/s]\u001b[A\n",
            " 40% 201/500 [00:09<00:21, 13.80it/s]\u001b[A\n",
            " 41% 203/500 [00:09<00:21, 13.68it/s]\u001b[A\n",
            " 41% 205/500 [00:10<00:21, 13.64it/s]\u001b[A\n",
            " 41% 207/500 [00:10<00:21, 13.62it/s]\u001b[A\n",
            " 42% 209/500 [00:10<00:21, 13.60it/s]\u001b[A\n",
            " 42% 211/500 [00:10<00:21, 13.61it/s]\u001b[A\n",
            " 43% 213/500 [00:10<00:21, 13.55it/s]\u001b[A\n",
            " 43% 215/500 [00:10<00:21, 13.52it/s]\u001b[A\n",
            " 43% 217/500 [00:11<00:21, 13.40it/s]\u001b[A\n",
            " 44% 219/500 [00:11<00:21, 13.31it/s]\u001b[A\n",
            " 44% 221/500 [00:11<00:21, 13.22it/s]\u001b[A\n",
            " 45% 223/500 [00:11<00:21, 13.12it/s]\u001b[A\n",
            " 45% 225/500 [00:11<00:21, 13.04it/s]\u001b[A\n",
            " 45% 227/500 [00:11<00:21, 12.95it/s]\u001b[A\n",
            " 46% 229/500 [00:11<00:20, 12.92it/s]\u001b[A\n",
            " 46% 231/500 [00:12<00:20, 12.92it/s]\u001b[A\n",
            " 47% 233/500 [00:12<00:20, 12.90it/s]\u001b[A\n",
            " 47% 235/500 [00:12<00:20, 12.86it/s]\u001b[A\n",
            " 47% 237/500 [00:12<00:20, 12.79it/s]\u001b[A\n",
            " 48% 239/500 [00:12<00:20, 12.75it/s]\u001b[A\n",
            " 48% 241/500 [00:12<00:20, 12.69it/s]\u001b[A\n",
            " 49% 243/500 [00:13<00:20, 12.65it/s]\u001b[A\n",
            " 49% 245/500 [00:13<00:20, 12.62it/s]\u001b[A\n",
            " 49% 247/500 [00:13<00:20, 12.60it/s]\u001b[A\n",
            " 50% 249/500 [00:13<00:20, 12.23it/s]\u001b[A\n",
            " 50% 251/500 [00:13<00:20, 11.94it/s]\u001b[A\n",
            " 51% 253/500 [00:13<00:21, 11.74it/s]\u001b[A\n",
            " 51% 255/500 [00:14<00:21, 11.58it/s]\u001b[A\n",
            " 51% 257/500 [00:14<00:21, 11.50it/s]\u001b[A\n",
            " 52% 259/500 [00:14<00:21, 11.35it/s]\u001b[A\n",
            " 52% 261/500 [00:14<00:21, 11.24it/s]\u001b[A\n",
            " 53% 263/500 [00:14<00:21, 11.22it/s]\u001b[A\n",
            " 53% 265/500 [00:14<00:20, 11.23it/s]\u001b[A\n",
            " 53% 267/500 [00:15<00:20, 11.19it/s]\u001b[A\n",
            " 54% 269/500 [00:15<00:20, 11.09it/s]\u001b[A\n",
            " 54% 271/500 [00:15<00:20, 11.03it/s]\u001b[A\n",
            " 55% 273/500 [00:15<00:20, 10.99it/s]\u001b[A\n",
            " 55% 275/500 [00:15<00:20, 10.99it/s]\u001b[A\n",
            " 55% 277/500 [00:16<00:20, 11.01it/s]\u001b[A\n",
            " 56% 279/500 [00:16<00:20, 10.97it/s]\u001b[A\n",
            " 56% 281/500 [00:16<00:20, 10.85it/s]\u001b[A\n",
            " 57% 283/500 [00:16<00:20, 10.77it/s]\u001b[A\n",
            " 57% 285/500 [00:16<00:20, 10.70it/s]\u001b[A\n",
            " 57% 287/500 [00:17<00:19, 10.70it/s]\u001b[A\n",
            " 58% 289/500 [00:17<00:19, 10.69it/s]\u001b[A\n",
            " 58% 291/500 [00:17<00:19, 10.69it/s]\u001b[A\n",
            " 59% 293/500 [00:17<00:19, 10.64it/s]\u001b[A\n",
            " 59% 295/500 [00:17<00:19, 10.52it/s]\u001b[A\n",
            " 59% 297/500 [00:17<00:19, 10.41it/s]\u001b[A\n",
            " 60% 299/500 [00:18<00:19, 10.36it/s]\u001b[A\n",
            " 60% 301/500 [00:18<00:19, 10.36it/s]\u001b[A\n",
            " 61% 303/500 [00:18<00:19, 10.36it/s]\u001b[A\n",
            " 61% 305/500 [00:18<00:18, 10.33it/s]\u001b[A\n",
            " 61% 307/500 [00:18<00:18, 10.32it/s]\u001b[A\n",
            " 62% 309/500 [00:19<00:18, 10.31it/s]\u001b[A\n",
            " 62% 311/500 [00:19<00:18, 10.31it/s]\u001b[A\n",
            " 63% 313/500 [00:19<00:18, 10.14it/s]\u001b[A\n",
            " 63% 315/500 [00:19<00:18,  9.98it/s]\u001b[A\n",
            " 63% 316/500 [00:19<00:18,  9.84it/s]\u001b[A\n",
            " 63% 317/500 [00:19<00:18,  9.75it/s]\u001b[A\n",
            " 64% 318/500 [00:20<00:18,  9.68it/s]\u001b[A\n",
            " 64% 319/500 [00:20<00:18,  9.63it/s]\u001b[A\n",
            " 64% 320/500 [00:20<00:18,  9.59it/s]\u001b[A\n",
            " 64% 321/500 [00:20<00:18,  9.57it/s]\u001b[A\n",
            " 64% 322/500 [00:20<00:18,  9.54it/s]\u001b[A\n",
            " 65% 323/500 [00:20<00:18,  9.53it/s]\u001b[A\n",
            " 65% 324/500 [00:20<00:18,  9.46it/s]\u001b[A\n",
            " 65% 325/500 [00:20<00:18,  9.40it/s]\u001b[A\n",
            " 65% 326/500 [00:20<00:18,  9.42it/s]\u001b[A\n",
            " 65% 327/500 [00:21<00:18,  9.47it/s]\u001b[A\n",
            " 66% 328/500 [00:21<00:18,  9.51it/s]\u001b[A\n",
            " 66% 329/500 [00:21<00:17,  9.54it/s]\u001b[A\n",
            " 66% 330/500 [00:21<00:17,  9.54it/s]\u001b[A\n",
            " 66% 331/500 [00:21<00:17,  9.49it/s]\u001b[A\n",
            " 66% 332/500 [00:21<00:17,  9.45it/s]\u001b[A\n",
            " 67% 333/500 [00:21<00:17,  9.43it/s]\u001b[A\n",
            " 67% 334/500 [00:21<00:17,  9.40it/s]\u001b[A\n",
            " 67% 335/500 [00:21<00:17,  9.39it/s]\u001b[A\n",
            " 67% 336/500 [00:21<00:17,  9.38it/s]\u001b[A\n",
            " 67% 337/500 [00:22<00:17,  9.37it/s]\u001b[A\n",
            " 68% 338/500 [00:22<00:17,  9.36it/s]\u001b[A\n",
            " 68% 339/500 [00:22<00:17,  9.35it/s]\u001b[A\n",
            " 68% 340/500 [00:22<00:17,  9.34it/s]\u001b[A\n",
            " 68% 341/500 [00:22<00:17,  9.27it/s]\u001b[A\n",
            " 68% 342/500 [00:22<00:17,  9.23it/s]\u001b[A\n",
            " 69% 343/500 [00:22<00:16,  9.25it/s]\u001b[A\n",
            " 69% 344/500 [00:22<00:17,  9.16it/s]\u001b[A\n",
            " 69% 345/500 [00:22<00:17,  9.07it/s]\u001b[A\n",
            " 69% 346/500 [00:23<00:17,  9.02it/s]\u001b[A\n",
            " 69% 347/500 [00:23<00:17,  9.00it/s]\u001b[A\n",
            " 70% 348/500 [00:23<00:16,  8.97it/s]\u001b[A\n",
            " 70% 349/500 [00:23<00:16,  8.94it/s]\u001b[A\n",
            " 70% 350/500 [00:23<00:16,  8.87it/s]\u001b[A\n",
            " 70% 351/500 [00:23<00:16,  8.83it/s]\u001b[A\n",
            " 70% 352/500 [00:23<00:16,  8.82it/s]\u001b[A\n",
            " 71% 353/500 [00:23<00:16,  8.85it/s]\u001b[A\n",
            " 71% 354/500 [00:23<00:16,  8.90it/s]\u001b[A\n",
            " 71% 355/500 [00:24<00:16,  8.91it/s]\u001b[A\n",
            " 71% 356/500 [00:24<00:16,  8.89it/s]\u001b[A\n",
            " 71% 357/500 [00:24<00:16,  8.83it/s]\u001b[A\n",
            " 72% 358/500 [00:24<00:16,  8.77it/s]\u001b[A\n",
            " 72% 359/500 [00:24<00:16,  8.77it/s]\u001b[A\n",
            " 72% 360/500 [00:24<00:15,  8.77it/s]\u001b[A\n",
            " 72% 361/500 [00:24<00:15,  8.81it/s]\u001b[A\n",
            " 72% 362/500 [00:24<00:15,  8.83it/s]\u001b[A\n",
            " 73% 363/500 [00:24<00:15,  8.82it/s]\u001b[A\n",
            " 73% 364/500 [00:25<00:15,  8.80it/s]\u001b[A\n",
            " 73% 365/500 [00:25<00:15,  8.78it/s]\u001b[A\n",
            " 73% 366/500 [00:25<00:15,  8.72it/s]\u001b[A\n",
            " 73% 367/500 [00:25<00:15,  8.73it/s]\u001b[A\n",
            " 74% 368/500 [00:25<00:15,  8.76it/s]\u001b[A\n",
            " 74% 369/500 [00:25<00:14,  8.77it/s]\u001b[A\n",
            " 74% 370/500 [00:25<00:14,  8.75it/s]\u001b[A\n",
            " 74% 371/500 [00:25<00:14,  8.74it/s]\u001b[A\n",
            " 74% 372/500 [00:26<00:14,  8.69it/s]\u001b[A\n",
            " 75% 373/500 [00:26<00:14,  8.61it/s]\u001b[A\n",
            " 75% 374/500 [00:26<00:14,  8.61it/s]\u001b[A\n",
            " 75% 375/500 [00:26<00:14,  8.66it/s]\u001b[A\n",
            " 75% 376/500 [00:26<00:14,  8.55it/s]\u001b[A\n",
            " 75% 377/500 [00:26<00:14,  8.45it/s]\u001b[A\n",
            " 76% 378/500 [00:26<00:14,  8.36it/s]\u001b[A\n",
            " 76% 379/500 [00:26<00:14,  8.30it/s]\u001b[A\n",
            " 76% 380/500 [00:26<00:14,  8.25it/s]\u001b[A\n",
            " 76% 381/500 [00:27<00:14,  8.18it/s]\u001b[A\n",
            " 76% 382/500 [00:27<00:14,  8.18it/s]\u001b[A\n",
            " 77% 383/500 [00:27<00:14,  8.17it/s]\u001b[A\n",
            " 77% 384/500 [00:27<00:14,  8.15it/s]\u001b[A\n",
            " 77% 385/500 [00:27<00:14,  8.18it/s]\u001b[A\n",
            " 77% 386/500 [00:27<00:13,  8.16it/s]\u001b[A\n",
            " 77% 387/500 [00:27<00:13,  8.11it/s]\u001b[A\n",
            " 78% 388/500 [00:27<00:13,  8.11it/s]\u001b[A\n",
            " 78% 389/500 [00:28<00:13,  8.13it/s]\u001b[A\n",
            " 78% 390/500 [00:28<00:13,  8.16it/s]\u001b[A\n",
            " 78% 391/500 [00:28<00:13,  8.16it/s]\u001b[A\n",
            " 78% 392/500 [00:28<00:13,  8.09it/s]\u001b[A\n",
            " 79% 393/500 [00:28<00:13,  8.04it/s]\u001b[A\n",
            " 79% 394/500 [00:28<00:13,  8.04it/s]\u001b[A\n",
            " 79% 395/500 [00:28<00:12,  8.09it/s]\u001b[A\n",
            " 79% 396/500 [00:28<00:12,  8.03it/s]\u001b[A\n",
            " 79% 397/500 [00:29<00:12,  8.02it/s]\u001b[A\n",
            " 80% 398/500 [00:29<00:12,  8.01it/s]\u001b[A\n",
            " 80% 399/500 [00:29<00:12,  8.00it/s]\u001b[A\n",
            " 80% 400/500 [00:29<00:12,  7.96it/s]\u001b[A\n",
            " 80% 401/500 [00:29<00:12,  7.94it/s]\u001b[A\n",
            " 80% 402/500 [00:29<00:12,  7.95it/s]\u001b[A\n",
            " 81% 403/500 [00:29<00:12,  8.00it/s]\u001b[A\n",
            " 81% 404/500 [00:29<00:12,  7.95it/s]\u001b[A\n",
            " 81% 405/500 [00:30<00:11,  7.94it/s]\u001b[A\n",
            " 81% 406/500 [00:30<00:11,  7.96it/s]\u001b[A\n",
            " 81% 407/500 [00:30<00:11,  8.02it/s]\u001b[A\n",
            " 82% 408/500 [00:30<00:11,  7.85it/s]\u001b[A\n",
            " 82% 409/500 [00:30<00:11,  7.76it/s]\u001b[A\n",
            " 82% 410/500 [00:30<00:11,  7.70it/s]\u001b[A\n",
            " 82% 411/500 [00:30<00:11,  7.64it/s]\u001b[A\n",
            " 82% 412/500 [00:30<00:11,  7.68it/s]\u001b[A\n",
            " 83% 413/500 [00:31<00:11,  7.67it/s]\u001b[A\n",
            " 83% 414/500 [00:31<00:11,  7.64it/s]\u001b[A\n",
            " 83% 415/500 [00:31<00:11,  7.63it/s]\u001b[A\n",
            " 83% 416/500 [00:31<00:10,  7.65it/s]\u001b[A\n",
            " 83% 417/500 [00:31<00:10,  7.62it/s]\u001b[A\n",
            " 84% 418/500 [00:31<00:10,  7.59it/s]\u001b[A\n",
            " 84% 419/500 [00:31<00:10,  7.58it/s]\u001b[A\n",
            " 84% 420/500 [00:32<00:10,  7.60it/s]\u001b[A\n",
            " 84% 421/500 [00:32<00:10,  7.59it/s]\u001b[A\n",
            " 84% 422/500 [00:32<00:10,  7.58it/s]\u001b[A\n",
            " 85% 423/500 [00:32<00:10,  7.57it/s]\u001b[A\n",
            " 85% 424/500 [00:32<00:10,  7.52it/s]\u001b[A\n",
            " 85% 425/500 [00:32<00:09,  7.51it/s]\u001b[A\n",
            " 85% 426/500 [00:32<00:09,  7.54it/s]\u001b[A\n",
            " 85% 427/500 [00:32<00:09,  7.50it/s]\u001b[A\n",
            " 86% 428/500 [00:33<00:09,  7.48it/s]\u001b[A\n",
            " 86% 429/500 [00:33<00:09,  7.47it/s]\u001b[A\n",
            " 86% 430/500 [00:33<00:09,  7.44it/s]\u001b[A\n",
            " 86% 431/500 [00:33<00:09,  7.45it/s]\u001b[A\n",
            " 86% 432/500 [00:33<00:09,  7.48it/s]\u001b[A\n",
            " 87% 433/500 [00:33<00:08,  7.47it/s]\u001b[A\n",
            " 87% 434/500 [00:33<00:08,  7.47it/s]\u001b[A\n",
            " 87% 435/500 [00:34<00:08,  7.50it/s]\u001b[A\n",
            " 87% 436/500 [00:34<00:08,  7.44it/s]\u001b[A\n",
            " 87% 437/500 [00:34<00:08,  7.43it/s]\u001b[A\n",
            " 88% 438/500 [00:34<00:08,  7.43it/s]\u001b[A\n",
            " 88% 439/500 [00:34<00:08,  7.45it/s]\u001b[A\n",
            " 88% 440/500 [00:34<00:08,  7.41it/s]\u001b[A\n",
            " 88% 441/500 [00:34<00:08,  7.32it/s]\u001b[A\n",
            " 88% 442/500 [00:35<00:08,  7.22it/s]\u001b[A\n",
            " 89% 443/500 [00:35<00:07,  7.19it/s]\u001b[A\n",
            " 89% 444/500 [00:35<00:07,  7.14it/s]\u001b[A\n",
            " 89% 445/500 [00:35<00:07,  7.10it/s]\u001b[A\n",
            " 89% 446/500 [00:35<00:07,  7.11it/s]\u001b[A\n",
            " 89% 447/500 [00:35<00:07,  7.11it/s]\u001b[A\n",
            " 90% 448/500 [00:35<00:07,  7.09it/s]\u001b[A\n",
            " 90% 449/500 [00:36<00:07,  7.05it/s]\u001b[A\n",
            " 90% 450/500 [00:36<00:07,  7.04it/s]\u001b[A\n",
            " 90% 451/500 [00:36<00:06,  7.05it/s]\u001b[A\n",
            " 90% 452/500 [00:36<00:06,  7.05it/s]\u001b[A\n",
            " 91% 453/500 [00:36<00:06,  7.04it/s]\u001b[A\n",
            " 91% 454/500 [00:36<00:06,  7.01it/s]\u001b[A\n",
            " 91% 455/500 [00:36<00:06,  7.04it/s]\u001b[A\n",
            " 91% 456/500 [00:36<00:06,  7.03it/s]\u001b[A\n",
            " 91% 457/500 [00:37<00:06,  7.03it/s]\u001b[A\n",
            " 92% 458/500 [00:37<00:05,  7.03it/s]\u001b[A\n",
            " 92% 459/500 [00:37<00:05,  7.04it/s]\u001b[A\n",
            " 92% 460/500 [00:37<00:05,  7.03it/s]\u001b[A\n",
            " 92% 461/500 [00:37<00:05,  6.99it/s]\u001b[A\n",
            " 92% 462/500 [00:37<00:05,  6.98it/s]\u001b[A\n",
            " 93% 463/500 [00:37<00:05,  6.99it/s]\u001b[A\n",
            " 93% 464/500 [00:38<00:05,  6.99it/s]\u001b[A\n",
            " 93% 465/500 [00:38<00:05,  6.99it/s]\u001b[A\n",
            " 93% 466/500 [00:38<00:04,  6.99it/s]\u001b[A\n",
            " 93% 467/500 [00:38<00:04,  6.98it/s]\u001b[A\n",
            " 94% 468/500 [00:38<00:04,  6.94it/s]\u001b[A\n",
            " 94% 469/500 [00:38<00:04,  6.95it/s]\u001b[A\n",
            " 94% 470/500 [00:39<00:04,  6.95it/s]\u001b[A\n",
            " 94% 471/500 [00:39<00:04,  6.97it/s]\u001b[A\n",
            " 94% 472/500 [00:39<00:04,  6.90it/s]\u001b[A\n",
            " 95% 473/500 [00:39<00:03,  6.85it/s]\u001b[A\n",
            " 95% 474/500 [00:39<00:03,  6.81it/s]\u001b[A\n",
            " 95% 475/500 [00:39<00:03,  6.78it/s]\u001b[A\n",
            " 95% 476/500 [00:39<00:03,  6.76it/s]\u001b[A\n",
            " 95% 477/500 [00:40<00:03,  6.74it/s]\u001b[A\n",
            " 96% 478/500 [00:40<00:03,  6.73it/s]\u001b[A\n",
            " 96% 479/500 [00:40<00:03,  6.69it/s]\u001b[A\n",
            " 96% 480/500 [00:40<00:02,  6.68it/s]\u001b[A\n",
            " 96% 481/500 [00:40<00:02,  6.69it/s]\u001b[A\n",
            " 96% 482/500 [00:40<00:02,  6.68it/s]\u001b[A\n",
            " 97% 483/500 [00:40<00:02,  6.64it/s]\u001b[A\n",
            " 97% 484/500 [00:41<00:02,  6.65it/s]\u001b[A\n",
            " 97% 485/500 [00:41<00:02,  6.66it/s]\u001b[A\n",
            " 97% 486/500 [00:41<00:02,  6.69it/s]\u001b[A\n",
            " 97% 487/500 [00:41<00:01,  6.66it/s]\u001b[A\n",
            " 98% 488/500 [00:41<00:01,  6.64it/s]\u001b[A\n",
            " 98% 489/500 [00:41<00:01,  6.61it/s]\u001b[A\n",
            " 98% 490/500 [00:41<00:01,  6.60it/s]\u001b[A\n",
            " 98% 491/500 [00:42<00:01,  6.60it/s]\u001b[A\n",
            " 98% 492/500 [00:42<00:01,  6.61it/s]\u001b[A\n",
            " 99% 493/500 [00:42<00:01,  6.61it/s]\u001b[A\n",
            " 99% 494/500 [00:42<00:00,  6.61it/s]\u001b[A\n",
            " 99% 495/500 [00:42<00:00,  6.62it/s]\u001b[A\n",
            " 99% 496/500 [00:42<00:00,  6.61it/s]\u001b[A\n",
            " 99% 497/500 [00:43<00:00,  6.61it/s]\u001b[A\n",
            "100% 498/500 [00:43<00:00,  6.61it/s]\u001b[A\n",
            "100% 499/500 [00:43<00:00,  6.60it/s]\u001b[A\n",
            "100% 500/500 [00:43<00:00, 11.49it/s]\n",
            "  Будьте практичны. Этот день может положить начало длительному периоду постоянного ожидания смерти. Такое приближение тем самым предсказывает смерть, но самым последним голосом, предупреждающим об этом, является довольно странный характерный звук, который часто бывает издан над какой-либо трубой. Иногда человек на мгновение объявляет себе смерть, но рано или поздно этот звук навсегда запечатлевается в его памяти. Если же мы, дети людей, призываем не умирать, то это означает лишь стремление к новым путешествиям, в которых не будет ни торжественного конца, ни изнурительных дней ожидания. Затем мы сами обретаем гораздо больше радости, чем были готовы потратить. Даже самые нетерпеливые защитники жизни сразу прекращают по меньшей мере погоню за смертью, чувствуя свою вину перед тем, что были не правы, отрицая эту очевидную истину.\n",
            "\n",
            "На время следует воздать должное, что замечание о том, что человека не лишают жизни, уже не является такой уж убедительной рекомендацией. Однако слова, а также последовательное понимание ими ценности жизни на Востоке и родственных узы с другими людьми составляют эту книгу, особенно после достижения ею высокого положения.\n",
            "\n",
            "\n",
            "Глава XXII\n",
            "\n",
            "О КУДЕСНИКЕ И ЕГО СОКРАЩЕНИИ ВАМИ\n",
            "\n",
            "\n",
            "Источник беспокойства, проблем, просьб, беспокойств\n",
            "\n",
            "\n",
            "Каждый ли маг или колдун думает только о собственном спасении. Трудно предположить, насколько полезным будет это знание для успеха жизни.\n",
            "\n",
            "Наши мысли и сердца лишь создают иллюзию безопасности и благополучия. Однако информация о существовании порождают множество тревог и даже волнений и разрушают все видимое и осязаемое.\n",
            "\n",
            "Есть тысячи причин, из-за которых в действительности трудность жизни уменьшается и мы с ужасом вспоминаем о том, что происходит, но, как только человек обретает твердость духа, уверенность и выдержку, перед ним открывается гораздо более сложная перспектива жизни и будущее, которое кажется таким далеким и опасным.\n",
            "\n",
            "Даже у самых отважных и сильных духом людей приходит в голову мысль, что если они могли бы оставить свет в этой жизни, то получили бы утешение в самой мрачной тюрьме, в которой им предстоит находиться. О своих страхах мы забываем из страха, что в подобной ситуации мы будем страдать в первую очередь от страха, от которого в точности зависим и который лишь ослабляет наше сопротивление, пока оно не сломлено полностью!\n",
            "\n",
            "Это борьба на грани безрассудства. Несмотря на то что мы избегаем крупных авантюр и авантюризма в тех случаях, когда один из нас рискует своей жизнью, существует опасность для других людей, которые решаются на борьбу ради и прощение Бога. Поскольку люди часто создают в своей жизни цели, к которым стремятся только для достижения цели, для которой они совершают серьезные труды, мы используем подобную\n",
            "Epoch:  80% 4/5 [21:35<05:23, 323.93s/it]\n",
            "Iteration:   0% 0/183 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   0% 0/183 [00:01<?, ?it/s, MovingLoss=3.35, Perplexity=28.50]\u001b[A\n",
            "Iteration:   1% 1/183 [00:01<04:37,  1.52s/it, MovingLoss=3.35, Perplexity=28.50]\u001b[A\n",
            "Iteration:   1% 1/183 [00:03<04:37,  1.52s/it, MovingLoss=3.35, Perplexity=28.49]\u001b[A\n",
            "Iteration:   1% 2/183 [00:03<04:36,  1.53s/it, MovingLoss=3.35, Perplexity=28.49]\u001b[A\n",
            "Iteration:   1% 2/183 [00:04<04:36,  1.53s/it, MovingLoss=3.35, Perplexity=28.47]\u001b[A\n",
            "Iteration:   2% 3/183 [00:04<04:34,  1.52s/it, MovingLoss=3.35, Perplexity=28.47]\u001b[A\n",
            "Iteration:   2% 3/183 [00:06<04:34,  1.52s/it, MovingLoss=3.35, Perplexity=28.47]\u001b[A\n",
            "Iteration:   2% 4/183 [00:06<04:33,  1.53s/it, MovingLoss=3.35, Perplexity=28.47]\u001b[A\n",
            "Iteration:   2% 4/183 [00:07<04:33,  1.53s/it, MovingLoss=3.35, Perplexity=28.47]\u001b[A\n",
            "Iteration:   3% 5/183 [00:07<04:31,  1.53s/it, MovingLoss=3.35, Perplexity=28.47]\u001b[A\n",
            "Iteration:   3% 5/183 [00:09<04:31,  1.53s/it, MovingLoss=3.35, Perplexity=28.48]\u001b[A\n",
            "Iteration:   3% 6/183 [00:09<04:30,  1.53s/it, MovingLoss=3.35, Perplexity=28.48]\u001b[A\n",
            "Iteration:   3% 6/183 [00:10<04:30,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:   4% 7/183 [00:10<04:28,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:   4% 7/183 [00:12<04:28,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   4% 8/183 [00:12<04:27,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   4% 8/183 [00:13<04:27,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   5% 9/183 [00:13<04:26,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   5% 9/183 [00:15<04:26,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:   5% 10/183 [00:15<04:24,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:   5% 10/183 [00:16<04:24,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   6% 11/183 [00:16<04:23,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   6% 11/183 [00:18<04:23,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   7% 12/183 [00:18<04:21,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   7% 12/183 [00:19<04:21,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   7% 13/183 [00:19<04:20,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   7% 13/183 [00:21<04:20,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   8% 14/183 [00:21<04:18,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   8% 14/183 [00:22<04:18,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   8% 15/183 [00:22<04:17,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   8% 15/183 [00:24<04:17,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   9% 16/183 [00:24<04:15,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   9% 16/183 [00:26<04:15,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   9% 17/183 [00:26<04:14,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:   9% 17/183 [00:27<04:14,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:  10% 18/183 [00:27<04:12,  1.53s/it, MovingLoss=3.35, Perplexity=28.46]\u001b[A\n",
            "Iteration:  10% 18/183 [00:29<04:12,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:  10% 19/183 [00:29<04:10,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:  10% 19/183 [00:30<04:10,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:  11% 20/183 [00:30<04:08,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:  11% 20/183 [00:32<04:08,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:  11% 21/183 [00:32<04:07,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:  11% 21/183 [00:33<04:07,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:  12% 22/183 [00:33<04:06,  1.53s/it, MovingLoss=3.35, Perplexity=28.45]\u001b[A\n",
            "Iteration:  12% 22/183 [00:35<04:06,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  13% 23/183 [00:35<04:04,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  13% 23/183 [00:36<04:04,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  13% 24/183 [00:36<04:03,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  13% 24/183 [00:38<04:03,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  14% 25/183 [00:38<04:02,  1.54s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  14% 25/183 [00:39<04:02,  1.54s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  14% 26/183 [00:39<04:01,  1.54s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  14% 26/183 [00:41<04:01,  1.54s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  15% 27/183 [00:41<03:59,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  15% 27/183 [00:42<03:59,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  15% 28/183 [00:42<03:57,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  15% 28/183 [00:44<03:57,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  16% 29/183 [00:44<03:55,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  16% 29/183 [00:45<03:55,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  16% 30/183 [00:45<03:53,  1.53s/it, MovingLoss=3.35, Perplexity=28.43]\u001b[A\n",
            "Iteration:  16% 30/183 [00:47<03:53,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  17% 31/183 [00:47<03:52,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  17% 31/183 [00:48<03:52,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  17% 32/183 [00:48<03:50,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  17% 32/183 [00:50<03:50,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  18% 33/183 [00:50<03:49,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  18% 33/183 [00:52<03:49,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  19% 34/183 [00:52<03:48,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  19% 34/183 [00:53<03:48,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  19% 35/183 [00:53<03:47,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  19% 35/183 [00:55<03:47,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  20% 36/183 [00:55<03:45,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  20% 36/183 [00:56<03:45,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  20% 37/183 [00:56<03:44,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  20% 37/183 [00:58<03:44,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  21% 38/183 [00:58<03:42,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  21% 38/183 [00:59<03:42,  1.53s/it, MovingLoss=3.35, Perplexity=28.42]\u001b[A\n",
            "Iteration:  21% 39/183 [00:59<03:40,  1.53s/it, MovingLoss=3.35, Perplexity=28.42]\u001b[A\n",
            "Iteration:  21% 39/183 [01:01<03:40,  1.53s/it, MovingLoss=3.35, Perplexity=28.42]\u001b[A\n",
            "Iteration:  22% 40/183 [01:01<03:38,  1.53s/it, MovingLoss=3.35, Perplexity=28.42]\u001b[A\n",
            "Iteration:  22% 40/183 [01:02<03:38,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  22% 41/183 [01:02<03:37,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  22% 41/183 [01:04<03:37,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  23% 42/183 [01:04<03:36,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  23% 42/183 [01:05<03:36,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  23% 43/183 [01:05<03:35,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  23% 43/183 [01:07<03:35,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  24% 44/183 [01:07<03:33,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  24% 44/183 [01:08<03:33,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  25% 45/183 [01:08<03:32,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  25% 45/183 [01:10<03:32,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  25% 46/183 [01:10<03:30,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  25% 46/183 [01:11<03:30,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  26% 47/183 [01:11<03:28,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  26% 47/183 [01:13<03:28,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  26% 48/183 [01:13<03:27,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  26% 48/183 [01:15<03:27,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  27% 49/183 [01:15<03:25,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  27% 49/183 [01:16<03:25,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  27% 50/183 [01:16<03:24,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  27% 50/183 [01:18<03:24,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  28% 51/183 [01:18<03:22,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  28% 51/183 [01:19<03:22,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  28% 52/183 [01:19<03:21,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  28% 52/183 [01:21<03:21,  1.54s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  29% 53/183 [01:21<03:19,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  29% 53/183 [01:22<03:19,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  30% 54/183 [01:22<03:17,  1.53s/it, MovingLoss=3.35, Perplexity=28.41]\u001b[A\n",
            "Iteration:  30% 54/183 [01:24<03:17,  1.53s/it, MovingLoss=3.35, Perplexity=28.39]\u001b[A\n",
            "Iteration:  30% 55/183 [01:24<03:15,  1.53s/it, MovingLoss=3.35, Perplexity=28.39]\u001b[A\n",
            "Iteration:  30% 55/183 [01:25<03:15,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  31% 56/183 [01:25<03:14,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  31% 56/183 [01:27<03:14,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  31% 57/183 [01:27<03:12,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  31% 57/183 [01:28<03:12,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  32% 58/183 [01:28<03:11,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  32% 58/183 [01:30<03:11,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  32% 59/183 [01:30<03:10,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  32% 59/183 [01:31<03:10,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  33% 60/183 [01:31<03:08,  1.54s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  33% 60/183 [01:33<03:08,  1.54s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  33% 61/183 [01:33<03:06,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  33% 61/183 [01:34<03:06,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  34% 62/183 [01:34<03:05,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  34% 62/183 [01:36<03:05,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  34% 63/183 [01:36<03:03,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  34% 63/183 [01:38<03:03,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  35% 64/183 [01:38<03:02,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  35% 64/183 [01:39<03:02,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  36% 65/183 [01:39<03:00,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  36% 65/183 [01:41<03:00,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  36% 66/183 [01:41<02:59,  1.53s/it, MovingLoss=3.35, Perplexity=28.37]\u001b[A\n",
            "Iteration:  36% 66/183 [01:42<02:59,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  37% 67/183 [01:42<02:58,  1.54s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  37% 67/183 [01:44<02:58,  1.54s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  37% 68/183 [01:44<02:56,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  37% 68/183 [01:45<02:56,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  38% 69/183 [01:45<02:54,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  38% 69/183 [01:47<02:54,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  38% 70/183 [01:47<02:53,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  38% 70/183 [01:48<02:53,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  39% 71/183 [01:48<02:51,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  39% 71/183 [01:50<02:51,  1.53s/it, MovingLoss=3.34, Perplexity=28.34]\u001b[A\n",
            "Iteration:  39% 72/183 [01:50<02:49,  1.53s/it, MovingLoss=3.34, Perplexity=28.34]\u001b[A\n",
            "Iteration:  39% 72/183 [01:51<02:49,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  40% 73/183 [01:51<02:48,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  40% 73/183 [01:53<02:48,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  40% 74/183 [01:53<02:47,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  40% 74/183 [01:54<02:47,  1.53s/it, MovingLoss=3.34, Perplexity=28.34]\u001b[A\n",
            "Iteration:  41% 75/183 [01:54<02:45,  1.53s/it, MovingLoss=3.34, Perplexity=28.34]\u001b[A\n",
            "Iteration:  41% 75/183 [01:56<02:45,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  42% 76/183 [01:56<02:44,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  42% 76/183 [01:57<02:44,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  42% 77/183 [01:57<02:42,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  42% 77/183 [01:59<02:42,  1.53s/it, MovingLoss=3.34, Perplexity=28.34]\u001b[A\n",
            "Iteration:  43% 78/183 [01:59<02:40,  1.53s/it, MovingLoss=3.34, Perplexity=28.34]\u001b[A\n",
            "Iteration:  43% 78/183 [02:01<02:40,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  43% 79/183 [02:01<02:39,  1.53s/it, MovingLoss=3.34, Perplexity=28.35]\u001b[A\n",
            "Iteration:  43% 79/183 [02:02<02:39,  1.53s/it, MovingLoss=3.34, Perplexity=28.34]\u001b[A\n",
            "Iteration:  44% 80/183 [02:02<02:37,  1.53s/it, MovingLoss=3.34, Perplexity=28.34]\u001b[A\n",
            "Iteration:  44% 80/183 [02:04<02:37,  1.53s/it, MovingLoss=3.34, Perplexity=28.34]\u001b[A\n",
            "Iteration:  44% 81/183 [02:04<02:36,  1.53s/it, MovingLoss=3.34, Perplexity=28.34]\u001b[A\n",
            "Iteration:  44% 81/183 [02:05<02:36,  1.53s/it, MovingLoss=3.34, Perplexity=28.32]\u001b[A\n",
            "Iteration:  45% 82/183 [02:05<02:35,  1.53s/it, MovingLoss=3.34, Perplexity=28.32]\u001b[A\n",
            "Iteration:  45% 82/183 [02:07<02:35,  1.53s/it, MovingLoss=3.34, Perplexity=28.32]\u001b[A\n",
            "Iteration:  45% 83/183 [02:07<02:33,  1.53s/it, MovingLoss=3.34, Perplexity=28.32]\u001b[A\n",
            "Iteration:  45% 83/183 [02:08<02:33,  1.53s/it, MovingLoss=3.34, Perplexity=28.32]\u001b[A\n",
            "Iteration:  46% 84/183 [02:08<02:31,  1.53s/it, MovingLoss=3.34, Perplexity=28.32]\u001b[A\n",
            "Iteration:  46% 84/183 [02:10<02:31,  1.53s/it, MovingLoss=3.34, Perplexity=28.32]\u001b[A\n",
            "Iteration:  46% 85/183 [02:10<02:29,  1.53s/it, MovingLoss=3.34, Perplexity=28.32]\u001b[A\n",
            "Iteration:  46% 85/183 [02:11<02:29,  1.53s/it, MovingLoss=3.34, Perplexity=28.32]\u001b[A\n",
            "Iteration:  47% 86/183 [02:11<02:28,  1.53s/it, MovingLoss=3.34, Perplexity=28.32]\u001b[A\n",
            "Iteration:  47% 86/183 [02:13<02:28,  1.53s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  48% 87/183 [02:13<02:26,  1.53s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  48% 87/183 [02:14<02:26,  1.53s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  48% 88/183 [02:14<02:25,  1.53s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  48% 88/183 [02:16<02:25,  1.53s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  49% 89/183 [02:16<02:24,  1.53s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  49% 89/183 [02:17<02:24,  1.53s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  49% 90/183 [02:17<02:22,  1.53s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  49% 90/183 [02:19<02:22,  1.53s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  50% 91/183 [02:19<02:21,  1.54s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  50% 91/183 [02:20<02:21,  1.54s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  50% 92/183 [02:20<02:19,  1.54s/it, MovingLoss=3.34, Perplexity=28.31]\u001b[A\n",
            "Iteration:  50% 92/183 [02:22<02:19,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  51% 93/183 [02:22<02:18,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  51% 93/183 [02:24<02:18,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  51% 94/183 [02:24<02:16,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  51% 94/183 [02:25<02:16,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  52% 95/183 [02:25<02:15,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  52% 95/183 [02:27<02:15,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  52% 96/183 [02:27<02:13,  1.53s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  52% 96/183 [02:28<02:13,  1.53s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  53% 97/183 [02:28<02:12,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  53% 97/183 [02:30<02:12,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  54% 98/183 [02:30<02:10,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  54% 98/183 [02:31<02:10,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  54% 99/183 [02:31<02:09,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  54% 99/183 [02:33<02:09,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  55% 100/183 [02:33<02:07,  1.54s/it, MovingLoss=3.34, Perplexity=28.29]\u001b[A\n",
            "Iteration:  55% 100/183 [02:34<02:07,  1.54s/it, MovingLoss=3.34, Perplexity=28.28]\u001b[A\n",
            "Iteration:  55% 101/183 [02:34<02:06,  1.54s/it, MovingLoss=3.34, Perplexity=28.28]\u001b[A\n",
            "Iteration:  55% 101/183 [02:36<02:06,  1.54s/it, MovingLoss=3.34, Perplexity=28.28]\u001b[A\n",
            "Iteration:  56% 102/183 [02:36<02:04,  1.54s/it, MovingLoss=3.34, Perplexity=28.28]\u001b[A\n",
            "Iteration:  56% 102/183 [02:37<02:04,  1.54s/it, MovingLoss=3.34, Perplexity=28.28]\u001b[A\n",
            "Iteration:  56% 103/183 [02:37<02:03,  1.54s/it, MovingLoss=3.34, Perplexity=28.28]\u001b[A\n",
            "Iteration:  56% 103/183 [02:39<02:03,  1.54s/it, MovingLoss=3.34, Perplexity=28.28]\u001b[A\n",
            "Iteration:  57% 104/183 [02:39<02:01,  1.54s/it, MovingLoss=3.34, Perplexity=28.28]\u001b[A\n",
            "Iteration:  57% 104/183 [02:40<02:01,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  57% 105/183 [02:40<02:00,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  57% 105/183 [02:42<02:00,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  58% 106/183 [02:42<01:58,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  58% 106/183 [02:44<01:58,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  58% 107/183 [02:44<01:57,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  58% 107/183 [02:45<01:57,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  59% 108/183 [02:45<01:55,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  59% 108/183 [02:47<01:55,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  60% 109/183 [02:47<01:53,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  60% 109/183 [02:48<01:53,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  60% 110/183 [02:48<01:52,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  60% 110/183 [02:50<01:52,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  61% 111/183 [02:50<01:50,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  61% 111/183 [02:51<01:50,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  61% 112/183 [02:51<01:49,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  61% 112/183 [02:53<01:49,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  62% 113/183 [02:53<01:47,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  62% 113/183 [02:54<01:47,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  62% 114/183 [02:54<01:45,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  62% 114/183 [02:56<01:45,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  63% 115/183 [02:56<01:44,  1.54s/it, MovingLoss=3.34, Perplexity=28.26]\u001b[A\n",
            "Iteration:  63% 115/183 [02:57<01:44,  1.54s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  63% 116/183 [02:57<01:42,  1.53s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  63% 116/183 [02:59<01:42,  1.53s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  64% 117/183 [02:59<01:41,  1.54s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  64% 117/183 [03:00<01:41,  1.54s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  64% 118/183 [03:00<01:39,  1.54s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  64% 118/183 [03:02<01:39,  1.54s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  65% 119/183 [03:02<01:38,  1.54s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  65% 119/183 [03:04<01:38,  1.54s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  66% 120/183 [03:04<01:36,  1.54s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  66% 120/183 [03:05<01:36,  1.54s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  66% 121/183 [03:05<01:35,  1.53s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  66% 121/183 [03:07<01:35,  1.53s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  67% 122/183 [03:07<01:33,  1.53s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  67% 122/183 [03:08<01:33,  1.53s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  67% 123/183 [03:08<01:31,  1.53s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  67% 123/183 [03:10<01:31,  1.53s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  68% 124/183 [03:10<01:30,  1.53s/it, MovingLoss=3.34, Perplexity=28.24]\u001b[A\n",
            "Iteration:  68% 124/183 [03:11<01:30,  1.53s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  68% 125/183 [03:11<01:29,  1.54s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  68% 125/183 [03:13<01:29,  1.54s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  69% 126/183 [03:13<01:27,  1.54s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  69% 126/183 [03:14<01:27,  1.54s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  69% 127/183 [03:14<01:26,  1.54s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  69% 127/183 [03:16<01:26,  1.54s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  70% 128/183 [03:16<01:24,  1.53s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  70% 128/183 [03:17<01:24,  1.53s/it, MovingLoss=3.34, Perplexity=28.22]\u001b[A\n",
            "Iteration:  70% 129/183 [03:17<01:22,  1.53s/it, MovingLoss=3.34, Perplexity=28.22]\u001b[A\n",
            "Iteration:  70% 129/183 [03:19<01:22,  1.53s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  71% 130/183 [03:19<01:21,  1.53s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  71% 130/183 [03:20<01:21,  1.53s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  72% 131/183 [03:20<01:19,  1.54s/it, MovingLoss=3.34, Perplexity=28.23]\u001b[A\n",
            "Iteration:  72% 131/183 [03:22<01:19,  1.54s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  72% 132/183 [03:22<01:18,  1.53s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  72% 132/183 [03:23<01:18,  1.53s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  73% 133/183 [03:23<01:16,  1.54s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  73% 133/183 [03:25<01:16,  1.54s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  73% 134/183 [03:25<01:15,  1.54s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  73% 134/183 [03:27<01:15,  1.54s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  74% 135/183 [03:27<01:14,  1.54s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  74% 135/183 [03:28<01:14,  1.54s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  74% 136/183 [03:28<01:12,  1.54s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  74% 136/183 [03:30<01:12,  1.54s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  75% 137/183 [03:30<01:10,  1.54s/it, MovingLoss=3.34, Perplexity=28.21]\u001b[A\n",
            "Iteration:  75% 137/183 [03:31<01:10,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  75% 138/183 [03:31<01:09,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  75% 138/183 [03:33<01:09,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  76% 139/183 [03:33<01:07,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  76% 139/183 [03:34<01:07,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  77% 140/183 [03:34<01:06,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  77% 140/183 [03:36<01:06,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  77% 141/183 [03:36<01:04,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  77% 141/183 [03:37<01:04,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  78% 142/183 [03:37<01:03,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  78% 142/183 [03:39<01:03,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  78% 143/183 [03:39<01:01,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  78% 143/183 [03:40<01:01,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  79% 144/183 [03:40<01:00,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  79% 144/183 [03:42<01:00,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  79% 145/183 [03:42<00:58,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  79% 145/183 [03:44<00:58,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  80% 146/183 [03:44<00:56,  1.54s/it, MovingLoss=3.34, Perplexity=28.19]\u001b[A\n",
            "Iteration:  80% 146/183 [03:45<00:56,  1.54s/it, MovingLoss=3.34, Perplexity=28.18]\u001b[A\n",
            "Iteration:  80% 147/183 [03:45<00:55,  1.54s/it, MovingLoss=3.34, Perplexity=28.18]\u001b[A\n",
            "Iteration:  80% 147/183 [03:47<00:55,  1.54s/it, MovingLoss=3.34, Perplexity=28.18]\u001b[A\n",
            "Iteration:  81% 148/183 [03:47<00:53,  1.54s/it, MovingLoss=3.34, Perplexity=28.18]\u001b[A\n",
            "Iteration:  81% 148/183 [03:48<00:53,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  81% 149/183 [03:48<00:52,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  81% 149/183 [03:50<00:52,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  82% 150/183 [03:50<00:50,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  82% 150/183 [03:51<00:50,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  83% 151/183 [03:51<00:49,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  83% 151/183 [03:53<00:49,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  83% 152/183 [03:53<00:47,  1.53s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  83% 152/183 [03:54<00:47,  1.53s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  84% 153/183 [03:54<00:46,  1.53s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  84% 153/183 [03:56<00:46,  1.53s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  84% 154/183 [03:56<00:44,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  84% 154/183 [03:57<00:44,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  85% 155/183 [03:57<00:43,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  85% 155/183 [03:59<00:43,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  85% 156/183 [03:59<00:41,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  85% 156/183 [04:00<00:41,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  86% 157/183 [04:00<00:39,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  86% 157/183 [04:02<00:39,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  86% 158/183 [04:02<00:38,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  86% 158/183 [04:04<00:38,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  87% 159/183 [04:04<00:36,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  87% 159/183 [04:05<00:36,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  87% 160/183 [04:05<00:35,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  87% 160/183 [04:07<00:35,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  88% 161/183 [04:07<00:33,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  88% 161/183 [04:08<00:33,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  89% 162/183 [04:08<00:32,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  89% 162/183 [04:10<00:32,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  89% 163/183 [04:10<00:30,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  89% 163/183 [04:11<00:30,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  90% 164/183 [04:11<00:29,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  90% 164/183 [04:13<00:29,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  90% 165/183 [04:13<00:27,  1.53s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  90% 165/183 [04:14<00:27,  1.53s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  91% 166/183 [04:14<00:26,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  91% 166/183 [04:16<00:26,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  91% 167/183 [04:16<00:24,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  91% 167/183 [04:17<00:24,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  92% 168/183 [04:17<00:23,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  92% 168/183 [04:19<00:23,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  92% 169/183 [04:19<00:21,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  92% 169/183 [04:20<00:21,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  93% 170/183 [04:20<00:20,  1.54s/it, MovingLoss=3.34, Perplexity=28.17]\u001b[A\n",
            "Iteration:  93% 170/183 [04:22<00:20,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  93% 171/183 [04:22<00:18,  1.55s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  93% 171/183 [04:24<00:18,  1.55s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  94% 172/183 [04:24<00:16,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  94% 172/183 [04:25<00:16,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  95% 173/183 [04:25<00:15,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  95% 173/183 [04:27<00:15,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  95% 174/183 [04:27<00:13,  1.54s/it, MovingLoss=3.34, Perplexity=28.16]\u001b[A\n",
            "Iteration:  95% 174/183 [04:28<00:13,  1.54s/it, MovingLoss=3.34, Perplexity=28.15]\u001b[A\n",
            "Iteration:  96% 175/183 [04:28<00:12,  1.54s/it, MovingLoss=3.34, Perplexity=28.15]\u001b[A\n",
            "Iteration:  96% 175/183 [04:30<00:12,  1.54s/it, MovingLoss=3.34, Perplexity=28.15]\u001b[A\n",
            "Iteration:  96% 176/183 [04:30<00:10,  1.54s/it, MovingLoss=3.34, Perplexity=28.15]\u001b[A\n",
            "Iteration:  96% 176/183 [04:31<00:10,  1.54s/it, MovingLoss=3.34, Perplexity=28.11]\u001b[A\n",
            "Iteration:  97% 177/183 [04:31<00:09,  1.54s/it, MovingLoss=3.34, Perplexity=28.11]\u001b[A\n",
            "Iteration:  97% 177/183 [04:33<00:09,  1.54s/it, MovingLoss=3.34, Perplexity=28.10]\u001b[A\n",
            "Iteration:  97% 178/183 [04:33<00:07,  1.54s/it, MovingLoss=3.34, Perplexity=28.10]\u001b[A\n",
            "Iteration:  97% 178/183 [04:34<00:07,  1.54s/it, MovingLoss=3.34, Perplexity=28.09]\u001b[A\n",
            "Iteration:  98% 179/183 [04:34<00:06,  1.54s/it, MovingLoss=3.34, Perplexity=28.09]\u001b[A\n",
            "Iteration:  98% 179/183 [04:36<00:06,  1.54s/it, MovingLoss=3.34, Perplexity=28.09]\u001b[A\n",
            "Iteration:  98% 180/183 [04:36<00:04,  1.54s/it, MovingLoss=3.34, Perplexity=28.09]\u001b[A\n",
            "Iteration:  98% 180/183 [04:37<00:04,  1.54s/it, MovingLoss=3.34, Perplexity=28.10]\u001b[A\n",
            "Iteration:  99% 181/183 [04:37<00:03,  1.54s/it, MovingLoss=3.34, Perplexity=28.10]\u001b[A\n",
            "Iteration:  99% 181/183 [04:39<00:03,  1.54s/it, MovingLoss=3.34, Perplexity=28.10]\u001b[A\n",
            "Iteration:  99% 182/183 [04:39<00:01,  1.54s/it, MovingLoss=3.34, Perplexity=28.10]\u001b[A\n",
            "Iteration:  99% 182/183 [04:40<00:01,  1.54s/it, MovingLoss=3.34, Perplexity=28.10]\u001b[A\n",
            "Iteration: 100% 183/183 [04:40<00:00,  1.54s/it, MovingLoss=3.34, Perplexity=28.10]\n",
            "\n",
            "  0% 0/500 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 5/500 [00:00<00:11, 44.83it/s]\u001b[A\n",
            "  2% 9/500 [00:00<00:11, 41.59it/s]\u001b[A\n",
            "  3% 13/500 [00:00<00:13, 37.29it/s]\u001b[A\n",
            "  3% 16/500 [00:00<00:13, 34.62it/s]\u001b[A\n",
            "  4% 19/500 [00:00<00:14, 32.81it/s]\u001b[A\n",
            "  4% 22/500 [00:00<00:15, 31.70it/s]\u001b[A\n",
            "  5% 25/500 [00:00<00:15, 30.87it/s]\u001b[A\n",
            "  6% 28/500 [00:00<00:15, 30.18it/s]\u001b[A\n",
            "  6% 31/500 [00:00<00:15, 29.64it/s]\u001b[A\n",
            "  7% 34/500 [00:01<00:15, 29.16it/s]\u001b[A\n",
            "  7% 37/500 [00:01<00:16, 28.87it/s]\u001b[A\n",
            "  8% 40/500 [00:01<00:16, 28.58it/s]\u001b[A\n",
            "  9% 43/500 [00:01<00:16, 28.37it/s]\u001b[A\n",
            "  9% 46/500 [00:01<00:16, 28.17it/s]\u001b[A\n",
            " 10% 49/500 [00:01<00:16, 27.82it/s]\u001b[A\n",
            " 10% 52/500 [00:01<00:16, 27.68it/s]\u001b[A\n",
            " 11% 55/500 [00:01<00:16, 27.53it/s]\u001b[A\n",
            " 12% 58/500 [00:01<00:16, 26.26it/s]\u001b[A\n",
            " 12% 61/500 [00:02<00:17, 25.52it/s]\u001b[A\n",
            " 13% 64/500 [00:02<00:17, 25.01it/s]\u001b[A\n",
            " 13% 67/500 [00:02<00:17, 24.58it/s]\u001b[A\n",
            " 14% 70/500 [00:02<00:17, 24.29it/s]\u001b[A\n",
            " 15% 73/500 [00:02<00:17, 24.00it/s]\u001b[A\n",
            " 15% 76/500 [00:02<00:17, 23.69it/s]\u001b[A\n",
            " 16% 79/500 [00:02<00:17, 23.56it/s]\u001b[A\n",
            " 16% 82/500 [00:02<00:17, 23.35it/s]\u001b[A\n",
            " 17% 85/500 [00:03<00:17, 23.20it/s]\u001b[A\n",
            " 18% 88/500 [00:03<00:17, 22.99it/s]\u001b[A\n",
            " 18% 91/500 [00:03<00:18, 22.63it/s]\u001b[A\n",
            " 19% 94/500 [00:03<00:18, 22.35it/s]\u001b[A\n",
            " 19% 97/500 [00:03<00:18, 22.05it/s]\u001b[A\n",
            " 20% 100/500 [00:03<00:18, 21.90it/s]\u001b[A\n",
            " 21% 103/500 [00:03<00:18, 21.73it/s]\u001b[A\n",
            " 21% 106/500 [00:04<00:18, 21.60it/s]\u001b[A\n",
            " 22% 109/500 [00:04<00:18, 21.47it/s]\u001b[A\n",
            " 22% 112/500 [00:04<00:18, 21.35it/s]\u001b[A\n",
            " 23% 115/500 [00:04<00:18, 21.26it/s]\u001b[A\n",
            " 24% 118/500 [00:04<00:18, 21.13it/s]\u001b[A\n",
            " 24% 121/500 [00:04<00:18, 20.53it/s]\u001b[A\n",
            " 25% 124/500 [00:04<00:18, 19.85it/s]\u001b[A\n",
            " 25% 126/500 [00:05<00:19, 19.30it/s]\u001b[A\n",
            " 26% 128/500 [00:05<00:19, 18.89it/s]\u001b[A\n",
            " 26% 130/500 [00:05<00:19, 18.57it/s]\u001b[A\n",
            " 26% 132/500 [00:05<00:20, 18.31it/s]\u001b[A\n",
            " 27% 134/500 [00:05<00:20, 18.14it/s]\u001b[A\n",
            " 27% 136/500 [00:05<00:20, 18.01it/s]\u001b[A\n",
            " 28% 138/500 [00:05<00:20, 17.93it/s]\u001b[A\n",
            " 28% 140/500 [00:05<00:20, 17.82it/s]\u001b[A\n",
            " 28% 142/500 [00:05<00:20, 17.75it/s]\u001b[A\n",
            " 29% 144/500 [00:06<00:20, 17.69it/s]\u001b[A\n",
            " 29% 146/500 [00:06<00:20, 17.57it/s]\u001b[A\n",
            " 30% 148/500 [00:06<00:20, 17.48it/s]\u001b[A\n",
            " 30% 150/500 [00:06<00:20, 17.42it/s]\u001b[A\n",
            " 30% 152/500 [00:06<00:20, 17.25it/s]\u001b[A\n",
            " 31% 154/500 [00:06<00:20, 16.94it/s]\u001b[A\n",
            " 31% 156/500 [00:06<00:20, 16.65it/s]\u001b[A\n",
            " 32% 158/500 [00:06<00:20, 16.39it/s]\u001b[A\n",
            " 32% 160/500 [00:07<00:21, 16.17it/s]\u001b[A\n",
            " 32% 162/500 [00:07<00:21, 16.09it/s]\u001b[A\n",
            " 33% 164/500 [00:07<00:20, 16.03it/s]\u001b[A\n",
            " 33% 166/500 [00:07<00:20, 15.96it/s]\u001b[A\n",
            " 34% 168/500 [00:07<00:20, 15.91it/s]\u001b[A\n",
            " 34% 170/500 [00:07<00:20, 15.84it/s]\u001b[A\n",
            " 34% 172/500 [00:07<00:20, 15.77it/s]\u001b[A\n",
            " 35% 174/500 [00:07<00:20, 15.75it/s]\u001b[A\n",
            " 35% 176/500 [00:08<00:20, 15.69it/s]\u001b[A\n",
            " 36% 178/500 [00:08<00:20, 15.61it/s]\u001b[A\n",
            " 36% 180/500 [00:08<00:20, 15.56it/s]\u001b[A\n",
            " 36% 182/500 [00:08<00:20, 15.52it/s]\u001b[A\n",
            " 37% 184/500 [00:08<00:20, 15.32it/s]\u001b[A\n",
            " 37% 186/500 [00:08<00:21, 14.90it/s]\u001b[A\n",
            " 38% 188/500 [00:08<00:21, 14.53it/s]\u001b[A\n",
            " 38% 190/500 [00:09<00:21, 14.25it/s]\u001b[A\n",
            " 38% 192/500 [00:09<00:21, 14.11it/s]\u001b[A\n",
            " 39% 194/500 [00:09<00:21, 14.01it/s]\u001b[A\n",
            " 39% 196/500 [00:09<00:21, 13.94it/s]\u001b[A\n",
            " 40% 198/500 [00:09<00:21, 13.88it/s]\u001b[A\n",
            " 40% 200/500 [00:09<00:21, 13.78it/s]\u001b[A\n",
            " 40% 202/500 [00:09<00:21, 13.72it/s]\u001b[A\n",
            " 41% 204/500 [00:10<00:21, 13.75it/s]\u001b[A\n",
            " 41% 206/500 [00:10<00:21, 13.73it/s]\u001b[A\n",
            " 42% 208/500 [00:10<00:21, 13.60it/s]\u001b[A\n",
            " 42% 210/500 [00:10<00:21, 13.54it/s]\u001b[A\n",
            " 42% 212/500 [00:10<00:21, 13.52it/s]\u001b[A\n",
            " 43% 214/500 [00:10<00:21, 13.46it/s]\u001b[A\n",
            " 43% 216/500 [00:10<00:21, 13.36it/s]\u001b[A\n",
            " 44% 218/500 [00:11<00:21, 13.24it/s]\u001b[A\n",
            " 44% 220/500 [00:11<00:21, 13.12it/s]\u001b[A\n",
            " 44% 222/500 [00:11<00:21, 13.02it/s]\u001b[A\n",
            " 45% 224/500 [00:11<00:21, 13.02it/s]\u001b[A\n",
            " 45% 226/500 [00:11<00:21, 13.01it/s]\u001b[A\n",
            " 46% 228/500 [00:11<00:21, 12.87it/s]\u001b[A\n",
            " 46% 230/500 [00:12<00:21, 12.78it/s]\u001b[A\n",
            " 46% 232/500 [00:12<00:21, 12.74it/s]\u001b[A\n",
            " 47% 234/500 [00:12<00:20, 12.76it/s]\u001b[A\n",
            " 47% 236/500 [00:12<00:20, 12.75it/s]\u001b[A\n",
            " 48% 238/500 [00:12<00:20, 12.66it/s]\u001b[A\n",
            " 48% 240/500 [00:12<00:20, 12.59it/s]\u001b[A\n",
            " 48% 242/500 [00:13<00:20, 12.55it/s]\u001b[A\n",
            " 49% 244/500 [00:13<00:20, 12.54it/s]\u001b[A\n",
            " 49% 246/500 [00:13<00:20, 12.53it/s]\u001b[A\n",
            " 50% 248/500 [00:13<00:20, 12.33it/s]\u001b[A\n",
            " 50% 250/500 [00:13<00:20, 12.01it/s]\u001b[A\n",
            " 50% 252/500 [00:13<00:21, 11.78it/s]\u001b[A\n",
            " 51% 254/500 [00:14<00:21, 11.54it/s]\u001b[A\n",
            " 51% 256/500 [00:14<00:21, 11.37it/s]\u001b[A\n",
            " 52% 258/500 [00:14<00:21, 11.30it/s]\u001b[A\n",
            " 52% 260/500 [00:14<00:21, 11.26it/s]\u001b[A\n",
            " 52% 262/500 [00:14<00:21, 11.23it/s]\u001b[A\n",
            " 53% 264/500 [00:14<00:21, 11.14it/s]\u001b[A\n",
            " 53% 266/500 [00:15<00:21, 11.05it/s]\u001b[A\n",
            " 54% 268/500 [00:15<00:20, 11.06it/s]\u001b[A\n",
            " 54% 270/500 [00:15<00:20, 11.06it/s]\u001b[A\n",
            " 54% 272/500 [00:15<00:20, 11.05it/s]\u001b[A\n",
            " 55% 274/500 [00:15<00:20, 10.95it/s]\u001b[A\n",
            " 55% 276/500 [00:16<00:20, 10.86it/s]\u001b[A\n",
            " 56% 278/500 [00:16<00:20, 10.83it/s]\u001b[A\n",
            " 56% 280/500 [00:16<00:20, 10.86it/s]\u001b[A\n",
            " 56% 282/500 [00:16<00:20, 10.79it/s]\u001b[A\n",
            " 57% 284/500 [00:16<00:20, 10.72it/s]\u001b[A\n",
            " 57% 286/500 [00:16<00:20, 10.70it/s]\u001b[A\n",
            " 58% 288/500 [00:17<00:20, 10.59it/s]\u001b[A\n",
            " 58% 290/500 [00:17<00:20, 10.47it/s]\u001b[A\n",
            " 58% 292/500 [00:17<00:19, 10.43it/s]\u001b[A\n",
            " 59% 294/500 [00:17<00:19, 10.44it/s]\u001b[A\n",
            " 59% 296/500 [00:17<00:19, 10.45it/s]\u001b[A\n",
            " 60% 298/500 [00:18<00:19, 10.44it/s]\u001b[A\n",
            " 60% 300/500 [00:18<00:19, 10.42it/s]\u001b[A\n",
            " 60% 302/500 [00:18<00:19, 10.40it/s]\u001b[A\n",
            " 61% 304/500 [00:18<00:18, 10.38it/s]\u001b[A\n",
            " 61% 306/500 [00:18<00:18, 10.35it/s]\u001b[A\n",
            " 62% 308/500 [00:19<00:18, 10.35it/s]\u001b[A\n",
            " 62% 310/500 [00:19<00:18, 10.37it/s]\u001b[A\n",
            " 62% 312/500 [00:19<00:18, 10.26it/s]\u001b[A\n",
            " 63% 314/500 [00:19<00:18, 10.05it/s]\u001b[A\n",
            " 63% 316/500 [00:19<00:18,  9.89it/s]\u001b[A\n",
            " 63% 317/500 [00:20<00:18,  9.79it/s]\u001b[A\n",
            " 64% 318/500 [00:20<00:18,  9.71it/s]\u001b[A\n",
            " 64% 319/500 [00:20<00:18,  9.64it/s]\u001b[A\n",
            " 64% 320/500 [00:20<00:18,  9.60it/s]\u001b[A\n",
            " 64% 321/500 [00:20<00:18,  9.56it/s]\u001b[A\n",
            " 64% 322/500 [00:20<00:18,  9.54it/s]\u001b[A\n",
            " 65% 323/500 [00:20<00:18,  9.53it/s]\u001b[A\n",
            " 65% 324/500 [00:20<00:18,  9.51it/s]\u001b[A\n",
            " 65% 325/500 [00:20<00:18,  9.49it/s]\u001b[A\n",
            " 65% 326/500 [00:20<00:18,  9.47it/s]\u001b[A\n",
            " 65% 327/500 [00:21<00:18,  9.43it/s]\u001b[A\n",
            " 66% 328/500 [00:21<00:18,  9.35it/s]\u001b[A\n",
            " 66% 329/500 [00:21<00:18,  9.31it/s]\u001b[A\n",
            " 66% 330/500 [00:21<00:18,  9.26it/s]\u001b[A\n",
            " 66% 331/500 [00:21<00:18,  9.24it/s]\u001b[A\n",
            " 66% 332/500 [00:21<00:18,  9.29it/s]\u001b[A\n",
            " 67% 333/500 [00:21<00:17,  9.33it/s]\u001b[A\n",
            " 67% 334/500 [00:21<00:17,  9.40it/s]\u001b[A\n",
            " 67% 335/500 [00:21<00:17,  9.42it/s]\u001b[A\n",
            " 67% 336/500 [00:22<00:17,  9.39it/s]\u001b[A\n",
            " 67% 337/500 [00:22<00:17,  9.37it/s]\u001b[A\n",
            " 68% 338/500 [00:22<00:17,  9.36it/s]\u001b[A\n",
            " 68% 339/500 [00:22<00:17,  9.35it/s]\u001b[A\n",
            " 68% 340/500 [00:22<00:17,  9.34it/s]\u001b[A\n",
            " 68% 341/500 [00:22<00:17,  9.30it/s]\u001b[A\n",
            " 68% 342/500 [00:22<00:17,  9.24it/s]\u001b[A\n",
            " 69% 343/500 [00:22<00:17,  9.21it/s]\u001b[A\n",
            " 69% 344/500 [00:22<00:17,  9.01it/s]\u001b[A\n",
            " 69% 345/500 [00:23<00:17,  8.90it/s]\u001b[A\n",
            " 69% 346/500 [00:23<00:17,  8.90it/s]\u001b[A\n",
            " 69% 347/500 [00:23<00:17,  8.89it/s]\u001b[A\n",
            " 70% 348/500 [00:23<00:17,  8.91it/s]\u001b[A\n",
            " 70% 349/500 [00:23<00:17,  8.87it/s]\u001b[A\n",
            " 70% 350/500 [00:23<00:16,  8.84it/s]\u001b[A\n",
            " 70% 351/500 [00:23<00:16,  8.81it/s]\u001b[A\n",
            " 70% 352/500 [00:23<00:16,  8.78it/s]\u001b[A\n",
            " 71% 353/500 [00:23<00:16,  8.80it/s]\u001b[A\n",
            " 71% 354/500 [00:24<00:16,  8.82it/s]\u001b[A\n",
            " 71% 355/500 [00:24<00:16,  8.83it/s]\u001b[A\n",
            " 71% 356/500 [00:24<00:16,  8.79it/s]\u001b[A\n",
            " 71% 357/500 [00:24<00:16,  8.75it/s]\u001b[A\n",
            " 72% 358/500 [00:24<00:16,  8.72it/s]\u001b[A\n",
            " 72% 359/500 [00:24<00:16,  8.72it/s]\u001b[A\n",
            " 72% 360/500 [00:24<00:16,  8.72it/s]\u001b[A\n",
            " 72% 361/500 [00:24<00:15,  8.73it/s]\u001b[A\n",
            " 72% 362/500 [00:24<00:15,  8.75it/s]\u001b[A\n",
            " 73% 363/500 [00:25<00:15,  8.75it/s]\u001b[A\n",
            " 73% 364/500 [00:25<00:15,  8.72it/s]\u001b[A\n",
            " 73% 365/500 [00:25<00:15,  8.67it/s]\u001b[A\n",
            " 73% 366/500 [00:25<00:15,  8.64it/s]\u001b[A\n",
            " 73% 367/500 [00:25<00:15,  8.64it/s]\u001b[A\n",
            " 74% 368/500 [00:25<00:15,  8.66it/s]\u001b[A\n",
            " 74% 369/500 [00:25<00:15,  8.68it/s]\u001b[A\n",
            " 74% 370/500 [00:25<00:15,  8.66it/s]\u001b[A\n",
            " 74% 371/500 [00:26<00:14,  8.63it/s]\u001b[A\n",
            " 74% 372/500 [00:26<00:14,  8.60it/s]\u001b[A\n",
            " 75% 373/500 [00:26<00:14,  8.59it/s]\u001b[A\n",
            " 75% 374/500 [00:26<00:14,  8.56it/s]\u001b[A\n",
            " 75% 375/500 [00:26<00:14,  8.60it/s]\u001b[A\n",
            " 75% 376/500 [00:26<00:14,  8.53it/s]\u001b[A\n",
            " 75% 377/500 [00:26<00:14,  8.42it/s]\u001b[A\n",
            " 76% 378/500 [00:26<00:14,  8.30it/s]\u001b[A\n",
            " 76% 379/500 [00:26<00:14,  8.25it/s]\u001b[A\n",
            " 76% 380/500 [00:27<00:14,  8.24it/s]\u001b[A\n",
            " 76% 381/500 [00:27<00:14,  8.27it/s]\u001b[A\n",
            " 76% 382/500 [00:27<00:14,  8.23it/s]\u001b[A\n",
            " 77% 383/500 [00:27<00:14,  8.16it/s]\u001b[A\n",
            " 77% 384/500 [00:27<00:14,  8.14it/s]\u001b[A\n",
            " 77% 385/500 [00:27<00:14,  8.18it/s]\u001b[A\n",
            " 77% 386/500 [00:27<00:13,  8.15it/s]\u001b[A\n",
            " 77% 387/500 [00:27<00:13,  8.08it/s]\u001b[A\n",
            " 78% 388/500 [00:28<00:13,  8.06it/s]\u001b[A\n",
            " 78% 389/500 [00:28<00:13,  8.06it/s]\u001b[A\n",
            " 78% 390/500 [00:28<00:13,  8.07it/s]\u001b[A\n",
            " 78% 391/500 [00:28<00:13,  8.05it/s]\u001b[A\n",
            " 78% 392/500 [00:28<00:13,  8.01it/s]\u001b[A\n",
            " 79% 393/500 [00:28<00:13,  8.03it/s]\u001b[A\n",
            " 79% 394/500 [00:28<00:13,  8.04it/s]\u001b[A\n",
            " 79% 395/500 [00:28<00:13,  8.00it/s]\u001b[A\n",
            " 79% 396/500 [00:29<00:13,  7.99it/s]\u001b[A\n",
            " 79% 397/500 [00:29<00:12,  7.99it/s]\u001b[A\n",
            " 80% 398/500 [00:29<00:12,  7.99it/s]\u001b[A\n",
            " 80% 399/500 [00:29<00:12,  7.97it/s]\u001b[A\n",
            " 80% 400/500 [00:29<00:12,  7.95it/s]\u001b[A\n",
            " 80% 401/500 [00:29<00:12,  7.96it/s]\u001b[A\n",
            " 80% 402/500 [00:29<00:12,  7.97it/s]\u001b[A\n",
            " 81% 403/500 [00:29<00:12,  7.97it/s]\u001b[A\n",
            " 81% 404/500 [00:30<00:12,  7.97it/s]\u001b[A\n",
            " 81% 405/500 [00:30<00:11,  7.96it/s]\u001b[A\n",
            " 81% 406/500 [00:30<00:11,  7.96it/s]\u001b[A\n",
            " 81% 407/500 [00:30<00:11,  7.95it/s]\u001b[A\n",
            " 82% 408/500 [00:30<00:11,  7.82it/s]\u001b[A\n",
            " 82% 409/500 [00:30<00:11,  7.74it/s]\u001b[A\n",
            " 82% 410/500 [00:30<00:11,  7.70it/s]\u001b[A\n",
            " 82% 411/500 [00:30<00:11,  7.66it/s]\u001b[A\n",
            " 82% 412/500 [00:31<00:11,  7.63it/s]\u001b[A\n",
            " 83% 413/500 [00:31<00:11,  7.62it/s]\u001b[A\n",
            " 83% 414/500 [00:31<00:11,  7.62it/s]\u001b[A\n",
            " 83% 415/500 [00:31<00:11,  7.60it/s]\u001b[A\n",
            " 83% 416/500 [00:31<00:11,  7.58it/s]\u001b[A\n",
            " 83% 417/500 [00:31<00:11,  7.54it/s]\u001b[A\n",
            " 84% 418/500 [00:31<00:10,  7.50it/s]\u001b[A\n",
            " 84% 419/500 [00:32<00:10,  7.51it/s]\u001b[A\n",
            " 84% 420/500 [00:32<00:10,  7.48it/s]\u001b[A\n",
            " 84% 421/500 [00:32<00:10,  7.48it/s]\u001b[A\n",
            " 84% 422/500 [00:32<00:10,  7.50it/s]\u001b[A\n",
            " 85% 423/500 [00:32<00:10,  7.47it/s]\u001b[A\n",
            " 85% 424/500 [00:32<00:10,  7.47it/s]\u001b[A\n",
            " 85% 425/500 [00:32<00:10,  7.47it/s]\u001b[A\n",
            " 85% 426/500 [00:32<00:09,  7.45it/s]\u001b[A\n",
            " 85% 427/500 [00:33<00:09,  7.44it/s]\u001b[A\n",
            " 86% 428/500 [00:33<00:09,  7.45it/s]\u001b[A\n",
            " 86% 429/500 [00:33<00:09,  7.42it/s]\u001b[A\n",
            " 86% 430/500 [00:33<00:09,  7.43it/s]\u001b[A\n",
            " 86% 431/500 [00:33<00:09,  7.43it/s]\u001b[A\n",
            " 86% 432/500 [00:33<00:09,  7.44it/s]\u001b[A\n",
            " 87% 433/500 [00:33<00:09,  7.44it/s]\u001b[A\n",
            " 87% 434/500 [00:34<00:08,  7.44it/s]\u001b[A\n",
            " 87% 435/500 [00:34<00:08,  7.45it/s]\u001b[A\n",
            " 87% 436/500 [00:34<00:08,  7.44it/s]\u001b[A\n",
            " 87% 437/500 [00:34<00:08,  7.44it/s]\u001b[A\n",
            " 88% 438/500 [00:34<00:08,  7.43it/s]\u001b[A\n",
            " 88% 439/500 [00:34<00:08,  7.44it/s]\u001b[A\n",
            " 88% 440/500 [00:34<00:08,  7.34it/s]\u001b[A\n",
            " 88% 441/500 [00:35<00:08,  7.28it/s]\u001b[A\n",
            " 88% 442/500 [00:35<00:08,  7.23it/s]\u001b[A\n",
            " 89% 443/500 [00:35<00:07,  7.16it/s]\u001b[A\n",
            " 89% 444/500 [00:35<00:07,  7.11it/s]\u001b[A\n",
            " 89% 445/500 [00:35<00:07,  7.11it/s]\u001b[A\n",
            " 89% 446/500 [00:35<00:07,  7.11it/s]\u001b[A\n",
            " 89% 447/500 [00:35<00:07,  7.08it/s]\u001b[A\n",
            " 90% 448/500 [00:36<00:07,  7.05it/s]\u001b[A\n",
            " 90% 449/500 [00:36<00:07,  7.02it/s]\u001b[A\n",
            " 90% 450/500 [00:36<00:07,  7.01it/s]\u001b[A\n",
            " 90% 451/500 [00:36<00:06,  7.02it/s]\u001b[A\n",
            " 90% 452/500 [00:36<00:06,  7.03it/s]\u001b[A\n",
            " 91% 453/500 [00:36<00:06,  7.03it/s]\u001b[A\n",
            " 91% 454/500 [00:36<00:06,  7.03it/s]\u001b[A\n",
            " 91% 455/500 [00:37<00:06,  7.01it/s]\u001b[A\n",
            " 91% 456/500 [00:37<00:06,  6.98it/s]\u001b[A\n",
            " 91% 457/500 [00:37<00:06,  6.97it/s]\u001b[A\n",
            " 92% 458/500 [00:37<00:05,  7.01it/s]\u001b[A\n",
            " 92% 459/500 [00:37<00:05,  7.00it/s]\u001b[A\n",
            " 92% 460/500 [00:37<00:05,  6.97it/s]\u001b[A\n",
            " 92% 461/500 [00:37<00:05,  6.95it/s]\u001b[A\n",
            " 92% 462/500 [00:38<00:05,  6.94it/s]\u001b[A\n",
            " 93% 463/500 [00:38<00:05,  6.92it/s]\u001b[A\n",
            " 93% 464/500 [00:38<00:05,  6.92it/s]\u001b[A\n",
            " 93% 465/500 [00:38<00:05,  6.93it/s]\u001b[A\n",
            " 93% 466/500 [00:38<00:04,  6.95it/s]\u001b[A\n",
            " 93% 467/500 [00:38<00:04,  6.95it/s]\u001b[A\n",
            " 94% 468/500 [00:38<00:04,  6.96it/s]\u001b[A\n",
            " 94% 469/500 [00:39<00:04,  6.94it/s]\u001b[A\n",
            " 94% 470/500 [00:39<00:04,  6.91it/s]\u001b[A\n",
            " 94% 471/500 [00:39<00:04,  6.90it/s]\u001b[A\n",
            " 94% 472/500 [00:39<00:04,  6.84it/s]\u001b[A\n",
            " 95% 473/500 [00:39<00:03,  6.80it/s]\u001b[A\n",
            " 95% 474/500 [00:39<00:03,  6.77it/s]\u001b[A\n",
            " 95% 475/500 [00:39<00:03,  6.75it/s]\u001b[A\n",
            " 95% 476/500 [00:40<00:03,  6.73it/s]\u001b[A\n",
            " 95% 477/500 [00:40<00:03,  6.72it/s]\u001b[A\n",
            " 96% 478/500 [00:40<00:03,  6.71it/s]\u001b[A\n",
            " 96% 479/500 [00:40<00:03,  6.71it/s]\u001b[A\n",
            " 96% 480/500 [00:40<00:02,  6.69it/s]\u001b[A\n",
            " 96% 481/500 [00:40<00:02,  6.67it/s]\u001b[A\n",
            " 96% 482/500 [00:40<00:02,  6.66it/s]\u001b[A\n",
            " 97% 483/500 [00:41<00:02,  6.66it/s]\u001b[A\n",
            " 97% 484/500 [00:41<00:02,  6.66it/s]\u001b[A\n",
            " 97% 485/500 [00:41<00:02,  6.66it/s]\u001b[A\n",
            " 97% 486/500 [00:41<00:02,  6.66it/s]\u001b[A\n",
            " 97% 487/500 [00:41<00:01,  6.65it/s]\u001b[A\n",
            " 98% 488/500 [00:41<00:01,  6.61it/s]\u001b[A\n",
            " 98% 489/500 [00:42<00:01,  6.61it/s]\u001b[A\n",
            " 98% 490/500 [00:42<00:01,  6.61it/s]\u001b[A\n",
            " 98% 491/500 [00:42<00:01,  6.62it/s]\u001b[A\n",
            " 98% 492/500 [00:42<00:01,  6.62it/s]\u001b[A\n",
            " 99% 493/500 [00:42<00:01,  6.59it/s]\u001b[A\n",
            " 99% 494/500 [00:42<00:00,  6.59it/s]\u001b[A\n",
            " 99% 495/500 [00:42<00:00,  6.57it/s]\u001b[A\n",
            " 99% 496/500 [00:43<00:00,  6.57it/s]\u001b[A\n",
            " 99% 497/500 [00:43<00:00,  6.56it/s]\u001b[A\n",
            "100% 498/500 [00:43<00:00,  6.56it/s]\u001b[A\n",
            "100% 499/500 [00:43<00:00,  6.54it/s]\u001b[A\n",
            "100% 500/500 [00:43<00:00, 11.45it/s]\n",
            "  Будьте практичны. Этот день может положить начало длительному спокойному периоду вашего существования и принесет вашему душевному равновесию совсем иное благополучие.\n",
            "\n",
            "\n",
            "Семь колец внимания\n",
            "\n",
            "\n",
            "Сосредоточьте свой взгляд на ничтожных вещах, над которыми вы до сих пор размышляли или собирались поработать, и сфокусируйте внимание только на значимых событиях, делающих ваши мысли интересными. Забудьте о повседневных вещах, о которых прежде вы словно бы и не имели ни малейшего представления. Вы можете вспомнить о существовании мудрых вещей и услышать простые слова, которые помогут вам справиться с возникшими в данный момент трудностями. Затем начните работать над течением мыслей и ощущениями каждого дня. Прослушивайте и анализируйте все мыслимые и немыслимые мысли и чувства, какие только у вас возникли, и даже если для вас это кажется таким простым делом, старайтесь ничего не упустить.\n",
            "\n",
            "\n",
            "Семь колец гармонии\n",
            "\n",
            "\n",
            "Сосредоточьте свои мысли на приятных вещах – не важно что, а главное, они приятны вашей душе.\n",
            "\n",
            "\n",
            "Девятка больших колец\n",
            "\n",
            "\n",
            "Сосредоточьтесь на том, что не позволяет вам вознестись к небу, но находится рядом с вами.\n",
            "\n",
            "\n",
            "Резонанс для работы над своим добром\n",
            "\n",
            "\n",
            "Ключевые слова взяты из книг с описанием тех вещей, которые все сильнее проявляются во всем мире. Девять колец согласия – это один из главных механизмов регулирования отношения между людьми и управляет всей их жизнью. Важно, чтобы они были гармоничными и в то же время не противоречили друг другу, не подвергались ограничениям, не были загрязнены. Колец гармонии, которых вы ищете, можно найти во множестве источников информации, и вы найдете их у каждого человека.\n",
            "\n",
            "\n",
            "Нейтральный эгоизм\n",
            "\n",
            "\n",
            "В тот день, когда вы отдаете предпочтение Благоразумию или Милосердию, вы не думаете, что должны игнорировать какие-то другие аспекты вашего внутреннего мира. В противоположность им, вы стремитесь найти эти аспекты внутренним голосом, и все же они по-прежнему препятствуют вам находиться на правильном пути. Можно в определенных обстоятельствах позволить себе чувство гордости за что-то свое, но даже этого недостаточно, чтобы стать счастливее. Никто из нас не считает себя независимым и каждый выбирает свое собственное понимание своей жизни. Любая позиция с позиции Творца предполагает необходимость действия, и только это определяет его поведение. Нейтральный эгоизм часто связан с поступками и переживаниями окружающих и тех, кто находится в близких отношениях. Каждый раз, когда вы начинаете избавляться от Нейтрального Эгоизма, вы рискуете обрести неприятности, которые могли бы даже помешать вам в достижении цели. И если вы не хотите\n",
            "Epoch: 100% 5/5 [27:00<00:00, 324.02s/it]\n",
            "10/21/2020 09:36:17 - INFO - __main__ -    global_step = 1900915, average loss = 0.001606054271890116\n",
            "10/21/2020 09:36:17 - INFO - __main__ -   Saving model checkpoint to /content/gdrive/My Drive/gpt2-ru\n",
            "10/21/2020 09:36:17 - INFO - transformers.configuration_utils -   Configuration saved in /content/gdrive/My Drive/gpt2-ru/config.json\n",
            "10/21/2020 09:36:20 - INFO - transformers.modeling_utils -   Model weights saved in /content/gdrive/My Drive/gpt2-ru/pytorch_model.bin\n",
            "10/21/2020 09:36:21 - INFO - __main__ -   Saving model checkpoint to /content/gdrive/My Drive/gpt2-ru/checkpoint-1900915\n",
            "10/21/2020 09:36:21 - INFO - transformers.configuration_utils -   Configuration saved in /content/gdrive/My Drive/gpt2-ru/checkpoint-1900915/config.json\n",
            "10/21/2020 09:36:24 - INFO - transformers.modeling_utils -   Model weights saved in /content/gdrive/My Drive/gpt2-ru/checkpoint-1900915/pytorch_model.bin\n",
            "10/21/2020 09:36:24 - INFO - transformers.configuration_utils -   loading configuration file /content/gdrive/My Drive/gpt2-ru/config.json\n",
            "10/21/2020 09:36:24 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_labels\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "10/21/2020 09:36:24 - INFO - transformers.modeling_utils -   loading weights file /content/gdrive/My Drive/gpt2-ru/pytorch_model.bin\n",
            "10/21/2020 09:36:33 - INFO - __main__ -   Evaluate the following checkpoints: ['/content/gdrive/My Drive/gpt2-ru']\n",
            "10/21/2020 09:36:33 - INFO - transformers.configuration_utils -   loading configuration file /content/gdrive/My Drive/gpt2-ru/config.json\n",
            "10/21/2020 09:36:33 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_labels\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "10/21/2020 09:36:33 - INFO - transformers.modeling_utils -   loading weights file /content/gdrive/My Drive/gpt2-ru/pytorch_model.bin\n",
            "10/21/2020 09:36:42 - INFO - __main__ -   Loading features from ./dataset/validation/validation.txt\n",
            "<IPython.core.display.HTML object>\n",
            "<IPython.core.display.HTML object>\n",
            "<IPython.core.display.HTML object>\n",
            "10/21/2020 09:36:42 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "10/21/2020 09:36:42 - INFO - __main__ -     Num examples = 30\n",
            "10/21/2020 09:36:42 - INFO - __main__ -     Batch size = 4\n",
            "Evaluating: 100% 8/8 [00:06<00:00,  1.18it/s]\n",
            "10/21/2020 09:36:49 - INFO - __main__ -   ***** Eval results  *****\n",
            "10/21/2020 09:36:49 - INFO - __main__ -     perplexity = tensor(23.9807)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NND63cuu0m2X"
      },
      "source": [
        "# Start\n",
        "# python3 run_lm_finetuning.py \\\n",
        "#     --output_dir=\"/content/gdrive/My Drive/gpt2-ru\" \\\n",
        "#     --model_type=gpt2 \\\n",
        "#     --model_name_or_path=./gpt2/m_checkpoint-3364613/ \\\n",
        "#     --do_train \\\n",
        "#     --train_data_file=./dataset/train/ \\\n",
        "#     --per_gpu_train_batch_size=2 \\\n",
        "#     --save_steps=10000 \\\n",
        "#     --logging_steps=1 \\\n",
        "#     --warmup_samples 16000 \\\n",
        "#     --learning_rate 3e-5 \\\n",
        "#     --tokenizer_class YTEncoder \\\n",
        "#     --tokenizer_name bpe/yt.model \\\n",
        "#     --do_eval \\\n",
        "#     --evaluate_during_training \\\n",
        "#     --eval_steps 1000 \\\n",
        "#     --eval_data_file=./dataset/validation/ \\\n",
        "#     --num_train_epochs 1.0 \\\n",
        "#     --unfreeze_level 0 \\\n",
        "#     --fp16 \\\n",
        "#     --fp16_opt_level O2 \\\n",
        "#     --overwrite_output_dir\n",
        "\n",
        "# Continue\n",
        "# python3 run_lm_finetuning.py \\\n",
        "#     --output_dir=\"/content/gdrive/My Drive/gpt2-ru\" \\\n",
        "#     --model_type=gpt2 \\\n",
        "#     --model_name_or_path=\"/content/gdrive/My Drive/gpt2-ru\" \\\n",
        "#     --do_train \\\n",
        "#     --train_data_file=\"./dataset/prepared/\" \\\n",
        "#     --per_gpu_train_batch_size=2 \\\n",
        "#     --save_steps=10000 \\\n",
        "#     --logging_steps=1 \\\n",
        "#     --warmup_samples 16000 \\\n",
        "#     --learning_rate 3e-5 \\\n",
        "#     --tokenizer_class YTEncoder \\\n",
        "#     --tokenizer_name bpe/yt.model \\\n",
        "#     --do_eval \\\n",
        "#     --evaluate_during_training \\\n",
        "#     --eval_steps 1000 \\\n",
        "#     --eval_data_file=./dataset/eval/ \\\n",
        "#     --num_train_epochs 2.0 \\\n",
        "#     --unfreeze_level 0 \\\n",
        "#     --fp16 \\\n",
        "#     --fp16_opt_level O2 \\\n",
        "#     --overwrite_output_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjagyzIJ_VUW"
      },
      "source": [
        "# Генерация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wec6dnONhFU5"
      },
      "source": [
        "Можно поиграться, нужно задавать начало фразы. Модель подгружается с Google Disk, указывайте путь до своего чекпоинта, если будете обучать.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kddwjkiU_U9W",
        "outputId": "2536b618-d572-45e7-fb14-dd1b7365cca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 evaluate_model.py --length 39 --model_path \"/content/gdrive/My Drive/gpt2-ru/checkpoint-1900915\" --continuous_run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-21 09:43:53.161083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:43:55.176095: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-21 09:43:55.180351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:43:55.181192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-21 09:43:55.181236: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:43:55.183343: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-21 09:43:55.185215: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-21 09:43:55.188498: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-21 09:43:55.190541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-21 09:43:55.194096: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-21 09:43:55.198541: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-21 09:43:55.198703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:43:55.199561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:43:55.200282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-21 09:43:55.206890: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-10-21 09:43:55.207162: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x61cea00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-21 09:43:55.207201: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-21 09:43:55.271168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:43:55.272110: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x61ce840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-21 09:43:55.272145: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-10-21 09:43:55.272381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:43:55.273115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-21 09:43:55.273172: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:43:55.273234: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-21 09:43:55.273274: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-21 09:43:55.273325: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-21 09:43:55.273379: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-21 09:43:55.273443: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-21 09:43:55.273497: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-21 09:43:55.273600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:43:55.274376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:43:55.275127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-21 09:43:55.275230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:43:58.073402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-21 09:43:58.073491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-21 09:43:58.073510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-21 09:43:58.073967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:43:58.074875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:43:58.075556: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-21 09:43:58.075620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10350 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "10/21/2020 09:43:58 - INFO - transformers.configuration_utils -   loading configuration file /content/gdrive/My Drive/gpt2-ru/checkpoint-1900915/config.json\n",
            "10/21/2020 09:43:58 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_labels\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "10/21/2020 09:43:58 - INFO - transformers.modeling_utils -   loading weights file /content/gdrive/My Drive/gpt2-ru/checkpoint-1900915/pytorch_model.bin\n",
            "Prompt: Вас ждет удачный день. Можно сосредоточиться\n",
            "100% 39/39 [00:00<00:00, 40.34it/s]\n",
            " на чем-нибудь еще, когда я пойду к королеве.\n",
            "Да уж, это определенно были не выходные.\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt: Яркий, насыщенный день. Вы чувствуете прилив энергии\n",
            "100% 39/39 [00:00<00:00, 41.29it/s]\n",
            " к жизни. Вот поэтому и называется «космический период». Все вокруг создано для того, чтобы жить. Это прекрасная цель, которую вы должны достичь.\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt:  Благоприятный день для общения и новых знакомств. Любые отношения\n",
            "100% 39/39 [00:00<00:00, 40.31it/s]\n",
            " могут быть иными, не всегда удобными.\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt: Не все дается легко, но в целом вы останетесь довольны тем,\n",
            "100% 39/39 [00:00<00:00, 41.89it/s]\n",
            " что вы есть.\n",
            "Это может быть что-то вроде «Как выглядит Иисус Христос»?\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt: Не спешите. Достичь успеха можно, но, скорее всего\n",
            "100% 39/39 [00:00<00:00, 42.10it/s]\n",
            " не сразу, а лишь до того момента, когда не будет больше никаких причин для беспокойства.\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt:  Вы отлично ладите с людьми и умело этим пользуетесь. Сегодня вам удастся\n",
            "100% 39/39 [00:00<00:00, 41.56it/s]\n",
            " доказать, что вы были правы, говоря, что «Любовь и любовь — это одно и то же».\n",
            "Как раз на этой идее я и собираюсь основать компанию.\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt: Вы сделаете все возможное, чтобы провести день плодотворно, ни минуты\n",
            "100% 39/39 [00:00<00:00, 44.25it/s]\n",
            " не тратя впустую.\n",
            "Самое время заняться своим делом.\n",
            "С этим я согласился.\n",
            "Я написал несколько писем и отправил их в типографию.\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt: Первая половина дня благоприятна для общения с близкими\n",
            "100% 39/39 [00:00<00:00, 41.79it/s]\n",
            " людьми, то и здоровому человеку, и великому духовному учителю будет лучше получить возможность общаться с самыми близкими людьми.\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt: Traceback (most recent call last):\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVRbWkH9hYdA"
      },
      "source": [
        "Аналогичная генерация из модели побольше, но без тюнинга."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EScjHnckLBc",
        "outputId": "facdf377-977b-4525-c521-643e21f353c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 evaluate_model.py --length 39 --model_path \"/content/ru_transformers/gpt2/m_checkpoint-3364613\" --continuous_run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-21 09:50:45.990143: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:50:47.919881: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-21 09:50:47.923786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:50:47.924541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-21 09:50:47.924584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:50:47.926534: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-21 09:50:47.928498: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-21 09:50:47.929107: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-21 09:50:47.931146: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-21 09:50:47.932474: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-21 09:50:47.936889: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-21 09:50:47.937039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:50:47.937873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:50:47.938613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-21 09:50:47.944970: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-10-21 09:50:47.945241: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6338a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-21 09:50:47.945279: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-21 09:50:48.003067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:50:48.003949: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6338840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-21 09:50:48.003985: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-10-21 09:50:48.004194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:50:48.004918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla K80 computeCapability: 3.7\n",
            "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
            "2020-10-21 09:50:48.005013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:50:48.005082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-10-21 09:50:48.005128: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-10-21 09:50:48.005170: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-10-21 09:50:48.005212: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-10-21 09:50:48.005252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-10-21 09:50:48.005293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-21 09:50:48.005395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:50:48.006240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:50:48.007004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-10-21 09:50:48.007062: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-10-21 09:50:50.842361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-21 09:50:50.842427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-10-21 09:50:50.842448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-10-21 09:50:50.842717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:50:50.843582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-21 09:50:50.844308: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-10-21 09:50:50.844367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10350 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "10/21/2020 09:50:50 - INFO - transformers.configuration_utils -   loading configuration file /content/ru_transformers/gpt2/m_checkpoint-3364613/config.json\n",
            "10/21/2020 09:50:50 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"num_labels\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "10/21/2020 09:50:50 - INFO - transformers.modeling_utils -   loading weights file /content/ru_transformers/gpt2/m_checkpoint-3364613/pytorch_model.bin\n",
            "Prompt: Несмотря на трудности, которые могут возникнуть в начале дня\n",
            "100% 39/39 [00:01<00:00, 20.79it/s]\n",
            " или на ночь, должны быть готовы:\n",
            "Кислая капуста – 2 ст. л., слива – 2 ст. л., морковь – 2 шт., лук репчатый – 1 шт.\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt:  Первая половина дня будет\n",
            "100% 39/39 [00:02<00:00, 16.92it/s]\n",
            " еще впереди. Вот только мы еще не знаем, что с ней делать.\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt:  Благоприятный день для работы и важных дел. Вы отлично\n",
            "100% 39/39 [00:01<00:00, 20.47it/s]\n",
            " отдохнули и выспались после утомительной недели в дороге.\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt:  Спокойный день, отлично подходящий для того, чтобы заниматься какими-то простыми и привычными\n",
            "100% 39/39 [00:01<00:00, 21.87it/s]\n",
            " делами.\n",
            "Если вы не знаете, что именно нужно делать, просто попробуйте это сделать.\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt:  Что-нибудь наверняка пойдет не по плану, но вы держитесь. Самое главное сейчас — не падать духом и не думать\n",
            "100% 39/39 [00:01<00:00, 21.09it/s]\n",
            " о последствиях…\n",
            "Так оно и случилось.\n",
            "Еду в госпиталь. И сразу же выясняется, что у меня опять повысился уровень адреналина.\n",
            "\n",
            "-------SAMPLE 0 END-------\n",
            "Prompt: Traceback (most recent call last):\n",
            "  File \"evaluate_model.py\", line 119, in <module>\n",
            "    main()\n",
            "  File \"evaluate_model.py\", line 108, in main\n",
            "    continuous_run(evaluator, args)\n",
            "  File \"evaluate_model.py\", line 76, in continuous_run\n",
            "    prompt = input(\"Prompt: \")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1fq5UAOkWsz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}